{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96eaf858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7738f8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8734c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing = fetch_california_housing()\n",
    "X, y = housing.data, housing.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1318f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6b51961",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76d10507",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f51897a",
   "metadata": {},
   "source": [
    "# Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d24d59d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ = keras.layers.Input(shape=X_train.shape[1:])\n",
    "hidden_1 = keras.layers.Dense(30, activation=\"relu\")(input_)\n",
    "hidden_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "concat = keras.layers.Concatenate()([input_, hidden_2])\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286301b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 8)]          0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 30)           270         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 30)           930         ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 38)           0           ['input_1[0][0]',                \n",
      "                                                                  'dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            39          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,239\n",
      "Trainable params: 1,239\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdebc8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.6708 - val_loss: 2.4923\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7269 - val_loss: 1.9459\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6450 - val_loss: 0.8167\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5773 - val_loss: 0.5607\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5476 - val_loss: 0.6324\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 0.5762\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5089 - val_loss: 0.4964\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4963 - val_loss: 0.5794\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4844 - val_loss: 0.5598\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4768 - val_loss: 0.4769\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.8762\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4641 - val_loss: 1.1973\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4645 - val_loss: 0.6665\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4524 - val_loss: 0.6827\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4484 - val_loss: 0.4903\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.6621\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4420 - val_loss: 0.6801\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4363 - val_loss: 0.4444\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4313 - val_loss: 0.4070\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4283 - val_loss: 0.4072\n",
      "162/162 [==============================] - 0s 683us/step - loss: 0.4215\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mean_squared_error\",optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val))\n",
    "mse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f1c571e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.42146021127700806"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "114d4b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = keras.layers.Input(shape=[5], name=\"wide_input\")\n",
    "input_b = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden_1 = keras.layers.Dense(30, activation=\"relu\")(input_b)\n",
    "hidden_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "conc = keras.layers.Concatenate()([input_a, hidden_2])\n",
    "output = keras.layers.Dense(1, name=\"output\")(conc)\n",
    "model = keras.Model(inputs=[input_a, input_b], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e59ccc81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8449 - val_loss: 0.8915\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7438 - val_loss: 0.6866\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6558 - val_loss: 0.6458\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6161 - val_loss: 0.5893\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5849 - val_loss: 0.5482\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5601 - val_loss: 0.5293\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5388 - val_loss: 0.5082\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5220 - val_loss: 0.4866\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5073 - val_loss: 0.4723\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4950 - val_loss: 0.4600\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4847 - val_loss: 0.4502\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4760 - val_loss: 0.4412\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4686 - val_loss: 0.4371\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4624 - val_loss: 0.4304\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4572 - val_loss: 0.4296\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4241\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4493 - val_loss: 0.4219\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4219\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4431 - val_loss: 0.4188\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4408 - val_loss: 0.4274\n",
      "162/162 [==============================] - 0s 699us/step - loss: 0.4348\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "\n",
    "X_train_A, X_train_B = X_train[:,:5], X_train[:,2:]\n",
    "X_test_A, X_test_B = X_test[:,:5], X_test[:,2:]\n",
    "X_val_A, X_val_B = X_val[:,:5], X_val[:,2:]\n",
    "X_new_A, X_new_B = X_test_A[:3], X_test_B[:3]\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_val_A, X_val_B), y_val))\n",
    "mse_test = model.evaluate((X_test_A,X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee426f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=[5], name=\"wide_input\") \n",
    "input_B = keras.layers.Input(shape=[6], name=\"deep_input\")\n",
    "hidden_1 = keras.layers.Dense(30, activation=\"relu\")(input_B)\n",
    "hidden_2 = keras.layers.Dense(30, activation=\"relu\")(hidden_1)\n",
    "concat = keras.layers.Concatenate()([hidden_1, input_A])\n",
    "output = keras.layers.Dense(1, name=\"main_output\")(concat)\n",
    "aux = keras.layers.Dense(1, name=\"Aux_output\")(hidden_2)\n",
    "\n",
    "model = keras.Model(inputs=[input_A, input_B], outputs=[output, aux])\n",
    "model.compile(loss=[\"mse\",\"mse\"], loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fdedc42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.2081 - main_output_loss: 2.0145 - Aux_output_loss: 3.9514 - val_loss: 2.6867 - val_main_output_loss: 1.4446 - val_Aux_output_loss: 13.8654\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.9459 - main_output_loss: 0.7336 - Aux_output_loss: 2.8565 - val_loss: 2.1739 - val_main_output_loss: 0.8076 - val_Aux_output_loss: 14.4704\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7940 - main_output_loss: 0.6383 - Aux_output_loss: 2.1951 - val_loss: 1.9398 - val_main_output_loss: 0.6054 - val_Aux_output_loss: 13.9494\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7277 - main_output_loss: 0.6064 - Aux_output_loss: 1.8185 - val_loss: 1.7688 - val_main_output_loss: 0.5767 - val_Aux_output_loss: 12.4980\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6867 - main_output_loss: 0.5856 - Aux_output_loss: 1.5968 - val_loss: 1.5962 - val_main_output_loss: 0.5544 - val_Aux_output_loss: 10.9727\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6566 - main_output_loss: 0.5670 - Aux_output_loss: 1.4628 - val_loss: 1.4635 - val_main_output_loss: 0.5362 - val_Aux_output_loss: 9.8087\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6338 - main_output_loss: 0.5512 - Aux_output_loss: 1.3773 - val_loss: 1.3567 - val_main_output_loss: 0.5214 - val_Aux_output_loss: 8.8737\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6149 - main_output_loss: 0.5369 - Aux_output_loss: 1.3174 - val_loss: 1.2502 - val_main_output_loss: 0.5056 - val_Aux_output_loss: 7.9510\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5980 - main_output_loss: 0.5233 - Aux_output_loss: 1.2704 - val_loss: 1.1579 - val_main_output_loss: 0.4925 - val_Aux_output_loss: 7.1465\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5832 - main_output_loss: 0.5113 - Aux_output_loss: 1.2310 - val_loss: 1.0779 - val_main_output_loss: 0.4801 - val_Aux_output_loss: 6.4584\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5701 - main_output_loss: 0.5004 - Aux_output_loss: 1.1975 - val_loss: 1.0139 - val_main_output_loss: 0.4716 - val_Aux_output_loss: 5.8942\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5582 - main_output_loss: 0.4906 - Aux_output_loss: 1.1666 - val_loss: 0.9545 - val_main_output_loss: 0.4595 - val_Aux_output_loss: 5.4099\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5475 - main_output_loss: 0.4819 - Aux_output_loss: 1.1381 - val_loss: 0.9027 - val_main_output_loss: 0.4510 - val_Aux_output_loss: 4.9678\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5379 - main_output_loss: 0.4742 - Aux_output_loss: 1.1107 - val_loss: 0.8577 - val_main_output_loss: 0.4434 - val_Aux_output_loss: 4.5858\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5288 - main_output_loss: 0.4671 - Aux_output_loss: 1.0846 - val_loss: 0.8202 - val_main_output_loss: 0.4397 - val_Aux_output_loss: 4.2445\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5208 - main_output_loss: 0.4609 - Aux_output_loss: 1.0591 - val_loss: 0.7832 - val_main_output_loss: 0.4330 - val_Aux_output_loss: 3.9349\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5134 - main_output_loss: 0.4555 - Aux_output_loss: 1.0346 - val_loss: 0.7544 - val_main_output_loss: 0.4314 - val_Aux_output_loss: 3.6610\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5078 - main_output_loss: 0.4518 - Aux_output_loss: 1.0114 - val_loss: 0.7309 - val_main_output_loss: 0.4329 - val_Aux_output_loss: 3.4133\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5023 - main_output_loss: 0.4481 - Aux_output_loss: 0.9898 - val_loss: 0.7052 - val_main_output_loss: 0.4292 - val_Aux_output_loss: 3.1890\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4983 - main_output_loss: 0.4460 - Aux_output_loss: 0.9693 - val_loss: 0.6929 - val_main_output_loss: 0.4374 - val_Aux_output_loss: 2.9919\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train_A, X_train_B], [y_train, y_train], epochs=20, validation_data=([X_val_A, X_val_B], [y_val,y_val]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ec9f1",
   "metadata": {},
   "source": [
    "# Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dcfdfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideAndDeepModel(keras.models.Model):\n",
    "    def __init__(self, units, activation, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden1 = keras.layers.Dense(units, activation=activation)\n",
    "        self.hidden2 = keras.layers.Dense(units, activation=activation)\n",
    "        self.main_output = keras.layers.Dense(1)\n",
    "        self.aux_output = keras.layers.Dense(1)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        input_A, input_B = inputs\n",
    "        hidden1 = self.hidden1(input_B)\n",
    "        hidden2 = self.hidden2(hidden1)\n",
    "        concat = keras.layers.Concatenate()([input_A, hidden2])\n",
    "        main_output = self.main_output(concat)\n",
    "        aux_output = self.aux_output(hidden2)\n",
    "        return main_output, aux_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41674af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WideAndDeepModel(units=30, activation=\"relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8b5ea0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 2.5328 - output_1_loss: 2.2768 - output_2_loss: 4.8370 - val_loss: 2.5687 - val_output_1_loss: 2.1936 - val_output_2_loss: 5.9446\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1123 - output_1_loss: 0.8768 - output_2_loss: 3.2318 - val_loss: 1.3334 - val_output_1_loss: 1.0711 - val_output_2_loss: 3.6941\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8959 - output_1_loss: 0.7328 - output_2_loss: 2.3633 - val_loss: 0.9501 - val_output_1_loss: 0.7634 - val_output_2_loss: 2.6307\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8055 - output_1_loss: 0.6805 - output_2_loss: 1.9314 - val_loss: 0.8357 - val_output_1_loss: 0.6935 - val_output_2_loss: 2.1148\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7545 - output_1_loss: 0.6493 - output_2_loss: 1.7011 - val_loss: 0.7535 - val_output_1_loss: 0.6334 - val_output_2_loss: 1.8341\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7174 - output_1_loss: 0.6231 - output_2_loss: 1.5659 - val_loss: 0.7154 - val_output_1_loss: 0.6100 - val_output_2_loss: 1.6635\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6885 - output_1_loss: 0.6013 - output_2_loss: 1.4730 - val_loss: 0.6721 - val_output_1_loss: 0.5749 - val_output_2_loss: 1.5471\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6626 - output_1_loss: 0.5803 - output_2_loss: 1.4032 - val_loss: 0.6439 - val_output_1_loss: 0.5534 - val_output_2_loss: 1.4587\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6388 - output_1_loss: 0.5603 - output_2_loss: 1.3456 - val_loss: 0.6191 - val_output_1_loss: 0.5338 - val_output_2_loss: 1.3868\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6167 - output_1_loss: 0.5412 - output_2_loss: 1.2958 - val_loss: 0.5920 - val_output_1_loss: 0.5103 - val_output_2_loss: 1.3271\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", loss_weights=[0.9, 0.1], optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "history = model.fit((X_train_A, X_train_B), (y_train, y_train), epochs=10,\n",
    "                    validation_data=((X_val_A, X_val_B), (y_val, y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6325ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 826us/step - loss: 0.5955 - output_1_loss: 0.5207 - output_2_loss: 1.2686\n"
     ]
    }
   ],
   "source": [
    "eval_results = model.evaluate([X_test_A, X_test_B],[y_test, y_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc81834b",
   "metadata": {},
   "source": [
    "# Saving and Restoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b358376",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e431a5be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.1563 - val_loss: 1.2299\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8704 - val_loss: 0.7260\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7283 - val_loss: 0.6743\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6730 - val_loss: 0.6113\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6326 - val_loss: 0.5798\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5980 - val_loss: 0.5597\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5692 - val_loss: 0.5606\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5444 - val_loss: 0.5029\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5222 - val_loss: 0.4974\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5030 - val_loss: 0.4968\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4867 - val_loss: 0.4497\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4722 - val_loss: 0.4585\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4604 - val_loss: 0.4307\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4502 - val_loss: 0.4195\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4414 - val_loss: 0.4130\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4339 - val_loss: 0.4075\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4275 - val_loss: 0.4174\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4219 - val_loss: 0.4143\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4166 - val_loss: 0.4039\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4123 - val_loss: 0.4304\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.4190\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4046 - val_loss: 0.4457\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4013 - val_loss: 0.4013\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3981 - val_loss: 0.4281\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3953 - val_loss: 0.4577\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3930 - val_loss: 0.4506\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3908 - val_loss: 0.4074\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3885 - val_loss: 0.4317\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3866 - val_loss: 0.4223\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4473\n",
      "162/162 [==============================] - 0s 702us/step - loss: 0.3802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_11/kernel:0' shape=(8, 30) dtype=float32, numpy=\n",
       " array([[-0.17768577,  0.00971486,  0.36011565,  0.07893822, -0.27610144,\n",
       "         -0.22293712, -0.38955867,  0.5115942 , -0.33368745,  0.39635187,\n",
       "          0.09846476, -0.31417608,  0.16699253,  0.23989193,  0.07175025,\n",
       "          0.29065537,  0.13163786, -0.12748659, -0.19328141, -0.1246537 ,\n",
       "          0.09995623,  0.02007288,  0.03889387,  0.11134671,  0.29252034,\n",
       "          0.34374103, -0.22397473, -0.132106  , -0.03969977, -0.25227657],\n",
       "        [-0.18592463, -0.1215399 ,  0.0181578 , -0.14408863,  0.19109239,\n",
       "         -0.13846442,  0.24220298,  0.11030792, -0.06089566,  0.34884614,\n",
       "         -0.13686483, -0.25893295, -0.348042  ,  0.02142049, -0.32260907,\n",
       "          0.27560952, -0.04714003,  0.19661461,  0.163129  ,  0.49370825,\n",
       "         -0.13329399, -0.3804392 ,  0.04339924,  0.08191223, -0.08972969,\n",
       "          0.07632751,  0.1777138 , -0.16396828, -0.25209746,  0.17597263],\n",
       "        [-0.11156897, -0.14324349, -0.35396647, -0.01149784,  0.09652574,\n",
       "         -0.1890878 ,  0.2587541 ,  0.22432026, -0.32142723, -0.21614522,\n",
       "         -0.23281062,  0.1763337 , -0.23240474,  0.36491802, -0.26214644,\n",
       "          0.02463679,  0.05452054, -0.29680443, -0.05837248, -0.04748354,\n",
       "         -0.21401788, -0.12085454, -0.10808257,  0.06642964,  0.2157522 ,\n",
       "          0.11208221, -0.16077906,  0.35417676, -0.32468033,  0.1119526 ],\n",
       "        [ 0.10252877,  0.0822643 , -0.04507922, -0.4470033 , -0.34280425,\n",
       "         -0.25641048,  0.17155682,  0.04780386,  0.11608027, -0.05719353,\n",
       "         -0.06904274, -0.08881799,  0.19837052, -0.03820532, -0.3743904 ,\n",
       "          0.04795648, -0.10701196,  0.28067794, -0.20546569,  0.03446567,\n",
       "          0.319693  , -0.10316765,  0.00477596,  0.04142499, -0.18274032,\n",
       "          0.18055879,  0.2557326 , -0.03843635, -0.29266113, -0.2758017 ],\n",
       "        [ 0.28315693,  0.06957562,  0.07776786, -0.06498393, -0.03563197,\n",
       "         -0.24322914,  0.04197838,  0.1009696 ,  0.19428435,  0.12515496,\n",
       "         -0.02309381, -0.05400334, -0.05073682, -0.3346583 ,  0.15302098,\n",
       "         -0.0777768 , -0.24668413, -0.14620851, -0.19621885,  0.2768344 ,\n",
       "          0.29214567,  0.05304989,  0.2425519 , -0.30097267,  0.08938825,\n",
       "          0.32334182,  0.43765807,  0.1614267 , -0.03579763,  0.3292847 ],\n",
       "        [-0.35415643, -0.10511401, -0.16162823,  0.3564654 , -0.16012706,\n",
       "         -0.00236782, -0.1509902 , -0.37796953, -0.0533725 ,  0.17439581,\n",
       "         -0.5535805 , -0.06822695,  0.08719586, -0.44972917,  0.34813207,\n",
       "         -0.00879265,  0.08330636, -0.2573855 , -0.07847515, -0.26723957,\n",
       "          0.291889  ,  0.12709163,  0.33541557,  0.08218297,  0.03298296,\n",
       "          0.30088225, -0.0396797 ,  0.04856601, -0.15871406,  0.1243721 ],\n",
       "        [ 0.2644884 ,  0.38216978,  0.15982692,  0.00430569,  0.15227789,\n",
       "          0.43234682,  0.26704895, -0.13122533, -0.36928666, -0.13226248,\n",
       "         -0.48205987,  0.04834228,  0.17754777,  0.17286645, -0.34951046,\n",
       "         -0.31770065,  0.40757665, -0.18054262, -0.0260059 ,  0.14413413,\n",
       "          0.48896262,  0.31273293, -0.23393402,  0.280305  , -0.38250646,\n",
       "          0.15523781,  0.08915967,  0.28923744, -0.4196516 ,  0.03454235],\n",
       "        [-0.24651863,  0.2771065 , -0.14471462,  0.35437706,  0.43834573,\n",
       "          0.1928337 ,  0.18947469, -0.1427889 , -0.19959615, -0.21878265,\n",
       "         -0.4124634 ,  0.2890446 , -0.06821997,  0.31054792,  0.11935061,\n",
       "         -0.01754006,  0.32726648, -0.13782695,  0.0971493 , -0.06476295,\n",
       "          0.02942048,  0.20774938, -0.03700671, -0.16104051,  0.12527464,\n",
       "          0.06014648,  0.34265062, -0.32968816,  0.26425105, -0.305092  ]],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_11/bias:0' shape=(30,) dtype=float32, numpy=\n",
       " array([ 0.03420044,  0.03854156, -0.01554036,  0.08791047,  0.08198116,\n",
       "         0.06865401,  0.00498175,  0.33145335,  0.01276158,  0.05684473,\n",
       "         0.21329916,  0.05164044, -0.00346859,  0.14758943, -0.01103142,\n",
       "         0.14102669,  0.10244276,  0.05981242, -0.08113382,  0.04726917,\n",
       "         0.02042879,  0.03087302,  0.09376589,  0.08082203,  0.08383019,\n",
       "         0.06059113, -0.04993272,  0.03030548,  0.12775482,  0.02316408],\n",
       "       dtype=float32)>,\n",
       " <tf.Variable 'dense_12/kernel:0' shape=(30, 30) dtype=float32, numpy=\n",
       " array([[ 1.33059323e-01, -2.30917454e-01, -1.66001126e-01,\n",
       "          1.72226205e-02,  2.63162673e-01,  2.54866362e-01,\n",
       "          3.59571069e-01, -1.60310552e-01, -1.04237668e-01,\n",
       "          1.42920867e-01, -3.40748966e-01,  7.92069137e-02,\n",
       "         -2.56170422e-01,  2.10917264e-01,  1.19871110e-01,\n",
       "         -2.65894592e-01, -1.57999024e-01, -2.41827220e-01,\n",
       "          2.22923860e-01,  2.09206030e-01, -3.08588266e-01,\n",
       "          2.77708787e-02,  2.12726399e-01,  1.50741994e-01,\n",
       "          7.18647465e-02, -1.04357675e-01,  1.22395465e-02,\n",
       "         -2.17580125e-01,  2.17851866e-02, -1.55582964e-01],\n",
       "        [-1.13456465e-01, -2.59768516e-01,  1.43934250e-01,\n",
       "          2.68090576e-01, -2.56311558e-02, -5.63263670e-02,\n",
       "          2.95150846e-01,  2.83459634e-01,  2.67759204e-01,\n",
       "         -1.81353182e-01,  1.43939957e-01, -2.59314794e-02,\n",
       "          3.07039976e-01, -2.58305013e-01,  1.42645806e-01,\n",
       "          2.07586274e-01, -4.19942513e-02, -3.05313647e-01,\n",
       "          2.40709409e-02, -6.95252344e-02, -1.61254406e-02,\n",
       "          6.60700575e-02, -5.17222844e-02,  1.78333879e-01,\n",
       "          2.82774091e-01, -1.66158482e-01,  2.47102275e-01,\n",
       "          2.57751584e-01, -1.94948569e-01, -1.95082799e-01],\n",
       "        [ 2.55520821e-01,  1.43164545e-01,  3.46152149e-02,\n",
       "         -6.30325451e-02, -2.40233038e-02, -2.28795022e-01,\n",
       "         -2.94255435e-01,  1.16101928e-01, -4.50830199e-02,\n",
       "          1.89996287e-01,  3.11054718e-02, -3.43069136e-02,\n",
       "          2.00923532e-01,  2.19429225e-01, -2.76959002e-01,\n",
       "          9.22401920e-02, -2.47902155e-01,  2.71713808e-02,\n",
       "          1.29912809e-01,  5.80656379e-02, -2.21541777e-01,\n",
       "          1.12276010e-01,  9.24811363e-02,  5.84342331e-02,\n",
       "          1.46545887e-01, -2.83774763e-01, -2.60938615e-01,\n",
       "          2.62896180e-01,  9.40709468e-03, -2.60616243e-01],\n",
       "        [-8.45323410e-03,  2.12660909e-01,  2.99106468e-03,\n",
       "         -2.69282192e-01, -1.75320074e-01, -8.06434453e-02,\n",
       "          1.08028851e-01, -2.50530183e-01, -1.69696450e-01,\n",
       "          9.79259908e-02, -2.04742432e-01, -9.08001885e-02,\n",
       "          1.97202608e-01, -2.88712263e-01,  4.37970534e-02,\n",
       "         -4.25571054e-02, -3.41056325e-02,  3.93993817e-02,\n",
       "         -2.94994503e-01, -3.07757229e-01,  2.33882844e-01,\n",
       "          1.07154235e-01, -1.63285881e-01, -1.86715111e-01,\n",
       "          3.83977480e-02, -1.97601388e-03, -2.38194898e-01,\n",
       "          1.03370026e-01,  1.51829913e-01, -2.25423142e-01],\n",
       "        [-1.10244237e-01, -1.24794200e-01,  3.73248011e-02,\n",
       "         -1.60089448e-01,  1.90299049e-01,  3.65289371e-03,\n",
       "          2.43096098e-01,  2.98322320e-01, -1.58772506e-02,\n",
       "          4.55018468e-02, -3.84931773e-01,  7.76304025e-03,\n",
       "         -1.06644973e-01,  2.21369378e-02,  5.61116561e-02,\n",
       "         -2.05537185e-01, -3.02534819e-01, -2.90306419e-01,\n",
       "         -1.12007260e-01, -1.68417543e-02, -3.85096706e-02,\n",
       "          4.50230017e-02,  6.70549497e-02,  1.54194906e-01,\n",
       "          2.21909471e-02, -1.22294072e-02, -9.55308974e-02,\n",
       "          1.22928500e-01,  1.91509143e-01, -8.58057439e-02],\n",
       "        [ 1.28903314e-01, -1.28954336e-01, -1.15466807e-02,\n",
       "         -1.42348588e-01,  6.42695725e-02, -2.43496940e-01,\n",
       "         -1.34901732e-01, -1.54348761e-01,  2.92682983e-02,\n",
       "         -3.97124976e-01, -1.25815809e-01,  2.49304116e-01,\n",
       "          3.26854475e-02, -6.61902130e-02, -1.53164968e-01,\n",
       "         -3.17516625e-02,  9.52292979e-02, -6.54761046e-02,\n",
       "         -2.82742560e-01, -1.19042434e-01, -1.96167231e-01,\n",
       "          5.67811839e-02,  1.92335993e-01,  1.78880751e-01,\n",
       "         -2.22495630e-01,  1.68137714e-01,  1.75675184e-01,\n",
       "          3.36593725e-02,  2.00262144e-01, -2.80677844e-02],\n",
       "        [ 1.23212129e-01,  7.80535936e-02,  1.12244658e-01,\n",
       "          2.82239169e-01,  1.56529859e-01, -2.55204678e-01,\n",
       "          2.32622877e-01,  1.02522738e-01, -2.76516855e-01,\n",
       "         -7.61176944e-02, -2.70000249e-01, -2.54599273e-01,\n",
       "         -1.15494974e-01, -1.24647813e-02,  1.83672950e-01,\n",
       "          1.99813366e-01,  9.32673439e-02,  2.75527071e-02,\n",
       "         -2.92831212e-01, -1.11362636e-01, -2.48379841e-01,\n",
       "         -2.75578618e-01, -9.03942734e-02,  1.21481851e-01,\n",
       "         -3.22098792e-01, -8.26514661e-02, -3.43792327e-02,\n",
       "         -1.01794511e-01,  1.93033069e-01, -1.04315065e-01],\n",
       "        [ 1.41071692e-01,  1.27017677e-01,  3.08803073e-03,\n",
       "         -1.06615469e-01,  1.77448895e-02,  3.20388436e-01,\n",
       "         -1.88005477e-01, -8.48133489e-02, -2.85231918e-01,\n",
       "          2.69343644e-01, -5.31899557e-02, -2.77513146e-01,\n",
       "         -1.50036514e-01,  1.46300003e-01,  7.29990527e-02,\n",
       "          6.27325550e-02, -2.27295667e-01,  1.89057469e-01,\n",
       "          3.89222145e-01, -2.86942989e-01,  1.74739346e-01,\n",
       "          2.96680510e-01, -1.10296957e-01,  2.98446000e-01,\n",
       "         -3.51409689e-02, -6.51533604e-02,  2.80872077e-01,\n",
       "         -3.10681790e-01, -1.15432143e-01,  1.51237860e-01],\n",
       "        [ 1.61360234e-01, -9.44180861e-02,  3.05444807e-01,\n",
       "         -1.08379781e-01, -2.94989288e-01, -4.46201488e-02,\n",
       "         -1.90815702e-01, -8.32991861e-03,  1.97592191e-02,\n",
       "          9.20280144e-02, -4.69722971e-02, -9.61283967e-02,\n",
       "         -1.35583788e-01,  1.42603815e-01, -8.57325420e-02,\n",
       "          1.47885442e-01, -1.11352757e-01, -2.12426614e-02,\n",
       "         -1.02743050e-02,  1.82502657e-01, -3.09280753e-01,\n",
       "          1.46246538e-01,  2.79546380e-01,  3.00412655e-01,\n",
       "         -4.71263714e-02, -3.10321033e-01, -2.29617551e-01,\n",
       "         -1.70167454e-03,  6.31476343e-02,  4.73345667e-02],\n",
       "        [-2.35225186e-01,  2.80358493e-01,  2.55087793e-01,\n",
       "         -1.28365174e-01, -1.93041936e-01, -2.02058330e-01,\n",
       "         -2.56969512e-01, -2.46513173e-01,  5.14693372e-02,\n",
       "          2.92753309e-01, -1.11850919e-02, -5.29533848e-02,\n",
       "         -1.75921619e-01, -1.18065462e-01,  1.31504804e-01,\n",
       "         -2.74775177e-01,  9.63612832e-03, -1.16004415e-01,\n",
       "          2.93135196e-01,  2.07226258e-02, -7.36482963e-02,\n",
       "          4.33438011e-02,  9.55797080e-03,  1.94606021e-01,\n",
       "         -3.81998792e-02,  6.71374649e-02, -3.09989393e-01,\n",
       "         -3.08485121e-01, -5.28639778e-02,  2.14679271e-01],\n",
       "        [ 6.01235554e-02, -2.62033314e-01, -1.20449476e-01,\n",
       "          8.26934651e-02, -1.08029440e-01,  2.47835621e-01,\n",
       "         -1.49782389e-01, -2.36773625e-01, -1.35288298e-01,\n",
       "         -1.18125699e-01,  3.66376579e-01,  3.56627465e-03,\n",
       "         -6.93892837e-02,  2.81287491e-01,  2.89845765e-01,\n",
       "          1.60691664e-01, -3.15941900e-01, -2.88346037e-02,\n",
       "          4.33337763e-02,  2.62156188e-01,  2.81165957e-01,\n",
       "          4.32323098e-01,  6.63432404e-02,  1.30855024e-01,\n",
       "          1.13877699e-01, -5.79143576e-02, -1.60559818e-01,\n",
       "         -7.34050870e-02, -2.98394144e-01,  3.89432847e-01],\n",
       "        [-1.00660175e-02, -1.27090290e-01, -1.43393025e-01,\n",
       "         -1.82899252e-01,  2.87673831e-01,  4.21203263e-02,\n",
       "          3.15299392e-01,  2.12194443e-01,  2.21806243e-01,\n",
       "         -1.79356098e-01, -1.53680965e-01,  3.11675906e-01,\n",
       "          1.90531641e-01,  2.22852025e-02,  2.34556179e-02,\n",
       "          1.32690996e-01,  3.05438071e-01, -2.66994208e-01,\n",
       "          2.71578014e-01, -3.45292664e-03,  1.66261531e-02,\n",
       "         -1.88909054e-01, -2.66547024e-01, -1.46627560e-01,\n",
       "          2.36345023e-01,  1.56448767e-01, -3.08001757e-01,\n",
       "         -2.05132470e-01, -1.69744313e-01, -8.89635980e-02],\n",
       "        [ 1.31989583e-01, -6.06580190e-02,  1.50764465e-01,\n",
       "         -2.86433306e-02,  2.03064814e-01, -3.85514013e-02,\n",
       "          1.52697891e-01, -2.69962758e-01, -1.89070985e-01,\n",
       "         -2.53399342e-01, -6.58064261e-02, -2.35173762e-01,\n",
       "         -2.23453477e-01, -4.38873060e-02,  2.25047678e-01,\n",
       "         -1.93229809e-01, -1.83326125e-01,  1.97341070e-01,\n",
       "          4.18317653e-02,  1.75388560e-01,  2.10821941e-01,\n",
       "          3.70138846e-02, -8.62187147e-02,  1.04981720e-01,\n",
       "          1.85868979e-01, -1.05604917e-01,  3.01882029e-01,\n",
       "          9.14280023e-03, -3.04975182e-01, -9.07503068e-02],\n",
       "        [-2.05334842e-01, -1.75046742e-01, -9.73566324e-02,\n",
       "         -1.19761139e-01,  6.17193477e-03,  2.05810443e-02,\n",
       "         -2.08816826e-01,  1.68777138e-01,  1.51092589e-01,\n",
       "         -1.84853245e-02,  2.12584049e-01, -1.61480442e-01,\n",
       "          1.58082545e-01, -2.43934631e-01,  2.48678938e-01,\n",
       "          1.20861471e-01, -2.59073138e-01,  2.42524639e-01,\n",
       "          5.99320652e-03, -6.09111227e-02,  1.76931359e-02,\n",
       "         -2.40371004e-02,  2.86913455e-01,  3.33275311e-02,\n",
       "         -1.34350941e-01,  3.20844710e-01,  1.17081270e-01,\n",
       "         -2.35502765e-01, -1.38153180e-01,  9.19031128e-02],\n",
       "        [-2.83346653e-01, -2.32853353e-01, -4.37510898e-03,\n",
       "         -1.87626947e-03,  1.69460118e-01,  2.45268673e-01,\n",
       "          1.03951395e-01, -2.29688376e-01, -9.66325924e-02,\n",
       "         -3.37227494e-01, -2.07731247e-01, -2.27508351e-01,\n",
       "         -1.93652570e-01,  2.23433271e-01, -2.54733771e-01,\n",
       "          1.53391644e-01, -2.26251453e-01,  1.41723558e-01,\n",
       "          2.30020568e-01,  2.39460349e-01, -3.08844626e-01,\n",
       "         -4.59834561e-02,  2.98311293e-01, -3.54527503e-01,\n",
       "         -4.05473374e-02, -1.78591520e-01,  2.07588255e-01,\n",
       "          9.19514671e-02, -1.02096595e-01,  9.16158929e-02],\n",
       "        [ 1.51077196e-01,  1.92507654e-01,  1.81568801e-01,\n",
       "          1.43700883e-01,  8.48673508e-02, -1.66495573e-02,\n",
       "          2.36618087e-01, -2.11366847e-01,  1.04144029e-01,\n",
       "          7.59134516e-02,  1.52983814e-01, -1.78800046e-01,\n",
       "         -1.61132589e-01, -6.41369121e-03,  1.35090694e-01,\n",
       "          4.39541824e-02, -2.63646096e-01, -2.53168613e-01,\n",
       "          1.18003108e-01, -2.27668136e-01,  6.55110553e-02,\n",
       "          2.13929219e-03, -2.35986859e-02, -9.36878193e-03,\n",
       "         -7.55091533e-02,  1.44471362e-01, -7.77458027e-02,\n",
       "          1.68517679e-01, -4.15573874e-03, -8.05669948e-02],\n",
       "        [-6.62380755e-02, -1.23527475e-01, -3.11514318e-01,\n",
       "          1.31808892e-01, -2.44059309e-01, -1.46294698e-01,\n",
       "          2.52452850e-01, -2.56642001e-03,  1.46939218e-01,\n",
       "         -3.08001451e-02, -2.37708181e-01, -2.18758523e-01,\n",
       "         -2.56666895e-02, -3.03875178e-01, -2.63469756e-01,\n",
       "         -6.16319962e-02,  1.50162533e-01,  8.67706388e-02,\n",
       "         -2.26872623e-01, -6.26355261e-02, -1.77392557e-01,\n",
       "          2.26227731e-01, -1.98949166e-02,  1.08208552e-01,\n",
       "          2.58215010e-01,  2.02059180e-01,  2.04768986e-01,\n",
       "         -3.05098474e-01, -6.27982914e-02,  2.66053863e-02],\n",
       "        [ 2.11799100e-01, -2.59628296e-02, -1.57670632e-01,\n",
       "         -1.52648821e-01, -3.00282776e-01,  7.53791630e-02,\n",
       "          1.27387404e-01,  2.45921195e-01, -3.04364920e-01,\n",
       "          1.85703710e-01,  2.85312295e-01,  2.47783452e-01,\n",
       "          2.12120384e-01,  2.49633968e-01, -6.03667647e-02,\n",
       "         -5.57770580e-02, -1.55667827e-01,  1.80492446e-01,\n",
       "          8.97017792e-02,  2.42194414e-01, -3.51071656e-02,\n",
       "         -1.46947667e-01,  3.55195664e-02, -2.16514453e-01,\n",
       "         -6.91471845e-02,  1.03540033e-01,  6.54027909e-02,\n",
       "          6.58846647e-02,  1.77456751e-01,  3.01010996e-01],\n",
       "        [-1.13669455e-01, -9.03783739e-02,  2.15843439e-01,\n",
       "          1.80709481e-01,  2.33818725e-01, -1.19968526e-01,\n",
       "          1.49896160e-01, -1.51985556e-01, -2.61984289e-01,\n",
       "         -1.68671340e-01, -2.29139596e-01,  1.22616865e-01,\n",
       "          2.45206714e-01,  1.40029326e-01, -6.89850748e-02,\n",
       "         -2.67399281e-01, -1.83615744e-01,  5.50211072e-02,\n",
       "         -7.27663413e-02, -1.72548518e-01, -2.23786265e-01,\n",
       "         -1.05933160e-01, -3.09410036e-01, -2.13855624e-01,\n",
       "          2.90447712e-01,  5.81827052e-02, -1.91281155e-01,\n",
       "         -1.39623374e-01, -2.57145673e-01,  1.22841261e-01],\n",
       "        [ 1.60526216e-01, -1.39924198e-01, -8.59013796e-02,\n",
       "          2.87359834e-01,  2.02363785e-02,  1.94113240e-01,\n",
       "         -2.65032530e-01,  3.83424424e-02, -1.65128335e-01,\n",
       "          2.00527638e-01,  1.90355554e-02,  8.48073810e-02,\n",
       "         -1.92771509e-01, -1.14265308e-01,  2.47898072e-01,\n",
       "         -1.94028541e-01, -1.35464638e-01,  1.01648420e-01,\n",
       "          2.05978498e-01, -1.07446037e-01, -1.34435212e-02,\n",
       "         -2.23551512e-01, -2.15033051e-02,  2.45687947e-01,\n",
       "          2.20179498e-01,  3.65647487e-02, -1.34139191e-02,\n",
       "          4.49173115e-02,  6.04586862e-02,  2.53004551e-01],\n",
       "        [-3.11914355e-01, -2.56982863e-01,  1.69214308e-01,\n",
       "         -3.07992429e-01, -1.79596618e-01, -1.71429202e-01,\n",
       "          2.02201366e-01,  6.61510527e-02,  8.31457600e-02,\n",
       "         -2.52562791e-01,  6.57782629e-02, -2.16698915e-01,\n",
       "          9.73367020e-02,  2.51490921e-02,  1.72997758e-01,\n",
       "         -2.09751904e-01, -2.96622574e-01,  1.00210167e-01,\n",
       "         -2.78243959e-01,  1.54820234e-01, -2.69042607e-02,\n",
       "          2.07320750e-01, -2.68919706e-01,  2.27755815e-01,\n",
       "         -1.29625767e-01, -2.52949327e-01, -3.65138389e-02,\n",
       "          2.32703805e-01,  2.31598392e-01, -1.59215480e-02],\n",
       "        [-8.83128345e-02, -1.89408675e-01,  1.03725426e-01,\n",
       "         -1.43322334e-01,  1.40406728e-01, -1.98639080e-01,\n",
       "          2.56096333e-01,  1.51203573e-01,  2.36578226e-01,\n",
       "          1.12126254e-01, -1.07174225e-01,  1.54971080e-02,\n",
       "          6.91907629e-02,  2.87697017e-01,  1.82837807e-02,\n",
       "          5.31809814e-02, -3.02919298e-01,  1.89809233e-01,\n",
       "          9.80266407e-02, -2.16891885e-01, -1.41810521e-01,\n",
       "          3.61211561e-02, -1.42648583e-02, -2.80810654e-01,\n",
       "          1.54165909e-01, -1.25811240e-02,  2.88283020e-01,\n",
       "         -4.62340079e-02, -1.25321448e-01,  1.48386955e-01],\n",
       "        [-1.43875465e-01,  2.68589668e-02, -1.65172666e-01,\n",
       "          1.73769236e-01, -4.46568755e-03,  2.21429497e-01,\n",
       "          2.17733592e-01,  5.34993969e-02, -3.00599188e-01,\n",
       "         -5.92226647e-02,  1.03113703e-01, -1.14571892e-01,\n",
       "          9.82545316e-02, -7.61712193e-02,  2.66409159e-01,\n",
       "          1.81254268e-01, -1.93680540e-01,  2.87137121e-01,\n",
       "          1.53938308e-01,  8.41783807e-02, -1.83744803e-01,\n",
       "          1.75027475e-01, -1.14984795e-01, -2.71452188e-01,\n",
       "         -2.24651713e-02, -1.18044935e-01,  1.91413313e-01,\n",
       "         -3.22250314e-02,  9.87427011e-02, -8.08810592e-02],\n",
       "        [-3.78858075e-02,  8.82798166e-04,  2.13493451e-01,\n",
       "          1.53423682e-01, -2.39510313e-01,  1.56995162e-01,\n",
       "         -3.08629274e-01,  3.17198545e-01,  2.77778864e-01,\n",
       "          1.23704575e-01, -3.73960063e-02,  1.80587366e-01,\n",
       "         -1.04066566e-01,  2.45421693e-01, -1.31202666e-02,\n",
       "         -5.97887374e-02, -2.30131283e-01,  2.05153003e-01,\n",
       "          2.48105794e-01, -2.71642417e-01, -2.95275211e-01,\n",
       "          1.09914184e-01, -3.13297629e-01, -1.94109574e-01,\n",
       "         -2.33314633e-01, -2.98973024e-01, -2.17716917e-01,\n",
       "          2.68204749e-01, -2.73075551e-02, -1.45819083e-01],\n",
       "        [-9.75797232e-03,  4.33512684e-03,  2.48165995e-01,\n",
       "         -2.98670623e-02,  2.52056181e-01, -1.51204597e-02,\n",
       "         -6.57535791e-02, -8.27652141e-02, -1.93638429e-01,\n",
       "          4.73507168e-03, -6.81837946e-02,  1.89927191e-01,\n",
       "         -1.72278844e-02,  2.20069170e-01,  2.07822453e-02,\n",
       "         -1.62722439e-01,  1.66392639e-01, -1.81723297e-01,\n",
       "         -1.38389962e-02, -2.16368452e-01,  9.88761857e-02,\n",
       "          1.98609065e-02,  1.26498699e-01,  3.11375558e-01,\n",
       "         -1.00010842e-01,  8.95607154e-05,  3.04255217e-01,\n",
       "         -1.83491737e-01, -2.31545895e-01, -7.33436793e-02],\n",
       "        [-9.91049856e-02, -2.75601093e-02,  8.88273567e-02,\n",
       "         -2.81124055e-01, -1.95086867e-01,  1.89984620e-01,\n",
       "          2.69015789e-01, -2.98840124e-02,  1.35771483e-02,\n",
       "         -2.86707938e-01,  2.72163630e-01, -2.35552043e-01,\n",
       "         -1.20798178e-01, -1.95306435e-01,  3.01477090e-02,\n",
       "          1.47053808e-01,  2.47758910e-01,  2.88682610e-01,\n",
       "          1.78917721e-01,  1.17435955e-01,  2.40409244e-02,\n",
       "         -4.90843095e-02, -2.96892393e-02,  1.52339498e-02,\n",
       "         -4.99368422e-02, -2.43618697e-01,  2.63019681e-01,\n",
       "          4.38525639e-02,  2.24612474e-01, -2.54062802e-01],\n",
       "        [ 1.66484758e-01, -1.70823392e-02,  3.37844901e-02,\n",
       "         -2.17497051e-01,  1.61682546e-01, -9.54204947e-02,\n",
       "         -3.37394215e-02, -2.08901167e-01, -2.35549107e-01,\n",
       "          1.52638853e-01,  6.48943037e-02,  2.22875580e-01,\n",
       "          2.40643919e-01, -1.51826203e-01, -3.17998111e-01,\n",
       "          1.46720231e-01,  3.10333699e-01, -2.79064421e-02,\n",
       "         -2.86078691e-01,  3.73477116e-02, -9.19787884e-02,\n",
       "         -3.00467134e-01,  1.27968028e-01, -3.25155318e-01,\n",
       "          1.80808350e-01, -1.79247409e-01,  1.54365569e-01,\n",
       "          3.00108343e-01,  9.72232968e-02,  2.03641370e-01],\n",
       "        [ 1.15145631e-01, -2.16340180e-03, -1.17415264e-01,\n",
       "         -1.24838278e-01,  3.40426490e-02,  8.67125914e-02,\n",
       "          1.50392950e-01,  2.71267980e-01, -2.78314918e-01,\n",
       "         -1.76951230e-01,  1.58987492e-02,  2.35884249e-01,\n",
       "          2.30692089e-01,  1.80455938e-01,  2.84014463e-01,\n",
       "         -2.47165456e-01, -8.37915316e-02,  1.63903058e-01,\n",
       "          6.77139163e-02, -1.57895297e-01, -2.67785043e-01,\n",
       "          1.87014472e-02, -2.06721291e-01,  7.57387280e-03,\n",
       "          2.36658156e-01, -2.47122332e-01,  1.91489549e-03,\n",
       "         -2.16187313e-01,  2.77029097e-01, -9.82052088e-02],\n",
       "        [ 4.24435362e-02, -1.03674009e-01, -1.19707240e-02,\n",
       "          2.43999213e-01,  2.98543483e-01,  1.09311685e-01,\n",
       "          1.64952189e-01, -1.06992181e-02, -1.88823357e-01,\n",
       "          2.01067761e-01,  1.06391571e-01,  8.73636156e-02,\n",
       "         -1.41198620e-01,  1.03700213e-01, -2.23401323e-01,\n",
       "         -5.06677032e-02,  2.42568806e-01, -1.11410066e-01,\n",
       "         -1.74396560e-01, -2.97474951e-01,  1.86395586e-01,\n",
       "          2.49272048e-01,  7.62075335e-02,  1.28807351e-01,\n",
       "          1.78144485e-01,  2.28386924e-01, -2.36928880e-01,\n",
       "         -2.26701722e-01, -1.76268518e-01,  1.12841211e-01],\n",
       "        [-6.78799748e-02, -7.88965821e-02,  1.36402279e-01,\n",
       "         -3.17500383e-01, -2.43423715e-01, -9.23381671e-02,\n",
       "         -1.26931235e-01,  1.81174964e-01,  3.74938771e-02,\n",
       "          1.98588163e-01,  2.56812215e-01,  1.69474989e-01,\n",
       "          4.45337035e-02,  5.33001088e-02, -2.06994802e-01,\n",
       "         -1.83413729e-01,  2.77655959e-01, -1.61569208e-01,\n",
       "         -9.10344273e-02, -3.65557410e-02, -4.08739671e-02,\n",
       "         -3.11079234e-01,  8.64954963e-02, -1.92839146e-01,\n",
       "         -1.93411857e-01,  4.40514758e-02,  2.76118994e-01,\n",
       "         -1.72896162e-01,  6.73317984e-02, -2.50384927e-01]], dtype=float32)>,\n",
       " <tf.Variable 'dense_12/bias:0' shape=(30,) dtype=float32, numpy=\n",
       " array([ 1.3825460e-01, -7.6920800e-02, -3.3787437e-02, -6.3570708e-02,\n",
       "         2.8581228e-02,  1.6789900e-01,  3.7582476e-02,  1.7787598e-02,\n",
       "         3.6495852e-03,  2.0347242e-01,  2.7052826e-01, -1.4737501e-02,\n",
       "         1.7371934e-02,  1.1437261e-01,  1.5946414e-01,  6.7086294e-02,\n",
       "        -3.7642574e-04,  9.8958807e-03,  2.5480947e-01, -6.5684766e-02,\n",
       "         2.3106826e-02,  2.4772076e-01,  1.6265528e-02,  1.6443269e-01,\n",
       "        -7.3151082e-02,  5.0582848e-02,  9.0249926e-02, -5.7050864e-05,\n",
       "         5.0203122e-02,  1.6935398e-01], dtype=float32)>,\n",
       " <tf.Variable 'dense_13/kernel:0' shape=(30, 1) dtype=float32, numpy=\n",
       " array([[ 0.4071494 ],\n",
       "        [-0.36837128],\n",
       "        [-0.10272145],\n",
       "        [-0.1233189 ],\n",
       "        [-0.04614791],\n",
       "        [ 0.42770177],\n",
       "        [-0.34217218],\n",
       "        [-0.45381215],\n",
       "        [ 0.32548946],\n",
       "        [ 0.44446126],\n",
       "        [ 0.71011025],\n",
       "        [-0.21357545],\n",
       "        [ 0.20305957],\n",
       "        [ 0.31533906],\n",
       "        [ 0.33285493],\n",
       "        [ 0.19729747],\n",
       "        [ 0.00098118],\n",
       "        [ 0.05526449],\n",
       "        [ 0.4846302 ],\n",
       "        [-0.24679728],\n",
       "        [ 0.12639   ],\n",
       "        [ 0.40014693],\n",
       "        [ 0.07118005],\n",
       "        [ 0.32628965],\n",
       "        [-0.18765755],\n",
       "        [ 0.22788234],\n",
       "        [ 0.23556846],\n",
       "        [ 0.3909062 ],\n",
       "        [-0.4882183 ],\n",
       "        [ 0.61991006]], dtype=float32)>,\n",
       " <tf.Variable 'dense_13/bias:0' shape=(1,) dtype=float32, numpy=array([0.6379125], dtype=float32)>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val))\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "model.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c54ea3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b407569",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e77e1101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x203ffdbcc40>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(\"my_keras_weights.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca4cc1f",
   "metadata": {},
   "source": [
    "# Callbacks during Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc12b52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6d5772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a535046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b9c7b370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.9071 - val_loss: 0.8546\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7107 - val_loss: 0.6505\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6347 - val_loss: 0.6063\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5853 - val_loss: 0.5667\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5475 - val_loss: 0.5236\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5156 - val_loss: 0.4969\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4905 - val_loss: 0.4821\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4707 - val_loss: 0.4488\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4544 - val_loss: 0.4322\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4417 - val_loss: 0.4202\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4324 - val_loss: 0.4122\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4045\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4182 - val_loss: 0.4009\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4129 - val_loss: 0.3957\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4082 - val_loss: 0.3935\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4043 - val_loss: 0.3885\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4008 - val_loss: 0.3898\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3976 - val_loss: 0.3886\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3940 - val_loss: 0.3856\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3919 - val_loss: 0.3935\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x203fd910f40>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "checkpoint_cb  = ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5b242f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.3890 - val_loss: 0.3839\n",
      "Epoch 2/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3867 - val_loss: 0.3923\n",
      "Epoch 3/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3846 - val_loss: 0.3884\n",
      "Epoch 4/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3822 - val_loss: 0.3852\n",
      "Epoch 5/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3806 - val_loss: 0.3758\n",
      "Epoch 6/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3785 - val_loss: 0.3782\n",
      "Epoch 7/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3769 - val_loss: 0.3757\n",
      "Epoch 8/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3753 - val_loss: 0.3677\n",
      "Epoch 9/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3737 - val_loss: 0.3729\n",
      "Epoch 10/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3722 - val_loss: 0.3749\n",
      "Epoch 11/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3712 - val_loss: 0.3654\n",
      "Epoch 12/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3696 - val_loss: 0.3706\n",
      "Epoch 13/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3683 - val_loss: 0.3715\n",
      "Epoch 14/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3671 - val_loss: 0.3631\n",
      "Epoch 15/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3660 - val_loss: 0.3647\n",
      "Epoch 16/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3648 - val_loss: 0.3591\n",
      "Epoch 17/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3637 - val_loss: 0.3643\n",
      "Epoch 18/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3628 - val_loss: 0.3620\n",
      "Epoch 19/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3613 - val_loss: 0.3608\n",
      "Epoch 20/20\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3607 - val_loss: 0.3685\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3889979422092438,\n",
       " 0.38672277331352234,\n",
       " 0.38456475734710693,\n",
       " 0.38215649127960205,\n",
       " 0.38061270117759705,\n",
       " 0.37850093841552734,\n",
       " 0.37694838643074036,\n",
       " 0.37531232833862305,\n",
       " 0.37372007966041565,\n",
       " 0.37217971682548523,\n",
       " 0.3711552917957306,\n",
       " 0.3696193993091583,\n",
       " 0.3682784140110016,\n",
       " 0.36707738041877747,\n",
       " 0.36598703265190125,\n",
       " 0.3647521436214447,\n",
       " 0.3636924922466278,\n",
       " 0.3628472089767456,\n",
       " 0.3613266944885254,\n",
       " 0.36070433259010315]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), callbacks=[early_stopping_cb] )\n",
    "history.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190264f7",
   "metadata": {},
   "source": [
    "# TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ecfe884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b41bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "015ecae3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.\\\\my_logs\\\\run_2023_05_03-12_14_02'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "run_logdir = get_run_logdir()\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b5e7cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc574377",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=[8]),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18c1a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6eef9ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.1943 - val_loss: 3.1206\n",
      "Epoch 2/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8165 - val_loss: 0.8137\n",
      "Epoch 3/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6794 - val_loss: 0.9006\n",
      "Epoch 4/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6309 - val_loss: 0.5748\n",
      "Epoch 5/30\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.5903 - val_loss: 0.5533\n",
      "Epoch 6/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5575 - val_loss: 0.6372\n",
      "Epoch 7/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5334 - val_loss: 0.5962\n",
      "Epoch 8/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5129 - val_loss: 0.5833\n",
      "Epoch 9/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4917 - val_loss: 0.5820\n",
      "Epoch 10/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4766 - val_loss: 0.4693\n",
      "Epoch 11/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4627 - val_loss: 0.5487\n",
      "Epoch 12/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4514 - val_loss: 0.5288\n",
      "Epoch 13/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4427 - val_loss: 0.4241\n",
      "Epoch 14/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4333 - val_loss: 0.4117\n",
      "Epoch 15/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4264 - val_loss: 0.4113\n",
      "Epoch 16/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4204 - val_loss: 0.3956\n",
      "Epoch 17/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4150 - val_loss: 0.4434\n",
      "Epoch 18/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4107 - val_loss: 0.3953\n",
      "Epoch 19/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4059 - val_loss: 0.3848\n",
      "Epoch 20/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4023 - val_loss: 0.4590\n",
      "Epoch 21/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3993 - val_loss: 0.3799\n",
      "Epoch 22/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3957 - val_loss: 0.4433\n",
      "Epoch 23/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3929 - val_loss: 0.3816\n",
      "Epoch 24/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3900 - val_loss: 0.4403\n",
      "Epoch 25/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3871 - val_loss: 0.4072\n",
      "Epoch 26/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3847 - val_loss: 0.4083\n",
      "Epoch 27/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3826 - val_loss: 0.3655\n",
      "Epoch 28/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3802 - val_loss: 0.4219\n",
      "Epoch 29/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3782 - val_loss: 0.3612\n",
      "Epoch 30/30\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3760 - val_loss: 0.4570\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras.model.h5\", save_best_only=True)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                   callbacks=[tensorboard_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c9bae",
   "metadata": {},
   "source": [
    "# Fine-Tuning NN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dc9c0d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fa4efcc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[8]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for i in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    optimizer = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(loss=\"mse\", optimizer=optimizer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f88f86c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c8d90f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nick\\AppData\\Local\\Temp\\ipykernel_6492\\2375457609.py:1: DeprecationWarning: KerasRegressor is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  ker_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 1s 1ms/step - loss: 4.9296 - val_loss: 7.6257\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.7217 - val_loss: 7.0123\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.5052 - val_loss: 6.4344\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 4.2910 - val_loss: 5.9000\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 4.0824 - val_loss: 5.4128\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.8820 - val_loss: 4.9676\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.6898 - val_loss: 4.5631\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.5055 - val_loss: 4.1983\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 3.3276 - val_loss: 3.8647\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 3.1547 - val_loss: 3.5588\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.9858 - val_loss: 3.2804\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 2.8197 - val_loss: 3.0207\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.6569 - val_loss: 2.7815\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.4976 - val_loss: 2.5597\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 2.3429 - val_loss: 2.3553\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 2.1942 - val_loss: 2.1680\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 2.0532 - val_loss: 1.9978\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.9210 - val_loss: 1.8440\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.7980 - val_loss: 1.7058\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.6852 - val_loss: 1.5828\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 1.5823 - val_loss: 1.4740\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 1.4885 - val_loss: 1.3777\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.4027 - val_loss: 1.2921\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 975us/step - loss: 1.3239 - val_loss: 1.2150\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2515 - val_loss: 1.1457\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1849 - val_loss: 1.0835\n",
      "Epoch 27/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.1239 - val_loss: 1.0270\n",
      "Epoch 28/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 1.0679 - val_loss: 0.9754\n",
      "Epoch 29/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0170 - val_loss: 0.9284\n",
      "Epoch 30/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.9709 - val_loss: 0.8860\n",
      "Epoch 31/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.9293 - val_loss: 0.8478\n",
      "Epoch 32/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.8919 - val_loss: 0.8134\n",
      "Epoch 33/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.8583 - val_loss: 0.7827\n",
      "Epoch 34/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8281 - val_loss: 0.7552\n",
      "Epoch 35/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.8010 - val_loss: 0.7305\n",
      "Epoch 36/100\n",
      "363/363 [==============================] - 0s 982us/step - loss: 0.7766 - val_loss: 0.7084\n",
      "Epoch 37/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7546 - val_loss: 0.6886\n",
      "Epoch 38/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.7350 - val_loss: 0.6708\n",
      "Epoch 39/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.7174 - val_loss: 0.6550\n",
      "Epoch 40/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.7017 - val_loss: 0.6410\n",
      "Epoch 41/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6878 - val_loss: 0.6286\n",
      "Epoch 42/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.6755 - val_loss: 0.6176\n",
      "Epoch 43/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.6647 - val_loss: 0.6079\n",
      "Epoch 44/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.6551 - val_loss: 0.5993\n",
      "Epoch 45/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.6466 - val_loss: 0.5918\n",
      "Epoch 46/100\n",
      "363/363 [==============================] - 0s 978us/step - loss: 0.6391 - val_loss: 0.5852\n",
      "Epoch 47/100\n",
      "363/363 [==============================] - 0s 988us/step - loss: 0.6325 - val_loss: 0.5793\n",
      "Epoch 48/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6266 - val_loss: 0.5741\n",
      "Epoch 49/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6214 - val_loss: 0.5695\n",
      "Epoch 50/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.6167 - val_loss: 0.5654\n",
      "Epoch 51/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.6125 - val_loss: 0.5616\n",
      "Epoch 52/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6087 - val_loss: 0.5583\n",
      "Epoch 53/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.6052 - val_loss: 0.5552\n",
      "Epoch 54/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6020 - val_loss: 0.5524\n",
      "Epoch 55/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5992 - val_loss: 0.5499\n",
      "Epoch 56/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.5965 - val_loss: 0.5475\n",
      "Epoch 57/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5940 - val_loss: 0.5453\n",
      "Epoch 58/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5917 - val_loss: 0.5433\n",
      "Epoch 59/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5896 - val_loss: 0.5414\n",
      "Epoch 60/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5876 - val_loss: 0.5396\n",
      "Epoch 61/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.5857 - val_loss: 0.5379\n",
      "Epoch 62/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.5839 - val_loss: 0.5363\n",
      "Epoch 63/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.5822 - val_loss: 0.5347\n",
      "Epoch 64/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5806 - val_loss: 0.5333\n",
      "Epoch 65/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5790 - val_loss: 0.5319\n",
      "Epoch 66/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5775 - val_loss: 0.5305\n",
      "Epoch 67/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 0.5292\n",
      "Epoch 68/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5747 - val_loss: 0.5279\n",
      "Epoch 69/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.5733 - val_loss: 0.5267\n",
      "Epoch 70/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.5720 - val_loss: 0.5255\n",
      "Epoch 71/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.5708 - val_loss: 0.5244\n",
      "Epoch 72/100\n",
      "363/363 [==============================] - 0s 999us/step - loss: 0.5695 - val_loss: 0.5232\n",
      "Epoch 73/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5683 - val_loss: 0.5221\n",
      "Epoch 74/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5671 - val_loss: 0.5210\n",
      "Epoch 75/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5660 - val_loss: 0.5200\n",
      "Epoch 76/100\n",
      "363/363 [==============================] - 0s 996us/step - loss: 0.5649 - val_loss: 0.5189\n",
      "Epoch 77/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.5637 - val_loss: 0.5179\n",
      "Epoch 78/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.5627 - val_loss: 0.5169\n",
      "Epoch 79/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5616 - val_loss: 0.5160\n",
      "Epoch 80/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5606 - val_loss: 0.5150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.5595 - val_loss: 0.5140\n",
      "Epoch 82/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5585 - val_loss: 0.5131\n",
      "Epoch 83/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5575 - val_loss: 0.5122\n",
      "Epoch 84/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5565 - val_loss: 0.5113\n",
      "Epoch 85/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5555 - val_loss: 0.5103\n",
      "Epoch 86/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5545 - val_loss: 0.5095\n",
      "Epoch 87/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5536 - val_loss: 0.5086\n",
      "Epoch 88/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5526 - val_loss: 0.5077\n",
      "Epoch 89/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5517 - val_loss: 0.5068\n",
      "Epoch 90/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5508 - val_loss: 0.5060\n",
      "Epoch 91/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5499 - val_loss: 0.5052\n",
      "Epoch 92/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.5043\n",
      "Epoch 93/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.5481 - val_loss: 0.5035\n",
      "Epoch 94/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5472 - val_loss: 0.5027\n",
      "Epoch 95/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5463 - val_loss: 0.5019\n",
      "Epoch 96/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5454 - val_loss: 0.5011\n",
      "Epoch 97/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5446 - val_loss: 0.5003\n",
      "Epoch 98/100\n",
      "363/363 [==============================] - 0s 1000us/step - loss: 0.5437 - val_loss: 0.4995\n",
      "Epoch 99/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5429 - val_loss: 0.4988\n",
      "Epoch 100/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5421 - val_loss: 0.4980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'build_fn': <function __main__.build_model(n_hidden=1, n_neurons=30, learning_rate=0.003, input_shape=[8])>}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ker_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "ker_reg.fit(X_train, y_train, epochs=100,\n",
    "           validation_data=(X_val, y_val),\n",
    "           callbacks=[keras.callbacks.EarlyStopping(patience=10)])\n",
    "ker_reg.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95533173",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e873824e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4977 - val_loss: 1.0742\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7445 - val_loss: 0.5493\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5760 - val_loss: 0.5070\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5417 - val_loss: 0.4826\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5185 - val_loss: 0.4651\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5034 - val_loss: 0.4542\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4914 - val_loss: 0.4471\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4855 - val_loss: 0.4461\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4814 - val_loss: 0.4418\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.4357\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4766 - val_loss: 0.4406\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.4370\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4719 - val_loss: 0.4332\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4734 - val_loss: 0.4343\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4319\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4719 - val_loss: 0.4321\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4356\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4708 - val_loss: 0.4321\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4321\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4712 - val_loss: 0.4316\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4711 - val_loss: 0.4338\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4688 - val_loss: 0.4321\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4703 - val_loss: 0.4378\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4706 - val_loss: 0.4353\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.4338\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4328\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4709 - val_loss: 0.4330\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4693 - val_loss: 0.4316\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.4324\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4702 - val_loss: 0.4323\n",
      "121/121 [==============================] - 0s 667us/step - loss: 0.4775\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   8.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7367 - val_loss: 3.2506\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6407 - val_loss: 0.5147\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5400 - val_loss: 0.4835\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5146 - val_loss: 0.4656\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4978 - val_loss: 0.4533\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4865 - val_loss: 0.4454\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4801 - val_loss: 0.4418\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4758 - val_loss: 0.4382\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4727 - val_loss: 0.4362\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4715 - val_loss: 0.4342\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4705 - val_loss: 0.4339\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4692 - val_loss: 0.4339\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4690 - val_loss: 0.4328\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4694 - val_loss: 0.4332\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4321\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4684 - val_loss: 0.4318\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4325\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4689 - val_loss: 0.4316\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4322\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4677 - val_loss: 0.4324\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4681 - val_loss: 0.4321\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4321\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4678 - val_loss: 0.4324\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4676 - val_loss: 0.4321\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4319\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4317\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4670 - val_loss: 0.4326\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4687 - val_loss: 0.4311\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4664 - val_loss: 0.4333\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4683 - val_loss: 0.4320\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4316\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4684 - val_loss: 0.4315\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4668 - val_loss: 0.4334\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4680 - val_loss: 0.4316\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4316\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4675 - val_loss: 0.4315\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4671 - val_loss: 0.4324\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4673 - val_loss: 0.4315\n",
      "121/121 [==============================] - 0s 663us/step - loss: 0.4778\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=  10.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 2.7664 - val_loss: 0.9109\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7009 - val_loss: 0.5510\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5751 - val_loss: 0.5094\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5412 - val_loss: 0.4849\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5203 - val_loss: 0.4672\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5057 - val_loss: 0.4568\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4966 - val_loss: 0.4488\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4923 - val_loss: 0.4430\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4872 - val_loss: 0.4407\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4820 - val_loss: 0.4371\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4836 - val_loss: 0.4363\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4810 - val_loss: 0.4382\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4764 - val_loss: 0.4345\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4807 - val_loss: 0.4342\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4794 - val_loss: 0.4331\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4765 - val_loss: 0.4324\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4772 - val_loss: 0.4328\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4770 - val_loss: 0.4344\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4779 - val_loss: 0.4330\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4766 - val_loss: 0.4321\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4775 - val_loss: 0.4322\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4770 - val_loss: 0.4323\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4781 - val_loss: 0.4329\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4742 - val_loss: 0.4329\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4765 - val_loss: 0.4323\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4740 - val_loss: 0.4334\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4749 - val_loss: 0.4325\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4762 - val_loss: 0.4370\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4745 - val_loss: 0.4329\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4786 - val_loss: 0.4327\n",
      "121/121 [==============================] - 0s 750us/step - loss: 0.4639\n",
      "[CV] END learning_rate=0.022174573948353458, n_hidden=1, n_neurons=4; total time=   8.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0696 - val_loss: 5.4131\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6035 - val_loss: 5.0001\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9180 - val_loss: 4.3428\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0405 - val_loss: 3.4659\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1720 - val_loss: 2.6293\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5530 - val_loss: 2.0602\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2248 - val_loss: 1.7141\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0529 - val_loss: 1.4617\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9445 - val_loss: 1.2857\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8809 - val_loss: 1.1618\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8411 - val_loss: 1.0686\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8114 - val_loss: 0.9964\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7862 - val_loss: 0.9362\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7613 - val_loss: 0.8861\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7352 - val_loss: 0.8398\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7101 - val_loss: 0.8027\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6922 - val_loss: 0.7757\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6786 - val_loss: 0.7541\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6673 - val_loss: 0.7357\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6576 - val_loss: 0.7193\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6490 - val_loss: 0.7050\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6412 - val_loss: 0.6926\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6342 - val_loss: 0.6814\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6278 - val_loss: 0.6714\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6222 - val_loss: 0.6624\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6169 - val_loss: 0.6544\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.6472\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6079 - val_loss: 0.6406\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6038 - val_loss: 0.6346\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6002 - val_loss: 0.6292\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5969 - val_loss: 0.6244\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5937 - val_loss: 0.6201\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5909 - val_loss: 0.6159\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5883 - val_loss: 0.6122\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5858 - val_loss: 0.6088\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5836 - val_loss: 0.6057\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5815 - val_loss: 0.6026\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5795 - val_loss: 0.6000\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5777 - val_loss: 0.5975\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5761 - val_loss: 0.5955\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5745 - val_loss: 0.5937\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5730 - val_loss: 0.5920\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5716 - val_loss: 0.5904\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5703 - val_loss: 0.5890\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - val_loss: 0.5878\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5678 - val_loss: 0.5868\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5668 - val_loss: 0.5860\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5657 - val_loss: 0.5855\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5647 - val_loss: 0.5850\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5638 - val_loss: 0.5847\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5629 - val_loss: 0.5845\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5620 - val_loss: 0.5843\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5611 - val_loss: 0.5844\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5603 - val_loss: 0.5845\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5595 - val_loss: 0.5849\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5587 - val_loss: 0.5849\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5580 - val_loss: 0.5852\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5573 - val_loss: 0.5855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5566 - val_loss: 0.5856\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5559 - val_loss: 0.5857\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5553 - val_loss: 0.5860\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5547 - val_loss: 0.5864\n",
      "121/121 [==============================] - 0s 717us/step - loss: 0.5640\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  19.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.1847 - val_loss: 5.5763\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7008 - val_loss: 5.3659\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9727 - val_loss: 5.0762\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0753 - val_loss: 4.7744\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2827 - val_loss: 4.5399\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7819 - val_loss: 4.3022\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4943 - val_loss: 3.9934\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3203 - val_loss: 3.6450\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2135 - val_loss: 3.3056\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1381 - val_loss: 2.9934\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0682 - val_loss: 2.7054\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0127 - val_loss: 2.4644\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9676 - val_loss: 2.2672\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9283 - val_loss: 2.0913\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8954 - val_loss: 1.9391\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8744 - val_loss: 1.8083\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8592 - val_loss: 1.6950\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8472 - val_loss: 1.5962\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8368 - val_loss: 1.5153\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8277 - val_loss: 1.4503\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8196 - val_loss: 1.3915\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8123 - val_loss: 1.3507\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8055 - val_loss: 1.3162\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7994 - val_loss: 1.2848\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7938 - val_loss: 1.2562\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7887 - val_loss: 1.2301\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7840 - val_loss: 1.2067\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7797 - val_loss: 1.1846\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7756 - val_loss: 1.1654\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7720 - val_loss: 1.1469\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7686 - val_loss: 1.1302\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7655 - val_loss: 1.1153\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7626 - val_loss: 1.1019\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7599 - val_loss: 1.0900\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7574 - val_loss: 1.0789\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7551 - val_loss: 1.0683\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7529 - val_loss: 1.0590\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7508 - val_loss: 1.0498\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7489 - val_loss: 1.0418\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7471 - val_loss: 1.0346\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7454 - val_loss: 1.0281\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7439 - val_loss: 1.0222\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7423 - val_loss: 1.0162\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7410 - val_loss: 1.0112\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7396 - val_loss: 1.0066\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7384 - val_loss: 1.0019\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7372 - val_loss: 0.9981\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7360 - val_loss: 0.9948\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7350 - val_loss: 0.9918\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7339 - val_loss: 0.9888\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7329 - val_loss: 0.9860\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7320 - val_loss: 0.9840\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7310 - val_loss: 0.9818\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7301 - val_loss: 0.9802\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7292 - val_loss: 0.9786\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7284 - val_loss: 0.9775\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7276 - val_loss: 0.9768\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7268 - val_loss: 0.9769\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7260 - val_loss: 0.9769\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7252 - val_loss: 0.9767\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7246 - val_loss: 0.9774\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7239 - val_loss: 0.9780\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7232 - val_loss: 0.9784\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7226 - val_loss: 0.9793\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7220 - val_loss: 0.9805\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7214 - val_loss: 0.9816\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7208 - val_loss: 0.9824\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7202 - val_loss: 0.9838\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7197 - val_loss: 0.9853\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7191 - val_loss: 0.9864\n",
      "121/121 [==============================] - 0s 700us/step - loss: 0.7317\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  21.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.2275 - val_loss: 5.2904\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7346 - val_loss: 4.8478\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9633 - val_loss: 4.1339\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9753 - val_loss: 3.2469\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0306 - val_loss: 2.3610\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4044 - val_loss: 1.7939\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0791 - val_loss: 1.4552\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9264 - val_loss: 1.2387\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8320 - val_loss: 1.0840\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7722 - val_loss: 0.9877\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7351 - val_loss: 0.9206\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7090 - val_loss: 0.8737\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6884 - val_loss: 0.8348\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6707 - val_loss: 0.8004\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6466 - val_loss: 0.7499\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6084 - val_loss: 0.7083\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5859 - val_loss: 0.6799\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - val_loss: 0.6577\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5604 - val_loss: 0.6387\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5511 - val_loss: 0.6224\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5429 - val_loss: 0.6080\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5356 - val_loss: 0.5952\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5291 - val_loss: 0.5838\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5230 - val_loss: 0.5739\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5176 - val_loss: 0.5647\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5125 - val_loss: 0.5566\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5079 - val_loss: 0.5492\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5037 - val_loss: 0.5426\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4997 - val_loss: 0.5367\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4962 - val_loss: 0.5311\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4928 - val_loss: 0.5263\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4897 - val_loss: 0.5219\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4869 - val_loss: 0.5178\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4842 - val_loss: 0.5144\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4818 - val_loss: 0.5111\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4794 - val_loss: 0.5084\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4773 - val_loss: 0.5059\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4753 - val_loss: 0.5036\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4733 - val_loss: 0.5017\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4715 - val_loss: 0.5001\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4698 - val_loss: 0.4988\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4682 - val_loss: 0.4975\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4667 - val_loss: 0.4961\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4653 - val_loss: 0.4951\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4638 - val_loss: 0.4941\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4625 - val_loss: 0.4933\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4612 - val_loss: 0.4925\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4600 - val_loss: 0.4920\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4588 - val_loss: 0.4918\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4578 - val_loss: 0.4917\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4566 - val_loss: 0.4917\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4557 - val_loss: 0.4917\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4546 - val_loss: 0.4916\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4538 - val_loss: 0.4914\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4528 - val_loss: 0.4916\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4519 - val_loss: 0.4927\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4511 - val_loss: 0.4941\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4503 - val_loss: 0.4947\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4495 - val_loss: 0.4951\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4488 - val_loss: 0.4950\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4480 - val_loss: 0.4953\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4473 - val_loss: 0.4965\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4467 - val_loss: 0.4968\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.4460 - val_loss: 0.4972\n",
      "121/121 [==============================] - 0s 721us/step - loss: 0.4392\n",
      "[CV] END learning_rate=0.005432590230265343, n_hidden=2, n_neurons=94; total time=  19.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9397 - val_loss: 6.0295\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9280 - val_loss: 6.0078\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9162 - val_loss: 5.9861\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9044 - val_loss: 5.9644\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8925 - val_loss: 5.9428\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8806 - val_loss: 5.9211\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8686 - val_loss: 5.8994\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8566 - val_loss: 5.8777\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8446 - val_loss: 5.8561\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8326 - val_loss: 5.8344\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8205 - val_loss: 5.8128\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8084 - val_loss: 5.7912\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7962 - val_loss: 5.7695\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7841 - val_loss: 5.7479\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7719 - val_loss: 5.7264\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7597 - val_loss: 5.7048\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7475 - val_loss: 5.6833\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7352 - val_loss: 5.6619\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7230 - val_loss: 5.6404\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7107 - val_loss: 5.6190\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6985 - val_loss: 5.5977\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6862 - val_loss: 5.5763\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6739 - val_loss: 5.5551\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6616 - val_loss: 5.5338\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6492 - val_loss: 5.5126\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6369 - val_loss: 5.4915\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6246 - val_loss: 5.4704\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6123 - val_loss: 5.4493\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5999 - val_loss: 5.4283\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5876 - val_loss: 5.4074\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5753 - val_loss: 5.3865\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5630 - val_loss: 5.3657\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5506 - val_loss: 5.3449\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5383 - val_loss: 5.3242\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5260 - val_loss: 5.3035\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5137 - val_loss: 5.2829\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5015 - val_loss: 5.2614\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4892 - val_loss: 5.2410\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4769 - val_loss: 5.2206\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4647 - val_loss: 5.2002\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4524 - val_loss: 5.1800\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4402 - val_loss: 5.1598\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4280 - val_loss: 5.1396\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4158 - val_loss: 5.1196\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4036 - val_loss: 5.0996\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3914 - val_loss: 5.0796\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3793 - val_loss: 5.0598\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3671 - val_loss: 5.0400\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3550 - val_loss: 5.0203\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3429 - val_loss: 5.0007\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3308 - val_loss: 4.9811\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3188 - val_loss: 4.9616\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3067 - val_loss: 4.9422\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2947 - val_loss: 4.9228\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2827 - val_loss: 4.9035\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2707 - val_loss: 4.8842\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2587 - val_loss: 4.8651\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2468 - val_loss: 4.8460\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2349 - val_loss: 4.8270\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2229 - val_loss: 4.8080\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2110 - val_loss: 4.7891\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1992 - val_loss: 4.7703\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1873 - val_loss: 4.7516\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1755 - val_loss: 4.7330\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1637 - val_loss: 4.7144\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1518 - val_loss: 4.6959\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1401 - val_loss: 4.6774\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1283 - val_loss: 4.6591\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1166 - val_loss: 4.6408\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1048 - val_loss: 4.6226\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0931 - val_loss: 4.6044\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0814 - val_loss: 4.5864\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0698 - val_loss: 4.5683\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0581 - val_loss: 4.5504\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0465 - val_loss: 4.5325\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0349 - val_loss: 4.5147\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0233 - val_loss: 4.4970\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0118 - val_loss: 4.4794\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0002 - val_loss: 4.4618\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9887 - val_loss: 4.4442\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9773 - val_loss: 4.4268\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9658 - val_loss: 4.4094\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9544 - val_loss: 4.3921\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9429 - val_loss: 4.3749\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9315 - val_loss: 4.3577\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9202 - val_loss: 4.3406\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9088 - val_loss: 4.3236\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8975 - val_loss: 4.3066\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8862 - val_loss: 4.2898\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8749 - val_loss: 4.2730\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8636 - val_loss: 4.2562\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8524 - val_loss: 4.2396\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8412 - val_loss: 4.2229\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8300 - val_loss: 4.2064\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8188 - val_loss: 4.1899\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8076 - val_loss: 4.1735\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7965 - val_loss: 4.1572\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7854 - val_loss: 4.1410\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7743 - val_loss: 4.1248\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7632 - val_loss: 4.1087\n",
      "121/121 [==============================] - 0s 658us/step - loss: 3.9110\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  28.1s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0336 - val_loss: 6.4475\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0227 - val_loss: 6.4344\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0117 - val_loss: 6.4212\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0006 - val_loss: 6.4080\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9896 - val_loss: 6.3947\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9785 - val_loss: 6.3814\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9674 - val_loss: 6.3680\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9562 - val_loss: 6.3546\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9450 - val_loss: 6.3412\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9338 - val_loss: 6.3277\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9226 - val_loss: 6.3141\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9114 - val_loss: 6.3005\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9002 - val_loss: 6.2869\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8889 - val_loss: 6.2732\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8776 - val_loss: 6.2595\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8664 - val_loss: 6.2458\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8551 - val_loss: 6.2320\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8438 - val_loss: 6.2182\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8325 - val_loss: 6.2044\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8212 - val_loss: 6.1906\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8099 - val_loss: 6.1767\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7986 - val_loss: 6.1628\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7873 - val_loss: 6.1489\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7760 - val_loss: 6.1349\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7647 - val_loss: 6.1210\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7534 - val_loss: 6.1070\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7421 - val_loss: 6.0931\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7308 - val_loss: 6.0791\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7196 - val_loss: 6.0651\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7083 - val_loss: 6.0511\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6971 - val_loss: 6.0371\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6858 - val_loss: 6.0231\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6746 - val_loss: 6.0091\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6633 - val_loss: 5.9951\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6521 - val_loss: 5.9811\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6409 - val_loss: 5.9671\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6297 - val_loss: 5.9531\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6185 - val_loss: 5.9390\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6074 - val_loss: 5.9250\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5962 - val_loss: 5.9109\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5850 - val_loss: 5.8969\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5739 - val_loss: 5.8828\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5627 - val_loss: 5.8688\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5516 - val_loss: 5.8548\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5405 - val_loss: 5.8407\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5293 - val_loss: 5.8267\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5182 - val_loss: 5.8127\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5072 - val_loss: 5.7987\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4961 - val_loss: 5.7846\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4850 - val_loss: 5.7706\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4740 - val_loss: 5.7566\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4630 - val_loss: 5.7426\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4520 - val_loss: 5.7287\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4410 - val_loss: 5.7147\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4300 - val_loss: 5.7007\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4191 - val_loss: 5.6868\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4081 - val_loss: 5.6728\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3972 - val_loss: 5.6589\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3863 - val_loss: 5.6450\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3755 - val_loss: 5.6311\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3646 - val_loss: 5.6172\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3538 - val_loss: 5.6033\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3429 - val_loss: 5.5894\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3321 - val_loss: 5.5756\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3213 - val_loss: 5.5617\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3105 - val_loss: 5.5478\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2998 - val_loss: 5.5340\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2890 - val_loss: 5.5201\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2783 - val_loss: 5.5063\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2676 - val_loss: 5.4925\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2569 - val_loss: 5.4787\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2463 - val_loss: 5.4649\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2356 - val_loss: 5.4511\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2250 - val_loss: 5.4374\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2144 - val_loss: 5.4236\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2038 - val_loss: 5.4099\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1932 - val_loss: 5.3962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1826 - val_loss: 5.3824\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1720 - val_loss: 5.3687\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1615 - val_loss: 5.3550\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1510 - val_loss: 5.3413\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1405 - val_loss: 5.3276\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1300 - val_loss: 5.3139\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1195 - val_loss: 5.3003\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1091 - val_loss: 5.2866\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0986 - val_loss: 5.2730\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0882 - val_loss: 5.2593\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0778 - val_loss: 5.2457\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0674 - val_loss: 5.2321\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0571 - val_loss: 5.2185\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0467 - val_loss: 5.2049\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0364 - val_loss: 5.1913\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0260 - val_loss: 5.1778\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0157 - val_loss: 5.1642\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0055 - val_loss: 5.1507\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9952 - val_loss: 5.1371\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9849 - val_loss: 5.1236\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9747 - val_loss: 5.1101\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9645 - val_loss: 5.0966\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9543 - val_loss: 5.0831\n",
      "121/121 [==============================] - 0s 692us/step - loss: 3.9055\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  28.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1243 - val_loss: 6.7609\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1127 - val_loss: 6.7336\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1009 - val_loss: 6.7064\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0891 - val_loss: 6.6792\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0773 - val_loss: 6.6520\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0655 - val_loss: 6.6249\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0535 - val_loss: 6.5979\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0416 - val_loss: 6.5709\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0296 - val_loss: 6.5439\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0176 - val_loss: 6.5170\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0056 - val_loss: 6.4901\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9935 - val_loss: 6.4634\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9814 - val_loss: 6.4366\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9693 - val_loss: 6.4100\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9571 - val_loss: 6.3834\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9449 - val_loss: 6.3568\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9327 - val_loss: 6.3303\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9205 - val_loss: 6.3039\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9082 - val_loss: 6.2776\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8960 - val_loss: 6.2513\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8837 - val_loss: 6.2251\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8714 - val_loss: 6.1990\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8591 - val_loss: 6.1729\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8468 - val_loss: 6.1470\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8344 - val_loss: 6.1211\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8221 - val_loss: 6.0953\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8097 - val_loss: 6.0695\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7974 - val_loss: 6.0439\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7850 - val_loss: 6.0183\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7726 - val_loss: 5.9929\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7602 - val_loss: 5.9675\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7478 - val_loss: 5.9422\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7354 - val_loss: 5.9169\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7230 - val_loss: 5.8918\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7106 - val_loss: 5.8668\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6983 - val_loss: 5.8418\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6859 - val_loss: 5.8170\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6735 - val_loss: 5.7922\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6611 - val_loss: 5.7675\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6487 - val_loss: 5.7429\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6363 - val_loss: 5.7184\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6239 - val_loss: 5.6940\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6115 - val_loss: 5.6697\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5991 - val_loss: 5.6455\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5867 - val_loss: 5.6214\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5744 - val_loss: 5.5974\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5620 - val_loss: 5.5735\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5497 - val_loss: 5.5497\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5373 - val_loss: 5.5260\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5250 - val_loss: 5.5024\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5127 - val_loss: 5.4788\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5003 - val_loss: 5.4554\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4880 - val_loss: 5.4321\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4757 - val_loss: 5.4089\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4635 - val_loss: 5.3858\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4512 - val_loss: 5.3627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4390 - val_loss: 5.3398\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4267 - val_loss: 5.3170\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4145 - val_loss: 5.2943\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4023 - val_loss: 5.2717\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3901 - val_loss: 5.2491\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3779 - val_loss: 5.2267\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3658 - val_loss: 5.2044\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3536 - val_loss: 5.1822\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3415 - val_loss: 5.1600\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3294 - val_loss: 5.1380\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3173 - val_loss: 5.1161\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3052 - val_loss: 5.0942\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2931 - val_loss: 5.0725\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2810 - val_loss: 5.0508\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2690 - val_loss: 5.0293\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2569 - val_loss: 5.0078\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2449 - val_loss: 4.9865\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2329 - val_loss: 4.9652\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2209 - val_loss: 4.9440\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2090 - val_loss: 4.9229\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1970 - val_loss: 4.9020\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1851 - val_loss: 4.8811\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1732 - val_loss: 4.8603\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1613 - val_loss: 4.8396\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1494 - val_loss: 4.8190\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1375 - val_loss: 4.7985\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1257 - val_loss: 4.7781\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1139 - val_loss: 4.7578\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1021 - val_loss: 4.7376\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0903 - val_loss: 4.7175\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0785 - val_loss: 4.6975\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0668 - val_loss: 4.6775\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0550 - val_loss: 4.6577\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0433 - val_loss: 4.6380\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0316 - val_loss: 4.6184\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0200 - val_loss: 4.5988\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0083 - val_loss: 4.5793\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9967 - val_loss: 4.5600\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9851 - val_loss: 4.5407\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9735 - val_loss: 4.5215\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9619 - val_loss: 4.5024\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9504 - val_loss: 4.4834\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9389 - val_loss: 4.4644\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9274 - val_loss: 4.4456\n",
      "121/121 [==============================] - 0s 796us/step - loss: 3.8130\n",
      "[CV] END learning_rate=0.00037078874137762145, n_hidden=1, n_neurons=51; total time=  28.3s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.2114 - val_loss: 5.5207\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1025 - val_loss: 5.4564\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9668 - val_loss: 5.3732\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8010 - val_loss: 5.2672\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6029 - val_loss: 5.1357\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3728 - val_loss: 4.9800\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1130 - val_loss: 4.7921\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8261 - val_loss: 4.5694\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5167 - val_loss: 4.3088\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1935 - val_loss: 4.0202\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8687 - val_loss: 3.7055\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5551 - val_loss: 3.3678\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2653 - val_loss: 3.0388\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0098 - val_loss: 2.7382\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7969 - val_loss: 2.4863\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6273 - val_loss: 2.2731\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4939 - val_loss: 2.0930\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3890 - val_loss: 1.9363\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3052 - val_loss: 1.7991\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2370 - val_loss: 1.6776\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1793 - val_loss: 1.5692\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1292 - val_loss: 1.4722\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0855 - val_loss: 1.3867\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0481 - val_loss: 1.3121\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0162 - val_loss: 1.2505\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9890 - val_loss: 1.2002\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9660 - val_loss: 1.1561\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9465 - val_loss: 1.1185\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9299 - val_loss: 1.0852\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9157 - val_loss: 1.0559\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9033 - val_loss: 1.0315\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8923 - val_loss: 1.0100\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8825 - val_loss: 0.9916\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8736 - val_loss: 0.9751\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8655 - val_loss: 0.9603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8580 - val_loss: 0.9470\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8510 - val_loss: 0.9340\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8445 - val_loss: 0.9222\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8384 - val_loss: 0.9111\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8327 - val_loss: 0.9007\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8272 - val_loss: 0.8910\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8220 - val_loss: 0.8822\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8170 - val_loss: 0.8739\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8123 - val_loss: 0.8660\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8077 - val_loss: 0.8587\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8034 - val_loss: 0.8517\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7993 - val_loss: 0.8451\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7953 - val_loss: 0.8388\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7915 - val_loss: 0.8327\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7879 - val_loss: 0.8269\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7843 - val_loss: 0.8213\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7810 - val_loss: 0.8160\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7777 - val_loss: 0.8110\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7745 - val_loss: 0.8061\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7715 - val_loss: 0.8015\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7685 - val_loss: 0.7969\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7657 - val_loss: 0.7926\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7629 - val_loss: 0.7884\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7602 - val_loss: 0.7843\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7576 - val_loss: 0.7804\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7551 - val_loss: 0.7766\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7526 - val_loss: 0.7730\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7502 - val_loss: 0.7695\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7479 - val_loss: 0.7661\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7456 - val_loss: 0.7628\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7435 - val_loss: 0.7596\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7414 - val_loss: 0.7566\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7393 - val_loss: 0.7537\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7374 - val_loss: 0.7508\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7355 - val_loss: 0.7481\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7336 - val_loss: 0.7454\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7318 - val_loss: 0.7429\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7301 - val_loss: 0.7404\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7284 - val_loss: 0.7380\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7268 - val_loss: 0.7357\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7252 - val_loss: 0.7335\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7237 - val_loss: 0.7314\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7222 - val_loss: 0.7294\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7208 - val_loss: 0.7274\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7194 - val_loss: 0.7255\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7180 - val_loss: 0.7236\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7167 - val_loss: 0.7219\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7154 - val_loss: 0.7201\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7142 - val_loss: 0.7185\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7130 - val_loss: 0.7168\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7117 - val_loss: 0.7153\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7106 - val_loss: 0.7137\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7095 - val_loss: 0.7123\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7084 - val_loss: 0.7108\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7074 - val_loss: 0.7094\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7064 - val_loss: 0.7081\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7054 - val_loss: 0.7068\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7044 - val_loss: 0.7055\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7035 - val_loss: 0.7043\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7026 - val_loss: 0.7031\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7017 - val_loss: 0.7020\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7008 - val_loss: 0.7009\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7000 - val_loss: 0.6998\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6992 - val_loss: 0.6987\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6984 - val_loss: 0.6977\n",
      "121/121 [==============================] - 0s 696us/step - loss: 0.7069\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  29.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.2720 - val_loss: 6.2671\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1386 - val_loss: 6.3167\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9736 - val_loss: 6.3722\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7769 - val_loss: 6.4319\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5480 - val_loss: 6.4936\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2861 - val_loss: 6.5541\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9914 - val_loss: 6.6075\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6693 - val_loss: 6.6493\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3297 - val_loss: 6.6744\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9861 - val_loss: 6.6751\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6525 - val_loss: 6.6443\n",
      "121/121 [==============================] - 0s 696us/step - loss: 2.5300\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=   3.6s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.2776 - val_loss: 5.4790\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 5.1540 - val_loss: 5.4219\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0036 - val_loss: 5.3484\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8258 - val_loss: 5.2611\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6214 - val_loss: 5.1478\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3898 - val_loss: 5.0127\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1320 - val_loss: 4.8492\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8515 - val_loss: 4.6577\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5524 - val_loss: 4.4238\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2440 - val_loss: 4.1486\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9387 - val_loss: 3.8702\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6481 - val_loss: 3.5711\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3807 - val_loss: 3.2653\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1462 - val_loss: 2.9718\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9464 - val_loss: 2.6925\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7766 - val_loss: 2.4399\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6326 - val_loss: 2.2296\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5124 - val_loss: 2.0499\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4126 - val_loss: 1.8960\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3279 - val_loss: 1.7595\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2552 - val_loss: 1.6394\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1929 - val_loss: 1.5344\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1409 - val_loss: 1.4448\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0987 - val_loss: 1.3735\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0653 - val_loss: 1.3132\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0389 - val_loss: 1.2632\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0176 - val_loss: 1.2198\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0001 - val_loss: 1.1823\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9853 - val_loss: 1.1502\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9727 - val_loss: 1.1217\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9616 - val_loss: 1.0959\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9518 - val_loss: 1.0726\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9430 - val_loss: 1.0521\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9350 - val_loss: 1.0339\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9276 - val_loss: 1.0179\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9209 - val_loss: 1.0042\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9146 - val_loss: 0.9916\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9088 - val_loss: 0.9798\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9033 - val_loss: 0.9689\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8981 - val_loss: 0.9587\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8933 - val_loss: 0.9492\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8887 - val_loss: 0.9402\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8843 - val_loss: 0.9318\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8801 - val_loss: 0.9238\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8761 - val_loss: 0.9161\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8723 - val_loss: 0.9092\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8687 - val_loss: 0.9028\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8652 - val_loss: 0.8968\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8618 - val_loss: 0.8911\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8586 - val_loss: 0.8857\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8555 - val_loss: 0.8804\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8525 - val_loss: 0.8754\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8496 - val_loss: 0.8706\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8469 - val_loss: 0.8660\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8442 - val_loss: 0.8615\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8416 - val_loss: 0.8573\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8391 - val_loss: 0.8532\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8366 - val_loss: 0.8493\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8343 - val_loss: 0.8454\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8320 - val_loss: 0.8417\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8297 - val_loss: 0.8382\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8274 - val_loss: 0.8349\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8253 - val_loss: 0.8317\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8231 - val_loss: 0.8285\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8209 - val_loss: 0.8253\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8186 - val_loss: 0.8222\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8163 - val_loss: 0.8189\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8137 - val_loss: 0.8154\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8107 - val_loss: 0.8113\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8069 - val_loss: 0.8061\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8012 - val_loss: 0.7983\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7916 - val_loss: 0.7856\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7771 - val_loss: 0.7706\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7639 - val_loss: 0.7590\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7539 - val_loss: 0.7502\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7463 - val_loss: 0.7434\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7406 - val_loss: 0.7380\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7361 - val_loss: 0.7337\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7326 - val_loss: 0.7302\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7298 - val_loss: 0.7273\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7274 - val_loss: 0.7247\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7254 - val_loss: 0.7224\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7236 - val_loss: 0.7204\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7220 - val_loss: 0.7185\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7205 - val_loss: 0.7167\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7192 - val_loss: 0.7151\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7180 - val_loss: 0.7136\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7168 - val_loss: 0.7121\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7157 - val_loss: 0.7107\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7146 - val_loss: 0.7094\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7135 - val_loss: 0.7081\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7125 - val_loss: 0.7068\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7115 - val_loss: 0.7056\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7106 - val_loss: 0.7044\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7097 - val_loss: 0.7033\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7088 - val_loss: 0.7022\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7079 - val_loss: 0.7012\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7070 - val_loss: 0.7002\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7062 - val_loss: 0.6992\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7054 - val_loss: 0.6982\n",
      "121/121 [==============================] - 0s 696us/step - loss: 0.6943\n",
      "[CV] END learning_rate=0.0016535051383872363, n_hidden=2, n_neurons=70; total time=  30.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 967us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 973us/step - loss: 6.4587 - val_loss: 18.4776\n",
      "121/121 [==============================] - 0s 629us/step - loss: 6.5948\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 977us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 988us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 983us/step - loss: 6.4148 - val_loss: 18.4776\n",
      "121/121 [==============================] - 0s 638us/step - loss: 6.6825\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.8s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 992us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 996us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 990us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 994us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 998us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 6.6387 - val_loss: 18.4776\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 971us/step - loss: 6.6387 - val_loss: 18.4776\n",
      "121/121 [==============================] - 0s 637us/step - loss: 6.2349\n",
      "[CV] END learning_rate=0.01824796188192035, n_hidden=0, n_neurons=40; total time=   2.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7418 - val_loss: 4.8414\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8590 - val_loss: 2.6505\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5310 - val_loss: 1.6614\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3635 - val_loss: 1.4616\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3108 - val_loss: 1.3604\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2728 - val_loss: 1.3001\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2434 - val_loss: 1.2536\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2192 - val_loss: 1.2202\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1997 - val_loss: 1.1968\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1834 - val_loss: 1.1765\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1700 - val_loss: 1.1612\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1589 - val_loss: 1.1491\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1496 - val_loss: 1.1380\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1416 - val_loss: 1.1297\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1202 - val_loss: 1.0342\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9853 - val_loss: 0.9622\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9595 - val_loss: 0.9529\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9540 - val_loss: 0.9483\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9497 - val_loss: 0.9460\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9466 - val_loss: 0.9424\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9433 - val_loss: 0.9421\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9406 - val_loss: 0.9436\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9380 - val_loss: 0.9456\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9355 - val_loss: 0.9520\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9339 - val_loss: 0.9576\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9318 - val_loss: 0.9625\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9302 - val_loss: 0.9703\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9287 - val_loss: 0.9769\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9267 - val_loss: 0.9817\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9257 - val_loss: 0.9798\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9244 - val_loss: 0.9750\n",
      "121/121 [==============================] - 0s 742us/step - loss: 0.9568\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   9.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.7314 - val_loss: 7.3068\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7849 - val_loss: 10.8663\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8230 - val_loss: 8.3003\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5721 - val_loss: 5.9343\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3719 - val_loss: 4.4055\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2917 - val_loss: 3.4129\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2568 - val_loss: 2.7454\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2308 - val_loss: 2.2814\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2109 - val_loss: 1.9967\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1960 - val_loss: 1.8059\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1843 - val_loss: 1.7048\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1753 - val_loss: 1.6324\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1686 - val_loss: 1.5774\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1630 - val_loss: 1.5507\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1581 - val_loss: 1.5198\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1538 - val_loss: 1.5079\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1500 - val_loss: 1.4932\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1468 - val_loss: 1.4927\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0860 - val_loss: 1.3593\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9748 - val_loss: 1.3415\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9652 - val_loss: 1.3417\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9622 - val_loss: 1.3531\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9596 - val_loss: 1.3657\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9572 - val_loss: 1.3785\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9551 - val_loss: 1.3936\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9529 - val_loss: 1.4095\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9506 - val_loss: 1.4266\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9489 - val_loss: 1.4468\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9462 - val_loss: 1.4953\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9454 - val_loss: 1.5114\n",
      "121/121 [==============================] - 0s 804us/step - loss: 0.9518\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   9.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.9095 - val_loss: 5.9721\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1296 - val_loss: 4.6308\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0597 - val_loss: 2.5461\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8884 - val_loss: 1.9889\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7139 - val_loss: 1.7595\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6562 - val_loss: 1.6664\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6258 - val_loss: 1.6143\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5969 - val_loss: 1.5525\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3565 - val_loss: 1.2282\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1020 - val_loss: 1.0032\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9074 - val_loss: 0.8745\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8617 - val_loss: 0.8497\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8479 - val_loss: 0.8325\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8371 - val_loss: 0.8177\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8279 - val_loss: 0.8051\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8207 - val_loss: 0.7937\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8140 - val_loss: 0.7852\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8091 - val_loss: 0.7788\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8047 - val_loss: 0.7716\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8010 - val_loss: 0.7669\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7973 - val_loss: 0.7662\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7940 - val_loss: 0.7673\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7911 - val_loss: 0.7688\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7885 - val_loss: 0.7776\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7857 - val_loss: 0.7779\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7833 - val_loss: 0.7787\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7814 - val_loss: 0.7861\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7794 - val_loss: 0.7829\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7772 - val_loss: 0.7946\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7761 - val_loss: 0.7871\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7748 - val_loss: 0.7815\n",
      "121/121 [==============================] - 0s 712us/step - loss: 0.7625\n",
      "[CV] END learning_rate=0.0045455096956331, n_hidden=3, n_neurons=30; total time=   9.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9730 - val_loss: 6.4233\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9085 - val_loss: 6.2789\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8427 - val_loss: 6.1357\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7760 - val_loss: 5.9942\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7087 - val_loss: 5.8547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6412 - val_loss: 5.7174\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5736 - val_loss: 5.5828\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5062 - val_loss: 5.4512\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4390 - val_loss: 5.3227\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3723 - val_loss: 5.1971\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3061 - val_loss: 5.0745\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2404 - val_loss: 4.9552\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1753 - val_loss: 4.8389\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1108 - val_loss: 4.7254\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0469 - val_loss: 4.6152\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9838 - val_loss: 4.5079\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9213 - val_loss: 4.4035\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8596 - val_loss: 4.3020\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7986 - val_loss: 4.2033\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7383 - val_loss: 4.1073\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6786 - val_loss: 4.0142\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6195 - val_loss: 3.9235\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5611 - val_loss: 3.8353\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5032 - val_loss: 3.7493\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4460 - val_loss: 3.6657\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3894 - val_loss: 3.5844\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3333 - val_loss: 3.5051\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2778 - val_loss: 3.4279\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2228 - val_loss: 3.3525\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1683 - val_loss: 3.2791\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1144 - val_loss: 3.2074\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0610 - val_loss: 3.1376\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0081 - val_loss: 3.0694\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9558 - val_loss: 3.0028\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9040 - val_loss: 2.9378\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8528 - val_loss: 2.8743\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8020 - val_loss: 2.8116\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7517 - val_loss: 2.7510\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7019 - val_loss: 2.6920\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6528 - val_loss: 2.6343\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6041 - val_loss: 2.5778\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5562 - val_loss: 2.5227\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5088 - val_loss: 2.4689\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4620 - val_loss: 2.4162\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4158 - val_loss: 2.3646\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3700 - val_loss: 2.3142\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3249 - val_loss: 2.2650\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2803 - val_loss: 2.2169\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2365 - val_loss: 2.1699\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1933 - val_loss: 2.1240\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1508 - val_loss: 2.0794\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1092 - val_loss: 2.0358\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0682 - val_loss: 1.9934\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0282 - val_loss: 1.9522\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9890 - val_loss: 1.9121\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9507 - val_loss: 1.8731\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9133 - val_loss: 1.8351\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8768 - val_loss: 1.7982\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8412 - val_loss: 1.7622\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.8065 - val_loss: 1.7273\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7726 - val_loss: 1.6932\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7395 - val_loss: 1.6601\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7072 - val_loss: 1.6278\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6757 - val_loss: 1.5965\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6449 - val_loss: 1.5659\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6150 - val_loss: 1.5362\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5858 - val_loss: 1.5073\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5573 - val_loss: 1.4793\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5296 - val_loss: 1.4519\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5025 - val_loss: 1.4253\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4761 - val_loss: 1.3995\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4504 - val_loss: 1.3743\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4253 - val_loss: 1.3498\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4009 - val_loss: 1.3260\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3771 - val_loss: 1.3029\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3539 - val_loss: 1.2803\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3313 - val_loss: 1.2584\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3093 - val_loss: 1.2371\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2879 - val_loss: 1.2163\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2671 - val_loss: 1.1961\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2468 - val_loss: 1.1764\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2270 - val_loss: 1.1573\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2077 - val_loss: 1.1387\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1890 - val_loss: 1.1205\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1708 - val_loss: 1.1029\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1531 - val_loss: 1.0858\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1359 - val_loss: 1.0691\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1191 - val_loss: 1.0529\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1028 - val_loss: 1.0371\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0869 - val_loss: 1.0217\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0714 - val_loss: 1.0068\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0563 - val_loss: 0.9923\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0417 - val_loss: 0.9782\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0275 - val_loss: 0.9645\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0136 - val_loss: 0.9511\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0001 - val_loss: 0.9381\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9870 - val_loss: 0.9255\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9743 - val_loss: 0.9132\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9619 - val_loss: 0.9013\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9498 - val_loss: 0.8896\n",
      "121/121 [==============================] - 0s 721us/step - loss: 0.9696\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  30.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.0568 - val_loss: 5.3794\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9881 - val_loss: 5.3079\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9172 - val_loss: 5.2341\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8448 - val_loss: 5.1586\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7713 - val_loss: 5.0820\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6973 - val_loss: 5.0048\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6232 - val_loss: 4.9273\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5492 - val_loss: 4.8499\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4757 - val_loss: 4.7729\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4028 - val_loss: 4.6963\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3306 - val_loss: 4.6202\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2593 - val_loss: 4.5449\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1888 - val_loss: 4.4702\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1192 - val_loss: 4.3961\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0505 - val_loss: 4.3229\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9828 - val_loss: 4.2504\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9159 - val_loss: 4.1785\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8500 - val_loss: 4.1074\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7849 - val_loss: 4.0372\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7208 - val_loss: 3.9677\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6576 - val_loss: 3.8990\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5954 - val_loss: 3.8312\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5340 - val_loss: 3.7641\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4733 - val_loss: 3.6978\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4134 - val_loss: 3.6322\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3543 - val_loss: 3.5673\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2959 - val_loss: 3.5032\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2382 - val_loss: 3.4397\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1813 - val_loss: 3.3771\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1251 - val_loss: 3.3152\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0696 - val_loss: 3.2540\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0149 - val_loss: 3.1936\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9608 - val_loss: 3.1340\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9074 - val_loss: 3.0751\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8549 - val_loss: 3.0171\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8031 - val_loss: 2.9600\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7522 - val_loss: 2.9037\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7021 - val_loss: 2.8483\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6527 - val_loss: 2.7939\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6042 - val_loss: 2.7402\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5565 - val_loss: 2.6875\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5096 - val_loss: 2.6356\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4635 - val_loss: 2.5846\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4181 - val_loss: 2.5343\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3736 - val_loss: 2.4849\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3299 - val_loss: 2.4364\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2869 - val_loss: 2.3887\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2447 - val_loss: 2.3418\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2031 - val_loss: 2.2957\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1623 - val_loss: 2.2505\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1222 - val_loss: 2.2061\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0827 - val_loss: 2.1625\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0440 - val_loss: 2.1197\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0060 - val_loss: 2.0777\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9687 - val_loss: 2.0364\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9320 - val_loss: 1.9960\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8961 - val_loss: 1.9562\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8608 - val_loss: 1.9172\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8262 - val_loss: 1.8790\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7922 - val_loss: 1.8415\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7589 - val_loss: 1.8048\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7263 - val_loss: 1.7688\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6943 - val_loss: 1.7335\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6629 - val_loss: 1.6990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6322 - val_loss: 1.6651\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6022 - val_loss: 1.6321\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5729 - val_loss: 1.5998\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5441 - val_loss: 1.5682\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5161 - val_loss: 1.5373\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4886 - val_loss: 1.5071\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4618 - val_loss: 1.4776\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4356 - val_loss: 1.4488\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4100 - val_loss: 1.4206\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3850 - val_loss: 1.3931\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3605 - val_loss: 1.3663\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3367 - val_loss: 1.3401\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3134 - val_loss: 1.3145\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2907 - val_loss: 1.2894\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 1.2686 - val_loss: 1.2650\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2470 - val_loss: 1.2413\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2259 - val_loss: 1.2180\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2054 - val_loss: 1.1954\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1853 - val_loss: 1.1733\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1658 - val_loss: 1.1518\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1468 - val_loss: 1.1309\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1283 - val_loss: 1.1105\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1104 - val_loss: 1.0907\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0929 - val_loss: 1.0714\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0759 - val_loss: 1.0527\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0594 - val_loss: 1.0345\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0434 - val_loss: 1.0169\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0279 - val_loss: 0.9998\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0128 - val_loss: 0.9832\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9982 - val_loss: 0.9672\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9841 - val_loss: 0.9516\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9704 - val_loss: 0.9366\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9571 - val_loss: 0.9220\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9442 - val_loss: 0.9079\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9318 - val_loss: 0.8943\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9198 - val_loss: 0.8812\n",
      "121/121 [==============================] - 0s 704us/step - loss: 0.9064\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  29.7s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.0931 - val_loss: 5.9513\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 5.0245 - val_loss: 5.8290\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.9544 - val_loss: 5.7075\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8833 - val_loss: 5.5869\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.8117 - val_loss: 5.4679\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7399 - val_loss: 5.3506\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.6680 - val_loss: 5.2350\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5963 - val_loss: 5.1214\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.5248 - val_loss: 5.0103\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4539 - val_loss: 4.9015\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3836 - val_loss: 4.7950\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3139 - val_loss: 4.6911\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.2450 - val_loss: 4.5895\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1768 - val_loss: 4.4903\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1094 - val_loss: 4.3933\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.0426 - val_loss: 4.2985\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9764 - val_loss: 4.2058\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.9110 - val_loss: 4.1153\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.8463 - val_loss: 4.0266\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7822 - val_loss: 3.9399\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.7188 - val_loss: 3.8551\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6560 - val_loss: 3.7721\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5938 - val_loss: 3.6910\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5323 - val_loss: 3.6118\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4716 - val_loss: 3.5344\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.4115 - val_loss: 3.4587\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3521 - val_loss: 3.3845\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2933 - val_loss: 3.3120\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2352 - val_loss: 3.2410\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1778 - val_loss: 3.1716\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.1210 - val_loss: 3.1035\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0648 - val_loss: 3.0370\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.0092 - val_loss: 2.9717\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.9541 - val_loss: 2.9076\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8995 - val_loss: 2.8447\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8455 - val_loss: 2.7832\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7921 - val_loss: 2.7229\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7393 - val_loss: 2.6637\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6872 - val_loss: 2.6058\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.6357 - val_loss: 2.5490\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5849 - val_loss: 2.4935\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.5348 - val_loss: 2.4391\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4854 - val_loss: 2.3860\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.4369 - val_loss: 2.3341\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3891 - val_loss: 2.2835\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3422 - val_loss: 2.2341\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2962 - val_loss: 2.1859\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2510 - val_loss: 2.1389\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.2066 - val_loss: 2.0930\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1631 - val_loss: 2.0482\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.1204 - val_loss: 2.0046\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0785 - val_loss: 1.9620\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0375 - val_loss: 1.9206\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9974 - val_loss: 1.8802\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9581 - val_loss: 1.8409\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.9196 - val_loss: 1.8025\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8819 - val_loss: 1.7650\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8450 - val_loss: 1.7286\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8089 - val_loss: 1.6931\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7737 - val_loss: 1.6586\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7393 - val_loss: 1.6251\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7058 - val_loss: 1.5925\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6731 - val_loss: 1.5608\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6413 - val_loss: 1.5301\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6104 - val_loss: 1.5003\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5803 - val_loss: 1.4713\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5510 - val_loss: 1.4433\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5225 - val_loss: 1.4160\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4948 - val_loss: 1.3896\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4678 - val_loss: 1.3639\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4416 - val_loss: 1.3390\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4162 - val_loss: 1.3149\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3914 - val_loss: 1.2914\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3674 - val_loss: 1.2687\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3441 - val_loss: 1.2466\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3214 - val_loss: 1.2251\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2993 - val_loss: 1.2043\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2779 - val_loss: 1.1841\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2571 - val_loss: 1.1644\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2368 - val_loss: 1.1454\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2172 - val_loss: 1.1269\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1981 - val_loss: 1.1089\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1796 - val_loss: 1.0915\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1616 - val_loss: 1.0746\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1441 - val_loss: 1.0581\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1271 - val_loss: 1.0422\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1106 - val_loss: 1.0267\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0946 - val_loss: 1.0117\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0791 - val_loss: 0.9971\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0641 - val_loss: 0.9830\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0494 - val_loss: 0.9692\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0352 - val_loss: 0.9559\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0214 - val_loss: 0.9430\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0080 - val_loss: 0.9304\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9950 - val_loss: 0.9182\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 2ms/step - loss: 0.9824 - val_loss: 0.9064\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9701 - val_loss: 0.8949\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9582 - val_loss: 0.8838\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9467 - val_loss: 0.8730\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9355 - val_loss: 0.8625\n",
      "121/121 [==============================] - 0s 800us/step - loss: 0.9216\n",
      "[CV] END learning_rate=0.0020587676114196545, n_hidden=1, n_neurons=49; total time=  28.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 4.9830 - val_loss: 5.0132\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3256 - val_loss: 3.9975\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8884 - val_loss: 2.4640\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6625 - val_loss: 2.0264\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6073 - val_loss: 1.8203\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5720 - val_loss: 1.7071\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5448 - val_loss: 1.6272\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5220 - val_loss: 1.5784\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5033 - val_loss: 1.5419\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4873 - val_loss: 1.5112\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4739 - val_loss: 1.4876\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4624 - val_loss: 1.4686\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4529 - val_loss: 1.4525\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4448 - val_loss: 1.4407\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4382 - val_loss: 1.4297\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4323 - val_loss: 1.4228\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4081 - val_loss: 1.3628\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3589 - val_loss: 1.3462\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3507 - val_loss: 1.3426\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3472 - val_loss: 1.3381\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3407 - val_loss: 1.3112\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2863 - val_loss: 1.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2707 - val_loss: 1.2703\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2673 - val_loss: 1.2698\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2656 - val_loss: 1.2700\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2634 - val_loss: 1.2703\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2615 - val_loss: 1.2709\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2598 - val_loss: 1.2719\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2575 - val_loss: 1.2735\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2561 - val_loss: 1.2743\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2546 - val_loss: 1.2731\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2529 - val_loss: 1.2735\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2514 - val_loss: 1.2755\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2498 - val_loss: 1.2766\n",
      "121/121 [==============================] - 0s 692us/step - loss: 1.2912\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  10.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.1550 - val_loss: 5.6602\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.5559 - val_loss: 10.0348\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0000 - val_loss: 9.3335\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5756 - val_loss: 5.7980\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4638 - val_loss: 3.9905\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4168 - val_loss: 2.9508\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3807 - val_loss: 2.3311\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3509 - val_loss: 1.9532\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3259 - val_loss: 1.7327\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3052 - val_loss: 1.5723\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2878 - val_loss: 1.4699\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2736 - val_loss: 1.4027\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2269 - val_loss: 1.3032\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1673 - val_loss: 1.2220\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1108 - val_loss: 1.1839\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1002 - val_loss: 1.1689\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0945 - val_loss: 1.1544\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0901 - val_loss: 1.1449\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0856 - val_loss: 1.1356\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0821 - val_loss: 1.1291\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0789 - val_loss: 1.1222\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0759 - val_loss: 1.1182\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0733 - val_loss: 1.1148\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0709 - val_loss: 1.1116\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0688 - val_loss: 1.1103\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0666 - val_loss: 1.1102\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0637 - val_loss: 1.1045\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0127 - val_loss: 1.0523\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9910 - val_loss: 1.0576\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9893 - val_loss: 1.0555\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9871 - val_loss: 1.0554\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9852 - val_loss: 1.0594\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9450 - val_loss: 1.0058\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9137 - val_loss: 1.0080\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9103 - val_loss: 1.0148\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9086 - val_loss: 1.0179\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9073 - val_loss: 1.0292\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9058 - val_loss: 1.0418\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9045 - val_loss: 1.0517\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9035 - val_loss: 1.0668\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9020 - val_loss: 1.0828\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9010 - val_loss: 1.0960\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8997 - val_loss: 1.1032\n",
      "121/121 [==============================] - 0s 671us/step - loss: 0.9018\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  13.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.9240 - val_loss: 4.9544\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.8587 - val_loss: 3.5243\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5556 - val_loss: 1.8702\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3232 - val_loss: 1.4891\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2677 - val_loss: 1.3484\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2332 - val_loss: 1.2751\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2067 - val_loss: 1.2266\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1853 - val_loss: 1.1835\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1675 - val_loss: 1.1571\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1530 - val_loss: 1.1348\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1404 - val_loss: 1.1171\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0910 - val_loss: 1.0438\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0530 - val_loss: 1.0300\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0444 - val_loss: 1.0214\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0381 - val_loss: 1.0143\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0331 - val_loss: 1.0075\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0284 - val_loss: 1.0032\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0245 - val_loss: 0.9995\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0213 - val_loss: 0.9960\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0182 - val_loss: 0.9936\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0153 - val_loss: 0.9915\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0125 - val_loss: 0.9911\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0101 - val_loss: 0.9902\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0077 - val_loss: 0.9920\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0056 - val_loss: 0.9901\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0033 - val_loss: 0.9905\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0016 - val_loss: 0.9918\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9995 - val_loss: 0.9944\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9975 - val_loss: 1.0018\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9959 - val_loss: 1.0012\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9910 - val_loss: 0.9805\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9371 - val_loss: 0.9480\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9218 - val_loss: 0.9438\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9191 - val_loss: 0.9501\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9176 - val_loss: 0.9433\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8765 - val_loss: 0.8806\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8465 - val_loss: 0.8689\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8433 - val_loss: 0.8711\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8416 - val_loss: 0.8700\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8402 - val_loss: 0.8694\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8386 - val_loss: 0.8789\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8377 - val_loss: 0.8791\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8362 - val_loss: 0.8624\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8354 - val_loss: 0.8653\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8340 - val_loss: 0.8700\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8330 - val_loss: 0.8674\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8316 - val_loss: 0.8541\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8309 - val_loss: 0.8517\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8293 - val_loss: 0.8646\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8286 - val_loss: 0.8711\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8271 - val_loss: 0.8777\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8265 - val_loss: 0.8750\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8254 - val_loss: 0.8588\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8216 - val_loss: 0.8206\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7677 - val_loss: 0.7786\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7516 - val_loss: 0.7800\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7495 - val_loss: 0.7905\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7481 - val_loss: 0.7834\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6993 - val_loss: 0.7260\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6769 - val_loss: 0.7017\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6742 - val_loss: 0.6995\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6731 - val_loss: 0.7145\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6726 - val_loss: 0.6887\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6716 - val_loss: 0.6876\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6707 - val_loss: 0.6726\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6695 - val_loss: 0.6963\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6691 - val_loss: 0.6697\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6682 - val_loss: 0.6945\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6673 - val_loss: 0.6674\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6664 - val_loss: 0.6938\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6658 - val_loss: 0.6684\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6649 - val_loss: 0.6861\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6643 - val_loss: 0.6660\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6638 - val_loss: 0.6594\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6630 - val_loss: 0.6813\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6617 - val_loss: 0.7096\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6619 - val_loss: 0.6693\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6606 - val_loss: 0.6655\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6602 - val_loss: 0.6542\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6590 - val_loss: 0.6632\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6180 - val_loss: 0.5930\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5900 - val_loss: 0.6031\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5865 - val_loss: 0.5904\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5852 - val_loss: 0.6156\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5801 - val_loss: 0.5455\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 0.5296\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5140 - val_loss: 0.5607\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5120 - val_loss: 0.5199\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5110 - val_loss: 0.5410\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5105 - val_loss: 0.5091\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5095 - val_loss: 0.5421\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5097 - val_loss: 0.4889\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5091 - val_loss: 0.5290\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5082 - val_loss: 0.5237\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5074 - val_loss: 0.5262\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5070 - val_loss: 0.5503\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5066 - val_loss: 0.5356\n",
      "Epoch 98/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5060 - val_loss: 0.4888\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5056 - val_loss: 0.5427\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5054 - val_loss: 0.5431\n",
      "121/121 [==============================] - 0s 671us/step - loss: 0.4977\n",
      "[CV] END learning_rate=0.005803602934201024, n_hidden=3, n_neurons=74; total time=  29.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.8533 - val_loss: 4.6503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7097 - val_loss: 2.7139\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2623 - val_loss: 1.4575\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0672 - val_loss: 1.2043\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0154 - val_loss: 1.0918\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9776 - val_loss: 1.0233\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9382 - val_loss: 0.9301\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8653 - val_loss: 0.8767\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8395 - val_loss: 0.8490\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8225 - val_loss: 0.8270\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8091 - val_loss: 0.8105\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7981 - val_loss: 0.7977\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7894 - val_loss: 0.7872\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7824 - val_loss: 0.7802\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7766 - val_loss: 0.7729\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7714 - val_loss: 0.7695\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7674 - val_loss: 0.7654\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7638 - val_loss: 0.7632\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7603 - val_loss: 0.7628\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7578 - val_loss: 0.7604\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7550 - val_loss: 0.7609\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7527 - val_loss: 0.7612\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7503 - val_loss: 0.7609\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7480 - val_loss: 0.7624\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7465 - val_loss: 0.7637\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7444 - val_loss: 0.7651\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7427 - val_loss: 0.7665\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7414 - val_loss: 0.7687\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7391 - val_loss: 0.7710\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7378 - val_loss: 0.7703\n",
      "121/121 [==============================] - 0s 683us/step - loss: 0.7597\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   9.2s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.0739 - val_loss: 5.8820\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.3300 - val_loss: 11.6333\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7811 - val_loss: 11.2739\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4649 - val_loss: 8.0773\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3382 - val_loss: 5.9154\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2685 - val_loss: 4.5595\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2300 - val_loss: 3.6469\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1997 - val_loss: 3.0262\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1757 - val_loss: 2.6242\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1572 - val_loss: 2.3467\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1242 - val_loss: 2.1142\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0711 - val_loss: 1.9561\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0597 - val_loss: 1.8442\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0531 - val_loss: 1.7904\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0474 - val_loss: 1.7242\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0428 - val_loss: 1.6970\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0389 - val_loss: 1.6586\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0357 - val_loss: 1.6407\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0203 - val_loss: 1.5762\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9700 - val_loss: 1.5554\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9625 - val_loss: 1.5391\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9601 - val_loss: 1.5425\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9579 - val_loss: 1.5464\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9561 - val_loss: 1.5415\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9544 - val_loss: 1.5440\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9527 - val_loss: 1.5505\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9509 - val_loss: 1.5616\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9495 - val_loss: 1.5648\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9474 - val_loss: 1.5948\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9468 - val_loss: 1.5891\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9243 - val_loss: 1.5498\n",
      "121/121 [==============================] - 0s 667us/step - loss: 0.9042\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=   9.4s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 5.3192 - val_loss: 5.3699\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1318 - val_loss: 5.2299\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3880 - val_loss: 2.5180\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8857 - val_loss: 2.0544\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.8143 - val_loss: 1.8839\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7346 - val_loss: 1.7918\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6997 - val_loss: 1.7461\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6778 - val_loss: 1.7069\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6592 - val_loss: 1.6781\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6437 - val_loss: 1.6535\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6301 - val_loss: 1.6323\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6186 - val_loss: 1.6142\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6091 - val_loss: 1.5998\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.6008 - val_loss: 1.5876\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5937 - val_loss: 1.5770\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5878 - val_loss: 1.5670\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5824 - val_loss: 1.5594\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5777 - val_loss: 1.5528\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5739 - val_loss: 1.5464\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5702 - val_loss: 1.5413\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5669 - val_loss: 1.5366\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5638 - val_loss: 1.5339\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5612 - val_loss: 1.5313\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5586 - val_loss: 1.5308\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5563 - val_loss: 1.5297\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5539 - val_loss: 1.5306\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5520 - val_loss: 1.5322\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5500 - val_loss: 1.5339\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5481 - val_loss: 1.5392\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5466 - val_loss: 1.5381\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5450 - val_loss: 1.5401\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5434 - val_loss: 1.5446\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5333 - val_loss: 1.5130\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4844 - val_loss: 1.5039\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4750 - val_loss: 1.4935\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4728 - val_loss: 1.4883\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4717 - val_loss: 1.4762\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4704 - val_loss: 1.4885\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4692 - val_loss: 1.4784\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4680 - val_loss: 1.4792\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4667 - val_loss: 1.4901\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4660 - val_loss: 1.4836\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4648 - val_loss: 1.4605\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4640 - val_loss: 1.4706\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4629 - val_loss: 1.4698\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4620 - val_loss: 1.4769\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4610 - val_loss: 1.4455\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4604 - val_loss: 1.4466\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4590 - val_loss: 1.4718\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4585 - val_loss: 1.4686\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4572 - val_loss: 1.4752\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.4446 - val_loss: 1.4323\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3988 - val_loss: 1.3828\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3898 - val_loss: 1.3740\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3878 - val_loss: 1.3749\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3869 - val_loss: 1.3876\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3862 - val_loss: 1.3998\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3858 - val_loss: 1.3836\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3847 - val_loss: 1.3905\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3840 - val_loss: 1.3648\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3832 - val_loss: 1.3689\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3825 - val_loss: 1.3884\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3822 - val_loss: 1.3568\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3813 - val_loss: 1.3651\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3807 - val_loss: 1.3500\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3798 - val_loss: 1.3757\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3795 - val_loss: 1.3481\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3787 - val_loss: 1.3752\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3781 - val_loss: 1.3459\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3773 - val_loss: 1.3767\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3768 - val_loss: 1.3468\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3762 - val_loss: 1.3687\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3757 - val_loss: 1.3439\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3753 - val_loss: 1.3408\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3747 - val_loss: 1.3666\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3737 - val_loss: 1.4020\n",
      "Epoch 77/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3740 - val_loss: 1.3488\n",
      "Epoch 78/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3729 - val_loss: 1.3492\n",
      "Epoch 79/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3726 - val_loss: 1.3368\n",
      "Epoch 80/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3719 - val_loss: 1.3556\n",
      "Epoch 81/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3717 - val_loss: 1.3398\n",
      "Epoch 82/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3711 - val_loss: 1.3671\n",
      "Epoch 83/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3707 - val_loss: 1.3440\n",
      "Epoch 84/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3701 - val_loss: 1.3751\n",
      "Epoch 85/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3697 - val_loss: 1.3254\n",
      "Epoch 86/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3625 - val_loss: 1.3186\n",
      "Epoch 87/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3165 - val_loss: 1.3357\n",
      "Epoch 88/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3043 - val_loss: 1.2700\n",
      "Epoch 89/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3017 - val_loss: 1.3071\n",
      "Epoch 90/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3010 - val_loss: 1.2638\n",
      "Epoch 91/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3002 - val_loss: 1.3046\n",
      "Epoch 92/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3001 - val_loss: 1.2539\n",
      "Epoch 93/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2998 - val_loss: 1.2767\n",
      "Epoch 94/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2990 - val_loss: 1.2846\n",
      "Epoch 95/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2984 - val_loss: 1.2831\n",
      "Epoch 96/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2980 - val_loss: 1.3097\n",
      "Epoch 97/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2977 - val_loss: 1.2914\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2972 - val_loss: 1.2520\n",
      "Epoch 99/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2970 - val_loss: 1.2840\n",
      "Epoch 100/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2965 - val_loss: 1.3098\n",
      "121/121 [==============================] - 0s 671us/step - loss: 1.2685\n",
      "[CV] END learning_rate=0.0059640580092043885, n_hidden=3, n_neurons=80; total time=  29.5s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 1ms/step - loss: 4.9174 - val_loss: 5.5439\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.3737 - val_loss: 5.2214\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6414 - val_loss: 4.6298\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7984 - val_loss: 3.7444\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0520 - val_loss: 2.7948\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5343 - val_loss: 2.0981\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2240 - val_loss: 1.6993\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0325 - val_loss: 1.4464\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9181 - val_loss: 1.2690\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8465 - val_loss: 1.1484\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7984 - val_loss: 1.0553\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7634 - val_loss: 0.9827\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7361 - val_loss: 0.9267\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7140 - val_loss: 0.8807\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6955 - val_loss: 0.8418\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6796 - val_loss: 0.8088\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6658 - val_loss: 0.7805\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6536 - val_loss: 0.7555\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6427 - val_loss: 0.7345\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6331 - val_loss: 0.7167\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6244 - val_loss: 0.7009\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6166 - val_loss: 0.6870\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6096 - val_loss: 0.6743\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6031 - val_loss: 0.6628\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5974 - val_loss: 0.6525\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5920 - val_loss: 0.6433\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5872 - val_loss: 0.6349\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5828 - val_loss: 0.6271\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5786 - val_loss: 0.6201\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5749 - val_loss: 0.6136\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5714 - val_loss: 0.6077\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5682 - val_loss: 0.6024\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5652 - val_loss: 0.5973\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5624 - val_loss: 0.5927\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5598 - val_loss: 0.5884\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5574 - val_loss: 0.5845\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5552 - val_loss: 0.5804\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5531 - val_loss: 0.5770\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5510 - val_loss: 0.5736\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5492 - val_loss: 0.5708\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5474 - val_loss: 0.5681\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5457 - val_loss: 0.5656\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5442 - val_loss: 0.5632\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5427 - val_loss: 0.5611\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5414 - val_loss: 0.5592\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5400 - val_loss: 0.5574\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5389 - val_loss: 0.5558\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5378 - val_loss: 0.5543\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5368 - val_loss: 0.5529\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5359 - val_loss: 0.5515\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5350 - val_loss: 0.5503\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5341 - val_loss: 0.5492\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5333 - val_loss: 0.5482\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5325 - val_loss: 0.5472\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5317 - val_loss: 0.5463\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5310 - val_loss: 0.5453\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5303 - val_loss: 0.5445\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5296 - val_loss: 0.5436\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5290 - val_loss: 0.5427\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5282 - val_loss: 0.5420\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5277 - val_loss: 0.5413\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5271 - val_loss: 0.5414\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5265 - val_loss: 0.5413\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5260 - val_loss: 0.5413\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5254 - val_loss: 0.5413\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5249 - val_loss: 0.5412\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5243 - val_loss: 0.5414\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5238 - val_loss: 0.5417\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5233 - val_loss: 0.5419\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5227 - val_loss: 0.5422\n",
      "Epoch 71/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5223 - val_loss: 0.5425\n",
      "Epoch 72/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5217 - val_loss: 0.5428\n",
      "Epoch 73/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5213 - val_loss: 0.5429\n",
      "Epoch 74/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5208 - val_loss: 0.5430\n",
      "Epoch 75/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5204 - val_loss: 0.5431\n",
      "Epoch 76/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5199 - val_loss: 0.5433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "121/121 [==============================] - 0s 683us/step - loss: 0.5308\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  22.0s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.0437 - val_loss: 6.3250\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.4811 - val_loss: 6.8387\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.6933 - val_loss: 7.5295\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.7754 - val_loss: 8.0439\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.0057 - val_loss: 7.9618\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.5170 - val_loss: 7.3592\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.2418 - val_loss: 6.4844\n",
      "Epoch 8/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0870 - val_loss: 5.5777\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9923 - val_loss: 4.8213\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9327 - val_loss: 4.1629\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8873 - val_loss: 3.5805\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8487 - val_loss: 3.0742\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8165 - val_loss: 2.6468\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7908 - val_loss: 2.2933\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7698 - val_loss: 2.0168\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7483 - val_loss: 1.7919\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7201 - val_loss: 1.6003\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6970 - val_loss: 1.4440\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6796 - val_loss: 1.3388\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6657 - val_loss: 1.2525\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6539 - val_loss: 1.1768\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6435 - val_loss: 1.1149\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6344 - val_loss: 1.0707\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6262 - val_loss: 1.0414\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6189 - val_loss: 1.0149\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6122 - val_loss: 0.9910\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6061 - val_loss: 0.9695\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6005 - val_loss: 0.9495\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5953 - val_loss: 0.9325\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5907 - val_loss: 0.9157\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5863 - val_loss: 0.9006\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5823 - val_loss: 0.8871\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5786 - val_loss: 0.8748\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5752 - val_loss: 0.8639\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5720 - val_loss: 0.8539\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5691 - val_loss: 0.8444\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5664 - val_loss: 0.8362\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5639 - val_loss: 0.8281\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5616 - val_loss: 0.8212\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5595 - val_loss: 0.8153\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5575 - val_loss: 0.8098\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5556 - val_loss: 0.8048\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5539 - val_loss: 0.7997\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5523 - val_loss: 0.7956\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5507 - val_loss: 0.7921\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5493 - val_loss: 0.7882\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5479 - val_loss: 0.7853\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5466 - val_loss: 0.7829\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5455 - val_loss: 0.7807\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5444 - val_loss: 0.7783\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5433 - val_loss: 0.7760\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5423 - val_loss: 0.7748\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5413 - val_loss: 0.7733\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5403 - val_loss: 0.7724\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5394 - val_loss: 0.7716\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5386 - val_loss: 0.7709\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5377 - val_loss: 0.7700\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5370 - val_loss: 0.7701\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5362 - val_loss: 0.7700\n",
      "Epoch 60/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5353 - val_loss: 0.7696\n",
      "Epoch 61/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5346 - val_loss: 0.7704\n",
      "Epoch 62/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5339 - val_loss: 0.7709\n",
      "Epoch 63/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5332 - val_loss: 0.7712\n",
      "Epoch 64/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5326 - val_loss: 0.7720\n",
      "Epoch 65/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5318 - val_loss: 0.7731\n",
      "Epoch 66/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5313 - val_loss: 0.7742\n",
      "Epoch 67/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5307 - val_loss: 0.7750\n",
      "Epoch 68/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5300 - val_loss: 0.7765\n",
      "Epoch 69/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5294 - val_loss: 0.7779\n",
      "Epoch 70/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5288 - val_loss: 0.7786\n",
      "121/121 [==============================] - 0s 700us/step - loss: 0.5438\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  20.9s\n",
      "Epoch 1/100\n",
      "242/242 [==============================] - 1s 2ms/step - loss: 5.2416 - val_loss: 5.3124\n",
      "Epoch 2/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.7968 - val_loss: 4.9512\n",
      "Epoch 3/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 4.1231 - val_loss: 4.3701\n",
      "Epoch 4/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 3.2399 - val_loss: 3.6036\n",
      "Epoch 5/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 2.3506 - val_loss: 2.7648\n",
      "Epoch 6/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.7105 - val_loss: 2.1536\n",
      "Epoch 7/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.3582 - val_loss: 1.7578\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 0s 1ms/step - loss: 1.1835 - val_loss: 1.4925\n",
      "Epoch 9/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0733 - val_loss: 1.3070\n",
      "Epoch 10/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 1.0042 - val_loss: 1.1876\n",
      "Epoch 11/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9600 - val_loss: 1.0988\n",
      "Epoch 12/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.9193 - val_loss: 1.0249\n",
      "Epoch 13/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8646 - val_loss: 0.9524\n",
      "Epoch 14/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.8220 - val_loss: 0.9052\n",
      "Epoch 15/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7969 - val_loss: 0.8718\n",
      "Epoch 16/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7796 - val_loss: 0.8450\n",
      "Epoch 17/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7657 - val_loss: 0.8231\n",
      "Epoch 18/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7536 - val_loss: 0.8042\n",
      "Epoch 19/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7429 - val_loss: 0.7871\n",
      "Epoch 20/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7328 - val_loss: 0.7718\n",
      "Epoch 21/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7230 - val_loss: 0.7574\n",
      "Epoch 22/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.7122 - val_loss: 0.7411\n",
      "Epoch 23/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6865 - val_loss: 0.6956\n",
      "Epoch 24/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6426 - val_loss: 0.6626\n",
      "Epoch 25/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6211 - val_loss: 0.6457\n",
      "Epoch 26/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6101 - val_loss: 0.6350\n",
      "Epoch 27/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.6030 - val_loss: 0.6267\n",
      "Epoch 28/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5975 - val_loss: 0.6199\n",
      "Epoch 29/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5928 - val_loss: 0.6141\n",
      "Epoch 30/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5887 - val_loss: 0.6087\n",
      "Epoch 31/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5850 - val_loss: 0.6042\n",
      "Epoch 32/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5816 - val_loss: 0.6001\n",
      "Epoch 33/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5785 - val_loss: 0.5964\n",
      "Epoch 34/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5756 - val_loss: 0.5933\n",
      "Epoch 35/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5731 - val_loss: 0.5903\n",
      "Epoch 36/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5706 - val_loss: 0.5876\n",
      "Epoch 37/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5684 - val_loss: 0.5852\n",
      "Epoch 38/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5663 - val_loss: 0.5831\n",
      "Epoch 39/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5644 - val_loss: 0.5813\n",
      "Epoch 40/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5626 - val_loss: 0.5798\n",
      "Epoch 41/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5610 - val_loss: 0.5786\n",
      "Epoch 42/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5595 - val_loss: 0.5774\n",
      "Epoch 43/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5580 - val_loss: 0.5761\n",
      "Epoch 44/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5567 - val_loss: 0.5753\n",
      "Epoch 45/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5554 - val_loss: 0.5744\n",
      "Epoch 46/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5542 - val_loss: 0.5737\n",
      "Epoch 47/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5530 - val_loss: 0.5730\n",
      "Epoch 48/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5520 - val_loss: 0.5726\n",
      "Epoch 49/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5509 - val_loss: 0.5725\n",
      "Epoch 50/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5500 - val_loss: 0.5728\n",
      "Epoch 51/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5490 - val_loss: 0.5739\n",
      "Epoch 52/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5482 - val_loss: 0.5743\n",
      "Epoch 53/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5473 - val_loss: 0.5740\n",
      "Epoch 54/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5465 - val_loss: 0.5738\n",
      "Epoch 55/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5456 - val_loss: 0.5737\n",
      "Epoch 56/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5449 - val_loss: 0.5740\n",
      "Epoch 57/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5442 - val_loss: 0.5747\n",
      "Epoch 58/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5435 - val_loss: 0.5751\n",
      "Epoch 59/100\n",
      "242/242 [==============================] - 0s 1ms/step - loss: 0.5427 - val_loss: 0.5752\n",
      "121/121 [==============================] - 0s 692us/step - loss: 0.5325\n",
      "[CV] END learning_rate=0.004591455636549438, n_hidden=2, n_neurons=59; total time=  18.4s\n",
      "Epoch 1/100\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 2.3428 - val_loss: 0.8916\n",
      "Epoch 2/100\n",
      "363/363 [==============================] - 0s 990us/step - loss: 0.6317 - val_loss: 0.5053\n",
      "Epoch 3/100\n",
      "363/363 [==============================] - 0s 993us/step - loss: 0.5330 - val_loss: 0.4733\n",
      "Epoch 4/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.5062 - val_loss: 0.4627\n",
      "Epoch 5/100\n",
      "363/363 [==============================] - 0s 986us/step - loss: 0.4944 - val_loss: 0.4429\n",
      "Epoch 6/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4807 - val_loss: 0.4441\n",
      "Epoch 7/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.4809 - val_loss: 0.4365\n",
      "Epoch 8/100\n",
      "363/363 [==============================] - 0s 985us/step - loss: 0.4776 - val_loss: 0.4348\n",
      "Epoch 9/100\n",
      "363/363 [==============================] - 0s 997us/step - loss: 0.4738 - val_loss: 0.4371\n",
      "Epoch 10/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4743 - val_loss: 0.4333\n",
      "Epoch 11/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.4721 - val_loss: 0.4317\n",
      "Epoch 12/100\n",
      "363/363 [==============================] - 0s 989us/step - loss: 0.4726 - val_loss: 0.4320\n",
      "Epoch 13/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4728 - val_loss: 0.4314\n",
      "Epoch 14/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4747 - val_loss: 0.4319\n",
      "Epoch 15/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4729 - val_loss: 0.4319\n",
      "Epoch 16/100\n",
      "363/363 [==============================] - 0s 971us/step - loss: 0.4730 - val_loss: 0.4309\n",
      "Epoch 17/100\n",
      "363/363 [==============================] - 0s 968us/step - loss: 0.4724 - val_loss: 0.4311\n",
      "Epoch 18/100\n",
      "363/363 [==============================] - 0s 977us/step - loss: 0.4737 - val_loss: 0.4311\n",
      "Epoch 19/100\n",
      "363/363 [==============================] - 0s 974us/step - loss: 0.4724 - val_loss: 0.4318\n",
      "Epoch 20/100\n",
      "363/363 [==============================] - 0s 979us/step - loss: 0.4739 - val_loss: 0.4319\n",
      "Epoch 21/100\n",
      "363/363 [==============================] - 0s 981us/step - loss: 0.4727 - val_loss: 0.4317\n",
      "Epoch 22/100\n",
      "363/363 [==============================] - 0s 983us/step - loss: 0.4730 - val_loss: 0.4315\n",
      "Epoch 23/100\n",
      "363/363 [==============================] - 0s 992us/step - loss: 0.4732 - val_loss: 0.4312\n",
      "Epoch 24/100\n",
      "363/363 [==============================] - 0s 994us/step - loss: 0.4718 - val_loss: 0.4323\n",
      "Epoch 25/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4704 - val_loss: 0.4347\n",
      "Epoch 26/100\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4718 - val_loss: 0.4320\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020381078DC0&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=3,\n",
       "                   estimator=&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020381078DC0&gt;,\n",
       "                   param_distributions={&#x27;learning_rate&#x27;: [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        &#x27;n_hidden&#x27;: [0, 1, 2, 3],\n",
       "                                        &#x27;n_neurons&#x27;: [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020381078DC0&gt;</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KerasRegressor</label><div class=\"sk-toggleable__content\"><pre>&lt;keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020381078DC0&gt;</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=<keras.wrappers.scikit_learn.KerasRegressor object at 0x0000020381078DC0>,\n",
       "                   param_distributions={'learning_rate': [0.001683454924600351,\n",
       "                                                          0.02390836445593178,\n",
       "                                                          0.008731907739399206,\n",
       "                                                          0.004725396149933917,\n",
       "                                                          0.0006154014789262348,\n",
       "                                                          0.0006153331256530192,\n",
       "                                                          0.0003920021771415983,\n",
       "                                                          0.01619845322936229,\n",
       "                                                          0.004779156784872302,\n",
       "                                                          0.007821074275112...\n",
       "                                                          0.005021425736625637,\n",
       "                                                          0.0005703073595961105,\n",
       "                                                          0.001151888789941251,\n",
       "                                                          0.001621231156394198,\n",
       "                                                          0.0024505367684280487,\n",
       "                                                          0.011155092541719619,\n",
       "                                                          0.0007524347058135697,\n",
       "                                                          0.0032032448128444043,\n",
       "                                                          0.004591455636549438,\n",
       "                                                          0.0003715541189658278, ...],\n",
       "                                        'n_hidden': [0, 1, 2, 3],\n",
       "                                        'n_neurons': [1, 2, 3, 4, 5, 6, 7, 8, 9,\n",
       "                                                      10, 11, 12, 13, 14, 15,\n",
       "                                                      16, 17, 18, 19, 20, 21,\n",
       "                                                      22, 23, 24, 25, 26, 27,\n",
       "                                                      28, 29, 30, ...]},\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1, 2, 3],\n",
    "    \"n_neurons\": np.arange(1, 100)               .tolist(),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2)      .rvs(1000).tolist(),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(ker_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=100,\n",
    "                  validation_data=(X_val, y_val),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ac102b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neurons': 4, 'n_hidden': 1, 'learning_rate': 0.022174573948353458}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d92df54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aa40200b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = rnd_search_cv.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4cc2eb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162/162 [==============================] - 0s 733us/step - loss: 0.4647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4647384285926819"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b456a305",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
