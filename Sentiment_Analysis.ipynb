{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/NickSlm/ml1/blob/main/Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pCdUlU7Gm_Om"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bh-mRROQCspp"
   },
   "outputs": [],
   "source": [
    "dataset = keras.datasets.imdb.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RPsr_docGzBO"
   },
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-M_YgHsKG44Y"
   },
   "outputs": [],
   "source": [
    "test_seq = X_train[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jk_-OttSY2A2"
   },
   "outputs": [],
   "source": [
    "word_index = keras.datasets.imdb.get_word_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "NBZUcWQfcysa",
    "outputId": "e9d4ef6b-a0ee-484e-9562-5491ac0bd33f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[START] this film was just brilliant casting location scenery story'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word = dict((id_ + 3,word) for word, id_ in word_index.items())\n",
    "id_to_word [1] = \"[START]\"\n",
    "id_to_word [2] = \"[OOV]\"\n",
    "\" \".join(id_to_word[id_] for id_ in test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "YAKON2Mpqway"
   },
   "outputs": [],
   "source": [
    "dataset, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "QClzRpn2uQvS"
   },
   "outputs": [],
   "source": [
    "train_size = info.splits[\"train\"].num_examples\n",
    "test_size = info.splits[\"test\"].num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cRUo9-GVvyhI"
   },
   "outputs": [],
   "source": [
    "def preprocess(X_batch, y_batch):\n",
    "  X_batch = tf.strings.substr(X_batch, 0, 300)\n",
    "  X_batch = tf.strings.regex_replace(X_batch, rb\"<br\\s*/?>\", b\" \")    # replace all <br>, <br/>\n",
    "  X_batch = tf.strings.regex_replace(X_batch, b\"[^a-zA-Z']\", b\" \")\n",
    "  X_batch = tf.strings.split(X_batch)\n",
    "  return X_batch.to_tensor(default_value=b\"<pad>\"), y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "X4YAOqcxKEM3"
   },
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cp1jS21OLiUU"
   },
   "outputs": [],
   "source": [
    "vocab = Counter()\n",
    "for X_batch, y_batch in dataset[\"train\"].batch(32).map(preprocess):\n",
    "  for review in X_batch:\n",
    "    vocab.update(list(review.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "GbDvx0xrL3Zl"
   },
   "outputs": [],
   "source": [
    "n_words = 10000\n",
    "truncated_vocab = [word for word, times in vocab.most_common()[:n_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QTYB2N5AY8x5"
   },
   "outputs": [],
   "source": [
    "word_ids = tf.range(len(truncated_vocab), dtype=tf.int64)\n",
    "words = tf.constant(truncated_vocab)\n",
    "table_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n",
    "oov_buckets = 1000\n",
    "table = tf.lookup.StaticVocabularyTable(table_init, oov_buckets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6mKoomvcioPS",
    "outputId": "691bc111-e09c-4720-eb94-b092556cc82d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int64, numpy=array([[   22,    12,    11, 10053]])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.lookup(tf.constant([b\"This movie was faaaaaantastic\".split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "YiSfBjip9fIS"
   },
   "outputs": [],
   "source": [
    "def encode_words(X_batch, y_batch):\n",
    "  return table.lookup(X_batch), y_batch\n",
    "\n",
    "train_set = dataset[\"train\"].batch(32).map(preprocess)\n",
    "train_set = train_set.map(encode_words).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DBXrhuDeBL52"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(n_words + oov_buckets, 128, mask_zero = True, input_shape=[None]),\n",
    "    keras.layers.GRU(128, return_sequences=True),\n",
    "    keras.layers.GRU(128),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okB_ADkc1zuS"
   },
   "source": [
    "Reusing Pretrained Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "zRE1sMYeNF4X"
   },
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "E3TzWr3t2JIG"
   },
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\",\n",
    "                   dtype=tf.string, input_shape=[], output_shape=[50]),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "iE4APKU-2XU4"
   },
   "outputs": [],
   "source": [
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "batch_size = 32\n",
    "train_set = datasets[\"train\"].batch(batch_size).prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WvZ2AUd18BsR",
    "outputId": "5c8435c1-0674-4a74-9f51-e89b8e830007"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "782/782 [==============================] - 13s 14ms/step - loss: 0.5472 - accuracy: 0.7266\n",
      "Epoch 2/5\n",
      "782/782 [==============================] - 8s 10ms/step - loss: 0.5145 - accuracy: 0.7466\n",
      "Epoch 3/5\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5093 - accuracy: 0.7508\n",
      "Epoch 4/5\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5057 - accuracy: 0.7533\n",
      "Epoch 5/5\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.5027 - accuracy: 0.7564\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_set, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "lx7hVUfS8KNS"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNjsxs6ZLVZhJZfr3GIRtHd",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
