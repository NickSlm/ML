{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de242d8c-e91d-47a7-8266-cfa065be4abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 12:04:19.057457: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-14 12:04:19.093779: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-14 12:04:19.093818: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-14 12:04:19.094559: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-14 12:04:19.099895: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-14 12:04:19.100942: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-14 12:04:19.746284: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59ac08f-2ca0-4d6f-bbeb-f97ee80a61cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = \"https://github.com/ageron/handson-ml2/raw/master/datasets/jsb_chorales/\"\n",
    "FILENAME = \"jsb_chorales.tgz\"\n",
    "filepath = keras.utils.get_file(FILENAME, DOWNLOAD_ROOT + FILENAME, \n",
    "                     cache_subdir=\"datasets/jsb_chorales\", \n",
    "                     extract=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11c38e9c-6ed7-436d-be3a-08769221f8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "jsb_chorales_dir = Path(filepath).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43a272b9-e89d-47e2-aa20-7c14b563b341",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = sorted([str(file) for file in jsb_chorales_dir.glob(\"train/chorale_*\")])\n",
    "test_files = sorted([str(file) for file in jsb_chorales_dir.glob(\"test/chorale_*\")])\n",
    "val_files = sorted([str(file) for file in jsb_chorales_dir.glob(\"valid/chorale_*\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "691740df-6655-4c45-ab0f-1ff2cc1c0488",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa010135-73cf-4d13-8d66-bc7ce8046128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/nick/.keras/datasets/jsb_chorales/train/chorale_000.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_001.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_002.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_003.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_004.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_005.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_006.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_007.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_008.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_009.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_010.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_011.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_012.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_013.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_014.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_015.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_016.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_017.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_018.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_019.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_020.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_021.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_022.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_023.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_024.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_025.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_026.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_027.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_028.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_029.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_030.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_031.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_032.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_033.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_034.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_035.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_036.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_037.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_038.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_039.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_040.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_041.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_042.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_043.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_044.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_045.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_046.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_047.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_048.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_049.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_050.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_051.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_052.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_053.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_054.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_055.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_056.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_057.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_058.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_059.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_060.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_061.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_062.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_063.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_064.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_065.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_066.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_067.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_068.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_069.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_070.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_071.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_072.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_073.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_074.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_075.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_076.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_077.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_078.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_079.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_080.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_081.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_082.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_083.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_084.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_085.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_086.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_087.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_088.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_089.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_090.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_091.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_092.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_093.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_094.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_095.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_096.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_097.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_098.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_099.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_100.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_101.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_102.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_103.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_104.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_105.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_106.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_107.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_108.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_109.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_110.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_111.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_112.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_113.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_114.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_115.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_116.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_117.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_118.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_119.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_120.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_121.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_122.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_123.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_124.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_125.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_126.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_127.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_128.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_129.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_130.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_131.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_132.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_133.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_134.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_135.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_136.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_137.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_138.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_139.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_140.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_141.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_142.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_143.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_144.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_145.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_146.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_147.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_148.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_149.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_150.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_151.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_152.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_153.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_154.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_155.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_156.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_157.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_158.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_159.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_160.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_161.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_162.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_163.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_164.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_165.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_166.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_167.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_168.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_169.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_170.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_171.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_172.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_173.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_174.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_175.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_176.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_177.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_178.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_179.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_180.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_181.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_182.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_183.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_184.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_185.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_186.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_187.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_188.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_189.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_190.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_191.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_192.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_193.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_194.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_195.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_196.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_197.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_198.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_199.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_200.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_201.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_202.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_203.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_204.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_205.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_206.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_207.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_208.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_209.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_210.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_211.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_212.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_213.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_214.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_215.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_216.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_217.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_218.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_219.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_220.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_221.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_222.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_223.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_224.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_225.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_226.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_227.csv',\n",
       " '/home/nick/.keras/datasets/jsb_chorales/train/chorale_228.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77d1ce80-b6bc-4d2f-8712-2627d46c483c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chorales(filepaths):\n",
    "    return [pd.read_csv(filepath).values.tolist() for filepath in filepaths]\n",
    "\n",
    "train_chorales = load_chorales(train_files)\n",
    "test_chorales = load_chorales(test_files)\n",
    "val_chorales = load_chorales(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8db13c51-1009-4644-a169-cfb2b854a309",
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = set()\n",
    "for chorales in (train_chorales, test_chorales, val_chorales):\n",
    "    for chorale in chorales:\n",
    "        for chord in chorale:\n",
    "            notes = notes | set(chord)\n",
    "            \n",
    "n_notes = len(notes)\n",
    "min_note = min(notes - {0})\n",
    "max_note = max(notes)\n",
    "\n",
    "assert min_note == 36\n",
    "assert max_note == 81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40be741e-458f-416a-9c65-05044a9722f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target(batch):\n",
    "    X = batch[:, :-1]\n",
    "    Y = batch[:, 1:] # predict next note in each arpegio, at each step\n",
    "    return X, Y\n",
    "\n",
    "def preprocess(window):\n",
    "    \"\"\"\n",
    "    Converts the values of the notes from 36-81 to 1-46\n",
    "    \"\"\"\n",
    "    window = tf.where(window == 0, window, window - min_note + 1) # every note that is not 0 reduce by 36 + 1(for 0 note)\n",
    "    return tf.reshape(window, [-1]) # convert to arpegio\n",
    "\n",
    "def bach_dataset(chorales, batch_size=32, shuffle_buffer_size=None,\n",
    "                 window_size=32, window_shift=16, cache=True):\n",
    "    \n",
    "    def batch_window(window):\n",
    "        return window.batch(window_size + 1)\n",
    "\n",
    "    def to_windows(chorale):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices(chorale)\n",
    "        dataset = dataset.window(window_size + 1, window_shift, drop_remainder=True)\n",
    "        return dataset.flat_map(batch_window)\n",
    "\n",
    "    chorales = tf.ragged.constant(chorales, ragged_rank=1)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(chorales)\n",
    "    dataset = dataset.flat_map(to_windows).map(preprocess)\n",
    "    if cache:\n",
    "        dataset = dataset.cache()\n",
    "    if shuffle_buffer_size:\n",
    "        dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(create_target)\n",
    "    return dataset.prefetch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e19a253-8a4c-4e7a-bd70-4c35c573ff4d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(32, 131), dtype=int32, numpy=\n",
      "array([[30, 25, 22, ..., 37, 32, 25],\n",
      "       [37, 30, 25, ..., 41, 32, 29],\n",
      "       [37, 32, 25, ..., 34, 30, 25],\n",
      "       ...,\n",
      "       [39, 34, 31, ..., 41, 31, 26],\n",
      "       [38, 33, 21, ..., 38, 29, 22],\n",
      "       [41, 31, 26, ..., 38, 29, 21]], dtype=int32)>, <tf.Tensor: shape=(32, 131), dtype=int32, numpy=\n",
      "array([[25, 22, 18, ..., 32, 25, 17],\n",
      "       [30, 25, 10, ..., 32, 29, 25],\n",
      "       [32, 25, 17, ..., 30, 25, 18],\n",
      "       ...,\n",
      "       [34, 31, 15, ..., 31, 26, 23],\n",
      "       [33, 21, 18, ..., 29, 22, 22],\n",
      "       [31, 26, 23, ..., 29, 21, 17]], dtype=int32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-14 12:04:43.329359: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "train_set = bach_dataset(train_chorales, shuffle_buffer_size=1000)\n",
    "valid_set = bach_dataset(val_chorales)\n",
    "test_set = bach_dataset(test_chorales)\n",
    "for i in test_set.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1541c0b-1fe3-425a-8b9b-f19696881556",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dims = 5\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=n_notes, output_dim=n_dims, input_shape=[None]),\n",
    "    keras.layers.Conv1D(32, kernel_size=2, padding=\"causal\", activation=\"relu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(48, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(64, kernel_size=2, padding=\"causal\",activation=\"relu\", dilation_rate=4),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv1D(96, kernel_size=2, padding=\"causal\", activation=\"relu\", dilation_rate=8),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LSTM(256, return_sequences=True),\n",
    "    keras.layers.Dense(n_notes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1b676b-cb92-4e99-9c89-a6753346555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam(learning_rate=1e-3)\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_set, epochs=20, validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f4a77-abbe-405e-91b6-4dc26c2c947f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chorale_v2(model, seed_chords, length, temperature=1):\n",
    "    arpegio = preprocess(tf.constant(seed_chords, dtype=tf.int64))\n",
    "    arpegio = tf.reshape(arpegio, [1, -1])\n",
    "    for chord in range(length):\n",
    "        for note in range(4):\n",
    "            next_note_probas = model.predict(arpegio)[0, -1:]\n",
    "            rescaled_logits = tf.math.log(next_note_probas) / temperature\n",
    "            next_note = tf.random.categorical(rescaled_logits, num_samples=1)\n",
    "            arpegio = tf.concat([arpegio, next_note], axis=1)\n",
    "    arpegio = tf.where(arpegio == 0, arpegio, arpegio + min_note - 1)\n",
    "    return tf.reshape(arpegio, shape=[-1, 4])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
