{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e837a9-18c9-4269-a93a-fcd768608bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 14:46:56.379806: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-25 14:46:56.417281: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-25 14:46:56.417313: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-25 14:46:56.418470: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-25 14:46:56.424658: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-25 14:46:56.425403: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-25 14:46:57.132461: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7fd963dd-eb76-4812-a240-22b3e7435ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "REBER_VOCAB = {\n",
    "    0: 'B',\n",
    "    1: 'T',\n",
    "    2: 'S',\n",
    "    3: 'X',\n",
    "    4: 'P',\n",
    "    5: 'V',\n",
    "    6: 'E',\n",
    "              }\n",
    "\n",
    "default_reber = {\n",
    "    0 : [('B', 1)],\n",
    "    1 : [('T', 2), ('P', 3)],\n",
    "    2 : [('S', 2), ('X', 4)],\n",
    "    3 : [('T', 3), ('V', 5)],\n",
    "    4 : [('X', 3), ('S', 6)],\n",
    "    5 : [('P', 4), ('V', 6)],\n",
    "    6 : [('E', None)]\n",
    "         }\n",
    "\n",
    "embedded_reber = {\n",
    "    0 : [('B', 1)], \n",
    "    1 : [('T', 2), ('P', 3)],\n",
    "    2 : [(default_reber, 4)],\n",
    "    3 : [(default_reber, 5)],\n",
    "    4 : [('T', 6)],\n",
    "    5 : [('P', 6)],\n",
    "    6 : [('E', None)]\n",
    "                 }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba9f4ee3-0c0b-4f31-a83f-35c326901e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_CHARS = \"BEPSTVX\"\n",
    "\n",
    "def generate_string(grammar):\n",
    "    state = 0\n",
    "    output = []\n",
    "    while state is not None:\n",
    "        rnd_index = np.random.randint(len(grammar[state]))\n",
    "        char, state = grammar[state][rnd_index]\n",
    "        if isinstance(char, dict):\n",
    "            char = generate_string(char)\n",
    "        output.append(char)\n",
    "    return ''.join(output)\n",
    "\n",
    "def generate_corrupted_string(grammar):\n",
    "    legal_string = generate_string(grammar)\n",
    "    illegal_string = list(legal_string)\n",
    "    index = np.random.randint(len(illegal_string))\n",
    "    good_char = legal_string[index]\n",
    "    bad_char = np.random.choice(sorted(set(POSSIBLE_CHARS) - set(good_char)))\n",
    "    return legal_string[:index] + bad_char + legal_string[index + 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a644ecb-5fa4-42f5-ae5a-a7ac407b79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(string):\n",
    "    return [list(REBER_VOCAB.keys())[list(REBER_VOCAB.values()).index(char)] for char in string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c2aa9d4-5747-4215-b817-55bb466e0a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples, legal_perc, illegal_perc):\n",
    "    legal_strings = []\n",
    "    illegal_strings = []\n",
    "\n",
    "    # legal\n",
    "    for _ in range(n_samples * legal_perc // 100):\n",
    "        legal_strings.append(generate_string(embedded_reber))\n",
    "    # Illegal\n",
    "    for _ in range(n_samples * illegal_perc // 100):\n",
    "        illegal_strings.append(generate_corrupted_string(embedded_reber))\n",
    "\n",
    "    return legal_strings, illegal_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f0a1bb-7d77-4376-a950-19e7ab7299a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data_file(filepath, n_samples, legal_perc=50, illegal_perc=50):\n",
    "\n",
    "    legal_strings, illegal_strings = generate_data(n_samples, legal_perc, legal_perc)\n",
    "    \n",
    "    with open(filepath, 'w') as file:\n",
    "        for legal_string in legal_strings:\n",
    "            file.write(legal_string + ',' + \"legal\")\n",
    "            file.write('\\n')\n",
    "        for illegal_string in illegal_strings:\n",
    "            file.write(illegal_string + ',' + \"illegal\")\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "832e6cbf-a36d-4cd5-9a20-49449daecd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = os.path.join('datasets', 'reber_grammar')\n",
    "file_path_train = os.path.join(dataset_dir, \"reber_strings_train_mine.txt\")\n",
    "file_path_test = os.path.join(dataset_dir, \"reber_strings_test_mine.txt\")\n",
    "\n",
    "N_SAMPLES = 25000\n",
    "train_size = N_SAMPLES * 80 // 100\n",
    "test_size = N_SAMPLES * 20 // 100\n",
    "\n",
    "generate_data_file(file_path_train, train_size)\n",
    "generate_data_file(file_path_test, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72530cd3-b999-4069-8766-11671285bc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filepath):\n",
    "    data = Path(filepath).read_text()\n",
    "    lines = data.splitlines()\n",
    "    pairs = [line.split(',') for line in lines]\n",
    "    X = np.array([X for X,Y in pairs])\n",
    "    Y = np.array([Y for X,Y in pairs])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7054c5-e982-435d-8f59-18e0505e3b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(X, Y):\n",
    "    X = tf.ragged.constant([vectorize_data(string) for string in X])\n",
    "    Y = np.array([[0.] if label == \"illegal\" else [1.] for label in Y])\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0300bb9d-d988-4754-b2cb-dd55f32cb195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(data, label, buffer_size, batch_size=32):\n",
    "        \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((data, label))\n",
    "    dataset = dataset.shuffle(buffer_size)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b3484be-86d6-44e8-8d4f-0a683c2d3f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 14:46:59.623824: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-25 14:46:59.653171: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "X_train, Y_train = load_data(Path(file_path_train))\n",
    "X_test, Y_test = load_data(Path(file_path_test))\n",
    "\n",
    "X_train, Y_train = process_data(X_train, Y_train)\n",
    "X_test, Y_test = process_data(X_test, Y_test)\n",
    "\n",
    "train_dataset = create_dataset(X_train, Y_train, buffer_size=train_size)\n",
    "test_dataset = create_dataset(X_test, Y_test, buffer_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8bd38bc-aaac-4bbd-804c-a36943ecfcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 13s 18ms/step - loss: 0.6683 - accuracy: 0.5640 - val_loss: 0.6446 - val_accuracy: 0.6312\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.6417 - accuracy: 0.5922 - val_loss: 0.6182 - val_accuracy: 0.6438\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.6072 - accuracy: 0.6468 - val_loss: 0.5464 - val_accuracy: 0.7128\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.4077 - accuracy: 0.8190 - val_loss: 0.2325 - val_accuracy: 0.9384\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.1291 - accuracy: 0.9622 - val_loss: 0.0608 - val_accuracy: 0.9882\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.0489 - accuracy: 0.9915 - val_loss: 0.0437 - val_accuracy: 0.9930\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 0.0374 - accuracy: 0.9936 - val_loss: 0.0360 - val_accuracy: 0.9932\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 0.0378 - accuracy: 0.9913 - val_loss: 0.0367 - val_accuracy: 0.9898\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 0.0258 - accuracy: 0.9919 - val_loss: 0.0076 - val_accuracy: 0.9932\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 0.0037 - accuracy: 0.9999 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 9.5272e-04 - accuracy: 1.0000 - val_loss: 8.2965e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 6.7753e-04 - accuracy: 1.0000 - val_loss: 6.1756e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 5.2197e-04 - accuracy: 1.0000 - val_loss: 4.9133e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 4.2229e-04 - accuracy: 1.0000 - val_loss: 4.0367e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 3.5250e-04 - accuracy: 1.0000 - val_loss: 3.4219e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 3.0165e-04 - accuracy: 1.0000 - val_loss: 2.9631e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 2.6333e-04 - accuracy: 1.0000 - val_loss: 2.6047e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "625/625 [==============================] - 10s 17ms/step - loss: 2.3298e-04 - accuracy: 1.0000 - val_loss: 2.3230e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "625/625 [==============================] - 11s 17ms/step - loss: 2.0865e-04 - accuracy: 1.0000 - val_loss: 2.0881e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    # keras.layers.InputLayer(input_shape=[None], dtype=tf.int32, ragged=True),\n",
    "    keras.layers.Embedding(input_dim=len(REBER_VOCAB), output_dim=512, input_shape=[None]),\n",
    "    keras.layers.GRU(30),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-02, momentum=0.95, nesterov=True)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit(train_dataset, epochs=20, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e3b1c1a-8fa8-435d-bb20-e7c656955fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 288ms/step\n",
      "\n",
      "Estimated probability that these are Reber strings:\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE: 1.20%\n",
      "BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE: 99.99%\n"
     ]
    }
   ],
   "source": [
    "test_strings = [\"BPBTSSSSSSSXXTTVPXVPXTTTTTVVETE\",\n",
    "                \"BPBTSSSSSSSXXTTVPXVPXTTTTTVVEPE\"]\n",
    "\n",
    "X_test = tf.ragged.constant([vectorize_data(string) for string in test_strings], ragged_rank=1)\n",
    "\n",
    "y_proba = model.predict(X_test)\n",
    "print()\n",
    "print(\"Estimated probability that these are Reber strings:\")\n",
    "for index, string in enumerate(test_strings):\n",
    "    print(\"{}: {:.2f}%\".format(string, 100 * y_proba[index][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57060517-6c7b-49eb-b416-5aaf92552e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
