{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a00a08a-1ab8-46c0-8564-7d389c70d4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-07 09:58:14.368460: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-07 09:58:16.070731: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/nick/miniconda3/envs/tf_env/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/nick/miniconda3/envs/tf_env/lib/\n",
      "2024-11-07 09:58:16.070878: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/nick/miniconda3/envs/tf_env/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/nick/miniconda3/envs/tf_env/lib/\n",
      "2024-11-07 09:58:16.070887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gymnasium\n",
    "from gymnasium.wrappers import AtariPreprocessing\n",
    "from gymnasium.wrappers import FrameStackObservation, TimeLimit\n",
    "from collections import deque\n",
    "import ale_py\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "909982d5-357a-42a3-b658-2ec2cf52873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"BreakoutNoFrameskip-v4\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf58f29-3045-47d4-b4fb-34390c385bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AtariPreprocessingFire(AtariPreprocessing):\n",
    "    def reset(self, **kwargs):\n",
    "        obs, reset_info = super().reset(**kwargs)\n",
    "        super().step(1)\n",
    "        return obs, reset_info\n",
    "    def step(self, action):\n",
    "        self.lives_before_action = self.ale.lives()\n",
    "        obs, rewards, terminated, truncated, info = super().step(action)\n",
    "        done = terminated or truncated\n",
    "        if not done and self.ale.lives() < self.lives_before_action:\n",
    "            super().step(1)\n",
    "        return obs, rewards, terminated, truncated, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "506bb123-c230-402a-8c31-0004aa0c09f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: CPU random generator seem to be failing, disabling hardware random number generation\n",
      "WARNING: RDRND generated: 0xffffffff 0xffffffff 0xffffffff 0xffffffff\n"
     ]
    }
   ],
   "source": [
    "env = AtariPreprocessingFire(env)\n",
    "env = FrameStackObservation(env, stack_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde1ef87-7f82-4837-96e5-fe630d791e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_observation(obs):\n",
    "    obs = obs.astype(np.float32)\n",
    "    img = obs[:3]\n",
    "    current_frame_delta = np.maximum(obs[3] - obs[:3].mean(axis=0), 0.)\n",
    "    img[0] += current_frame_delta\n",
    "    img[2] += current_frame_delta\n",
    "    img = np.clip(img / 150, 0, 1)\n",
    "    img = np.transpose(img, (1,2,0))\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01918706-44a8-440d-a6a5-39d5ce63e141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (channels, height, width)\n",
    "# (observation, reward, terminated, truncated, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0efbf55-b8e8-4e9d-b5d5-b6bd7bd7253d",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_net = keras.models.Sequential([\n",
    "    keras.layers.Input(shape=env.observation_space.shape),\n",
    "    keras.layers.Lambda(lambda obs: tf.cast(obs, np.float32) / 255.),\n",
    "    keras.layers.Conv2D(32, (8,8), strides=4, activation=\"relu\", data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(64, (4,4), strides=2, activation=\"relu\", data_format=\"channels_first\"),\n",
    "    keras.layers.Conv2D(64, (3,3), strides=1, activation=\"relu\", data_format=\"channels_first\"),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation=\"relu\"),\n",
    "    keras.layers.Dense(4)\n",
    "])\n",
    "\n",
    "target_net = keras.models.clone_model(q_net)\n",
    "target_net.set_weights(q_net.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78afd72a-5066-47b5-824f-daaee65fe94c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(obs, action_space, epsilon):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return action_space.sample()\n",
    "    else:\n",
    "        q_values = q_net.predict(obs)\n",
    "        return np.argmax(q_values)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6cc1c3ab-3d8c-48b0-8f98-0b5164c87695",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_period = 4\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=2.5e-4, rho=0.95, momentum=0.0, epsilon=1e-5, centered=True)\n",
    "epsilon_fn = keras.optimizers.schedules.PolynomialDecay(initial_learning_rate=1.0,\n",
    "                                          decay_steps=250000 // update_period,\n",
    "                                          end_learning_rate=0.01)\n",
    "replay_buffer = deque(maxlen=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b75ee946-138a-4629-a2d1-1602794196df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_experience(state, env):\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, terminated, truncated, info = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    replay_buffer.append((state, action, reward, next_state, done))\n",
    "    return next_state, done\n",
    "\n",
    "\n",
    "def init_collect_policy(env, n_steps):\n",
    "    \"\"\"\n",
    "    Saves initial experiences before training\n",
    "    \"\"\"\n",
    "    obs, _ = env.reset()\n",
    "    for step in range(n_steps):\n",
    "        obs, done = save_experience(obs, env)\n",
    "        if done:\n",
    "            obs, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1215fe4-3bc0-4be0-b7d5-5e654820ebae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_driver(n_steps, episodes=0):\n",
    "    obs, _ = env.reset()\n",
    "    episodes = +1\n",
    "    for step in range(n_steps):\n",
    "        obs, done = save_experience(obs, env)\n",
    "        n_buffer += 1\n",
    "        if n_buffer % 4 == 0\n",
    "            training_step()\n",
    "            n_buffer = 0\n",
    "        if done:\n",
    "            return episodes, _, _, _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d502ca5-5b80-41cb-8615-ddac0ee18dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_collect_policy(env, n_steps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3235cae-c774-4a36-9d75-6dfb2bd5e75e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'n_iterations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m iteration \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mn_iterations\u001b[49m):\n\u001b[1;32m      2\u001b[0m     obs, _ \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mreset()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'n_iterations' is not defined"
     ]
    }
   ],
   "source": [
    "training_n_iterations = 50000\n",
    "env_n_steps = 27000\n",
    "\n",
    "# logs\n",
    "number_of_episodes = 0\n",
    "environment_steps = 0\n",
    "average_return = 0\n",
    "average_episode_length = 0\n",
    "\n",
    "\n",
    "for iteration in range(training_n_iterations):\n",
    "\n",
    "    episodes = collect_policy(n_steps=env_n_steps)\n",
    "\n",
    "    \n",
    "    if iteration % target_update_period == 0:\n",
    "        target_net.set_weights(q_net.get_weights())\n",
    "    if iteration % 1000 == 0:\n",
    "        print(episodes, environment_steps,)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b095f-e875-4d65-a6db-b33a82406e8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
