{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2282847d-403d-46bc-8f9b-b046e2c4bb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:18:25.459124: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-05 16:18:25.491214: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-05 16:18:25.491247: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-05 16:18:25.492013: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-05 16:18:25.496961: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-02-05 16:18:25.497820: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-05 16:18:26.173298: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import tensorflow_text as tf_text\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb164b7e-b793-41b6-9c19-a2950318cf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw_data(path, filename):\n",
    "    \"\"\"\n",
    "    Pull raw data from the provided filepath\n",
    "    \"\"\"\n",
    "    filepath = os.path.join(path, filename)\n",
    "    with open(filepath, \"r\") as f:\n",
    "        sentences = f.readlines()\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cdc0091-a5de-4e7a-944c-e68f29a77e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(raw_data, train_size=0.8, test_size=0.2, val_size=0.2):\n",
    "    \"\"\"\n",
    "    Input: raw_data(array), train_size, test_size, val_size(Percentage)\n",
    "    Shuffles the data and splits it into (input, output).\n",
    "    Returns train_data, test_data, val_data\n",
    "    \"\"\"\n",
    "    raw_data = np.array([sen.split('\\t') for sen in raw_data])\n",
    "    np.random.shuffle(raw_data)\n",
    "    X, y = raw_data[:,0], raw_data[:,1]\n",
    "\n",
    "    X, X_test, y, y_test = train_test_split(X, y, train_size=train_size, test_size=test_size)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, train_size=train_size, test_size=val_size)\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test, X_val, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46a374e7-8e89-4642-ac2c-4f8ae2a38ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_text_preprocess(context):\n",
    "    context = tf.ragged.constant(context)\n",
    "    context = tf.strings.lower(context)\n",
    "    context = tf.strings.regex_replace(context, \"[^a-z0-9.?!,¿ ]\", \"\")\n",
    "    context = tf.strings.regex_replace(context, \"[.?!,¿]\", r\" \\0 \")\n",
    "    context = tf.strings.strip(context)\n",
    "    return context\n",
    "    \n",
    "def target_text_preprocess(target):\n",
    "    target = tf.ragged.constant(target)\n",
    "    target = tf.strings.lower(target)\n",
    "    target = tf.strings.regex_replace(target, \"[^א-ת0-9a-z.?!,¿ ]\", \"\")\n",
    "    target = tf.strings.regex_replace(target, \"[.?!,¿]\", r\" \\0 \")\n",
    "    target = tf.strings.strip(target)\n",
    "\n",
    "    target = tf.strings.join([\"[SOS]\", target, \"[EOS]\"], separator=' ' )\n",
    "    \n",
    "    target = target.numpy()\n",
    "    target = [sen.decode('utf-8') for sen in target]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa50f05c-daf0-4312-8901-8139fc40a6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = get_raw_data(\"./datasets/sentences\", \"heb.txt\")\n",
    "X_train, y_train, X_test, y_test, X_val, y_val = split_data(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42c5ab48-4cb0-4e69-a8a8-1718bbb4cb57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:18:28.435762: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-05 16:18:28.448937: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "context = context_text_preprocess(X_train)\n",
    "target = target_text_preprocess(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c5fe2e13-0ea5-42d9-9b96-6ca2ad50b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vectorization = keras.layers.TextVectorization(max_tokens=5000)\n",
    "target_vectorization = keras.layers.TextVectorization(max_tokens=5000)\n",
    "\n",
    "context_vectorization.adapt(context)\n",
    "target_vectorization.adapt(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c29c9448-fabd-45e5-a9e8-07b8a064584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(keras.layers.Layer):\n",
    "    def __init__(self, units, text_processor, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.units = units\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab = self.text_processor.get_vocabulary()\n",
    "        \n",
    "        \n",
    "        self.embedding_layer = keras.layers.Embedding(input_dim=len(self.vocab), output_dim=self.units, mask_zero=True)\n",
    "        self.rnn = keras.layers.LSTM(self.units, return_sequences=True, return_state=True)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = inputs\n",
    "        x = self.text_processor(x)\n",
    "        self.embedding = self.embedding_layer(x)\n",
    "        self.context, self.hidden_state, self.cell_state = self.rnn(self.embedding)\n",
    "        return self.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65184c96-1dc6-456e-865c-23f31f217540",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossAttention(keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.attention = keras.layers.Attention()\n",
    "        self.layer_norm = keras.layers.LayerNormalization()\n",
    "        self.add = keras.layers.Add()\n",
    "    \n",
    "    def call(self, value, query):\n",
    "\n",
    "        attention_output, attention_scores = self.attention([query, value], return_attention_scores=True)\n",
    "        self.attention_weights = attention_scores\n",
    "        x = self.add([query, attention_output])\n",
    "        x = self.layer_norm(x)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fe78be2-fead-459c-b516-6d129291b4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(keras.layers.Layer):\n",
    "    def __init__(self, units, text_processor,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.text_processor = text_processor\n",
    "        self.vocab = self.text_processor.get_vocabulary()\n",
    "        \n",
    "        self.embedding_layer = keras.layers.Embedding(input_dim=len(self.vocab), output_dim=self.units, mask_zero=True)\n",
    "        self.rnn = keras.layers.LSTM(self.units, return_sequences=True, return_state=True)\n",
    "        \n",
    "        self.attention = CrossAttention()\n",
    "        self.output_layer = keras.layers.Dense(len(self.vocab))\n",
    "    \n",
    "    def call(self, context, x):\n",
    "        x = self.text_processor(x)\n",
    "        embedding = self.embedding_layer(x)\n",
    "        x, f_hidden_states, f_cell_states = self.rnn(embedding)\n",
    "        x = self.attention(context, x)\n",
    "        logits = self.output_layer(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b04c745b-9fdc-4037-ac2f-bc4aff3fc510",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(16, context_vectorization)\n",
    "decoder = Decoder(16, target_vectorization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "70042d5d-b9bd-447d-9390-dfae73f39f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-05 16:18:34.568177: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2900000000 exceeds 10% of free system memory.\n",
      "2024-02-05 16:18:35.195490: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 2900000000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "context = encoder(context[:5000])\n",
    "logits = decoder(context, target[:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8617f528-bb76-451b-a0cb-28251644d9b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5000, 29, 5000), dtype=float32, numpy=\n",
       "array([[[ 0.01501542, -0.02215884,  0.03292631, ..., -0.00316633,\n",
       "          0.03249658,  0.01084893],\n",
       "        [-0.01315241, -0.02400041,  0.02878876, ..., -0.01211426,\n",
       "          0.02269103,  0.01042926],\n",
       "        [ 0.01843226, -0.00509004,  0.0372501 , ...,  0.00710234,\n",
       "          0.02691102,  0.00563984],\n",
       "        ...,\n",
       "        [-0.00019369,  0.00490617,  0.02298385, ..., -0.00897576,\n",
       "          0.01258669,  0.01089346],\n",
       "        [-0.00019369,  0.00490617,  0.02298385, ..., -0.00897576,\n",
       "          0.01258669,  0.01089346],\n",
       "        [-0.00019369,  0.00490617,  0.02298385, ..., -0.00897576,\n",
       "          0.01258669,  0.01089346]],\n",
       "\n",
       "       [[ 0.01870219, -0.01824124,  0.02909059, ..., -0.01494344,\n",
       "          0.03485141,  0.02876124],\n",
       "        [ 0.00853089, -0.0220951 , -0.00837404, ..., -0.02269654,\n",
       "          0.02480217,  0.03579467],\n",
       "        [-0.0010935 , -0.01995786,  0.00864671, ..., -0.02249029,\n",
       "          0.03681054,  0.02755852],\n",
       "        ...,\n",
       "        [-0.00566679,  0.02181057,  0.00877623, ..., -0.00769021,\n",
       "          0.00687201,  0.01364852],\n",
       "        [-0.00566679,  0.02181057,  0.00877623, ..., -0.00769021,\n",
       "          0.00687201,  0.01364852],\n",
       "        [-0.00566679,  0.02181057,  0.00877623, ..., -0.00769021,\n",
       "          0.00687201,  0.01364852]],\n",
       "\n",
       "       [[-0.00059223,  0.00169307,  0.01206711, ...,  0.03208941,\n",
       "          0.01370687, -0.0077597 ],\n",
       "        [-0.00558032,  0.00506002,  0.01709604, ...,  0.03674179,\n",
       "          0.0238603 ,  0.00914265],\n",
       "        [-0.00942715,  0.02244187,  0.01511322, ...,  0.04404514,\n",
       "          0.01880431,  0.01146439],\n",
       "        ...,\n",
       "        [-0.03553863, -0.00179217,  0.0203522 , ..., -0.03065206,\n",
       "          0.00469893,  0.02741307],\n",
       "        [-0.03553863, -0.00179217,  0.0203522 , ..., -0.03065206,\n",
       "          0.00469893,  0.02741307],\n",
       "        [-0.03553863, -0.00179217,  0.0203522 , ..., -0.03065206,\n",
       "          0.00469893,  0.02741307]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.0009327 , -0.02248041,  0.02438407, ...,  0.00792776,\n",
       "          0.01895783,  0.01637544],\n",
       "        [-0.00491591,  0.00250196,  0.02155665, ...,  0.01085611,\n",
       "         -0.00295549,  0.02904456],\n",
       "        [-0.03325726,  0.00033623,  0.02127687, ..., -0.00122824,\n",
       "         -0.00632845,  0.00866901],\n",
       "        ...,\n",
       "        [-0.03914975,  0.00850117,  0.01755111, ..., -0.03348384,\n",
       "          0.01316375,  0.03614075],\n",
       "        [-0.03914975,  0.00850117,  0.01755111, ..., -0.03348384,\n",
       "          0.01316375,  0.03614075],\n",
       "        [-0.03914975,  0.00850117,  0.01755111, ..., -0.03348384,\n",
       "          0.01316375,  0.03614075]],\n",
       "\n",
       "       [[ 0.01153447, -0.01179732,  0.018307  , ...,  0.00524654,\n",
       "          0.02390486,  0.0150157 ],\n",
       "        [ 0.0013945 , -0.00188659,  0.00015044, ..., -0.00908831,\n",
       "          0.00191171,  0.00736655],\n",
       "        [ 0.02796755,  0.01201994,  0.00837083, ...,  0.0116179 ,\n",
       "          0.00629564, -0.00106589],\n",
       "        ...,\n",
       "        [-0.02745522,  0.00883653,  0.01360181, ..., -0.02171874,\n",
       "         -0.01170636,  0.04077806],\n",
       "        [-0.02745522,  0.00883653,  0.01360181, ..., -0.02171874,\n",
       "         -0.01170636,  0.04077806],\n",
       "        [-0.02745522,  0.00883653,  0.01360181, ..., -0.02171874,\n",
       "         -0.01170636,  0.04077806]],\n",
       "\n",
       "       [[ 0.01629987, -0.02181969,  0.02930655, ...,  0.0056739 ,\n",
       "          0.03134693, -0.00604913],\n",
       "        [ 0.02805311, -0.03349372,  0.02498093, ...,  0.00199769,\n",
       "          0.04784694,  0.0131402 ],\n",
       "        [-0.00146324, -0.02522668,  0.04927605, ...,  0.0092578 ,\n",
       "          0.04288067,  0.00119597],\n",
       "        ...,\n",
       "        [-0.02191743, -0.00981752,  0.00114185, ..., -0.01314935,\n",
       "          0.01422212,  0.01516736],\n",
       "        [-0.02191743, -0.00981752,  0.00114185, ..., -0.01314935,\n",
       "          0.01422212,  0.01516736],\n",
       "        [-0.02191743, -0.00981752,  0.00114185, ..., -0.01314935,\n",
       "          0.01422212,  0.01516736]]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b231ae14-bdf2-486b-b8b4-6409f81d0fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]],[[1,2,3],[1,2,3]]]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54019061-6f80-479a-862a-17108dde0a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
