{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d731555a-e763-4042-9749-efbf7d443849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 15:44:56.355712: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-02 15:44:56.390584: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-02 15:44:56.390621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-02 15:44:56.391386: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-02 15:44:56.396277: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-01-02 15:44:56.397368: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-02 15:44:57.041912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7910b815-39cc-4e10-98e2-190250487abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "MONTHS_DICT = {\n",
    "    1: \"January\",\n",
    "    2: \"February\",\n",
    "    3: \"March\",\n",
    "    4: \"April\",\n",
    "    5: \"May\",\n",
    "    6: \"June\",\n",
    "    7: \"July\",\n",
    "    8: \"August\",\n",
    "    9: \"September\",\n",
    "    10: \"October\",\n",
    "    11: \"November\",\n",
    "    12: \"December\"\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa6a62e-f5b5-403f-b46f-2501767a247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples):\n",
    "    X, y = [], []\n",
    "    ordinal_min = date(1000, 1, 1).toordinal()\n",
    "    ordinal_max = date(9999, 12, 31).toordinal()\n",
    "    \n",
    "    ordinal_random = np.random.randint(ordinal_max - ordinal_min, size=n_samples) + ordinal_min\n",
    "\n",
    "    for ordinal in ordinal_random:\n",
    "        dt = date.fromordinal(ordinal)\n",
    "        month = MONTHS_DICT[dt.month]\n",
    "        y.append(dt.isoformat())\n",
    "        X.append(month + \" \" + dt.strftime(\"%d, %Y\"))\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d63a4a-362e-4968-8556-3c41e84873f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHARS = sorted(set(\"\".join(MONTHS_DICT.values()) + \"1234567890, \"))\n",
    "OUTPUT_CHARS = \"0123456789-\"\n",
    "def vectorize_input(data):\n",
    "    return [INPUT_CHARS.index(char) for char in data]\n",
    "\n",
    "def vectorize_output(data):\n",
    "    return [OUTPUT_CHARS.index(char) for char in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36728810-2c03-452c-8b42-229e344cfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n_samples, batch_size=32):\n",
    "    x, y = generate_data(n_samples)\n",
    "    \n",
    "    X = [vectorize_input(dt) for dt in x]\n",
    "    Y = [vectorize_output(dt) for dt in y]\n",
    "    X, Y = tf.ragged.constant(X, ragged_rank=1), tf.ragged.constant(Y,ragged_rank=1)\n",
    "\n",
    "    X, Y = (X + 1).to_tensor(), (Y + 1).to_tensor()\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "    # dataset = dataset.shuffle(n_samples)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset, X.shape, Y.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f0f46d-8f8e-4310-82ef-bc5e726ee852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 15:45:02.955529: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-01-02 15:45:02.990585: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "train_dataset, MAX_INPUT_SHAPE, MAX_OUTPUT_SHAPE = create_dataset(n_samples=15000)\n",
    "test_dataset, _, _ = create_dataset(n_samples=3000)\n",
    "val_dataset, _, _ = create_dataset(n_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48345486-8501-47b0-8393-7c551591b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1, output_dim=embedding_size, input_shape=[None]),\n",
    "    keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")   \n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder,\n",
    "    keras.layers.RepeatVector(MAX_OUTPUT_SHAPE[1]),\n",
    "    decoder\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2608126a-3e52-4536-844f-6dc04165a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "469/469 [==============================] - 17s 30ms/step - loss: 1.6784 - accuracy: 0.4017 - val_loss: 1.4858 - val_accuracy: 0.4634\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 1.1216 - accuracy: 0.5987 - val_loss: 0.9368 - val_accuracy: 0.6636\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 13s 29ms/step - loss: 0.7362 - accuracy: 0.7216 - val_loss: 0.6013 - val_accuracy: 0.7599\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.4898 - accuracy: 0.8020 - val_loss: 0.3745 - val_accuracy: 0.8508\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.5369 - accuracy: 0.8071 - val_loss: 0.3466 - val_accuracy: 0.8735\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.2315 - accuracy: 0.9242 - val_loss: 0.1413 - val_accuracy: 0.9650\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0895 - accuracy: 0.9810 - val_loss: 0.0554 - val_accuracy: 0.9906\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0358 - accuracy: 0.9958 - val_loss: 0.0250 - val_accuracy: 0.9977\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 14s 29ms/step - loss: 0.0306 - accuracy: 0.9961 - val_loss: 0.0134 - val_accuracy: 0.9992\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 14s 30ms/step - loss: 0.0089 - accuracy: 0.9998 - val_loss: 0.0072 - val_accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f9166e944f0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94522f9a-0d51-4222-ad23-cffe8bf98c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(date_strs):\n",
    "    ids = [vectorize_input(str) for str in date_strs]\n",
    "    X = tf.ragged.constant(ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2712963-95df-4351-8d40-5a27fd25ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_input([\"September 17, 2009\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f218be-a06e-4e3d-b057-c3f8859160f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 551ms/step\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c054eac-0caf-432e-abea-cc94442fa867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "for id in ids:\n",
    "    print(''.join([OUTPUT_CHARS[index -1] for index in id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb51093e-16a4-4cda-bebb-9f048790955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_input([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9258661-de16-4f13-b196-e72a65e2b467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 479ms/step\n",
      "2020-02-02\n",
      "1789-02-14\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for id in ids:\n",
    "    print(''.join([OUTPUT_CHARS[index -1] for index in id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83862de6-215f-4084-ad84-dfa1fe104c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_input([\"May 02, 2020\", \"September 17, 2009\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "071f8e34-df28-4235-9b44-302c47a8d79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=int32, numpy=\n",
       "array([17, 21, 38,  1,  3,  5,  2,  1,  5,  3,  5,  3,  0,  0,  0,  0,  0,\n",
       "        0], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d14f003e-f94d-46ef-b371-3d1f778ef3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [vectorize_input(dt) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e26f2d0-181a-455f-8b21-eee8a5688d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = prepare_date_strs(date_strs)\n",
    "    if X.shape[1] < MAX_INPUT_SHAPE[1]:\n",
    "        X = tf.pad(X, [[0, 0], [0, MAX_INPUT_SHAPE[1] - X.shape[1]]])\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    ids = np.argmax(model.predict(X), axis=-1)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48741b2e-5f6a-4c76-a039-81914283ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = convert_date_strs([\"July 14, 1789\", \"May 01, 2020\", \"August 01, 1993\", \"November 14, 1996\", \n",
    "                           \"May 22, 4322\", \"May 01, 1999\", \"July 14, 4111\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29328af2-556b-452e-b486-689a9007d45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789-07-14\n",
      "2020-05-01\n",
      "1993-08-01\n",
      "1996-11-14\n",
      "4322-05-22\n",
      "1999-05-01\n",
      "4111-07-14\n"
     ]
    }
   ],
   "source": [
    "for id in pred:\n",
    "    print(''.join([OUTPUT_CHARS[index -1] for index in id]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87503d09-da5b-4d68-ae48-b7648c63560a",
   "metadata": {},
   "source": [
    "## Teacher Forcing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e90d85c7-4e52-4fd6-9035-a73a9ca80d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_ID = len(OUTPUT_CHARS) + 1\n",
    "def shift_output(dataset):\n",
    "    X = np.concatenate([X for X,Y in dataset], axis=0)\n",
    "    Y = np.concatenate([Y for X,Y in dataset], axis=0)\n",
    "\n",
    "    sos_token = tf.fill(dims=(Y.shape[0], 1), value=TOKEN_ID)\n",
    "    X_decoder = np.concatenate([sos_token, Y[:, :-1]], axis=1)\n",
    "    \n",
    "    return tf.constant(X), X_decoder, tf.constant(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee79f9d2-8a92-46fe-8847-4057e7ec7b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_train_decoder, y_train = shift_output(train_dataset)\n",
    "X_test, X_test_decoder, y_test = shift_output(test_dataset)\n",
    "X_val, X_val_decoder, y_val = shift_output(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6156a03d-c286-4a04-8f4a-9e4b958f0160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 23s 43ms/step - loss: 0.6927 - accuracy: 0.7648 - val_loss: 0.1625 - val_accuracy: 0.9581\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 19s 39ms/step - loss: 0.0807 - accuracy: 0.9841 - val_loss: 0.0315 - val_accuracy: 0.9974\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0341 - accuracy: 0.9952 - val_loss: 0.0123 - val_accuracy: 0.9996\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0217 - accuracy: 0.9966 - val_loss: 0.0230 - val_accuracy: 0.9972\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0065 - accuracy: 0.9999 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0559 - accuracy: 0.9875 - val_loss: 0.0209 - val_accuracy: 0.9984\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0083 - accuracy: 0.9998 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.0026 - val_accuracy: 0.9999\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 8.8384e-04 - accuracy: 1.0000 - val_loss: 8.6871e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0723 - accuracy: 0.9841 - val_loss: 0.0639 - val_accuracy: 0.9884\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0112 - accuracy: 0.9990 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 0.0033 - accuracy: 0.9997 - val_loss: 0.0045 - val_accuracy: 0.9998\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 19s 41ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 9.5132e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 6.5820e-04 - accuracy: 1.0000 - val_loss: 6.1645e-04 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 4.5211e-04 - accuracy: 1.0000 - val_loss: 4.4823e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 21s 44ms/step - loss: 3.2510e-04 - accuracy: 1.0000 - val_loss: 3.4152e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 2.4284e-04 - accuracy: 1.0000 - val_loss: 2.6675e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 1.8623e-04 - accuracy: 1.0000 - val_loss: 2.0340e-04 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 19s 40ms/step - loss: 1.4336e-04 - accuracy: 1.0000 - val_loss: 1.6731e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "encoder_input_layer = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "encoder_embedding_layer = keras.layers.Embedding(input_dim=len(INPUT_CHARS)+ 1, output_dim=512)(encoder_input_layer)\n",
    "output, encoder_h_state, encoder_c_state = keras.layers.LSTM(128, return_state=True)(encoder_embedding_layer)\n",
    "\n",
    "encoder_state = [encoder_h_state, encoder_c_state]\n",
    "\n",
    "decoder_input_layer = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
    "decoder_embedding_layer = keras.layers.Embedding(input_dim=len(OUTPUT_CHARS)+ 2, output_dim=512)(decoder_input_layer)\n",
    "decoder_LSTM_output = keras.layers.LSTM(128, return_sequences=True)(decoder_embedding_layer, initial_state=encoder_state)\n",
    "decoder_output = keras.layers.Dense(len(OUTPUT_CHARS)+1, activation=\"softmax\")(decoder_LSTM_output)\n",
    "\n",
    "model = keras.models.Model(inputs=[encoder_input_layer, decoder_input_layer], outputs=[decoder_output])\n",
    "\n",
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "history = model.fit([X_train, X_train_decoder], y_train, epochs=20, validation_data=([X_val, X_val_decoder], y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b20d873-1b09-4906-95a1-9266ef41d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dates = [\"July 14, 1789\", \"May 01, 2020\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "772fe18b-2127-4135-858d-4607c724f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    print(X)\n",
    "    Y_pred = tf.fill(dims=[len(X), 1], value=TOKEN_ID)\n",
    "    for index in range(MAX_OUTPUT_SHAPE[1]):\n",
    "        X_decoder = tf.pad(Y_pred, [[0,0],[0, MAX_OUTPUT_SHAPE[1] - Y_pred.shape[1]]])\n",
    "        pred_indices = np.argmax(model.predict([X, X_decoder])[:,index:index+1], axis=-1)\n",
    "        Y_pred = np.concatenate((Y_pred, pred_indices), axis=1)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "78ae8ba3-1b10-498f-b038-3cc5d11f2273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[16 36 28 38  1  4  7  2  1  4 10 11 12  0  0  0  0  0]\n",
      " [17 21 38  1  3  4  2  1  5  3  5  3  0  0  0  0  0  0]\n",
      " [13 36 25 36 34 35  1  3  4  2  1  4 12 12  6  0  0  0]\n",
      " [18 31 37 24 29 22 24 33  1  4  7  2  1  4 12 12  9  0]\n",
      " [17 21 38  1  5  5  2  1  7  6  5  5  0  0  0  0  0  0]\n",
      " [17 21 38  1  3  4  2  1  4 12 12 12  0  0  0  0  0  0]\n",
      " [16 36 28 38  1  4  7  2  1  7  4  4  4  0  0  0  0  0]], shape=(7, 18), dtype=int32)\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = predict_date_strs([\"July 14, 1789\", \"May 01, 2020\", \"August 01, 1993\", \"November 14, 1996\", \n",
    "                           \"May 22, 4322\", \"May 01, 1999\", \"July 14, 4111\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3bfb5e77-fbc6-4d8e-96c7-37546e81a562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1789-07-14\n",
      "2020-05-01\n",
      "1993-08-01\n",
      "1996-11-14\n",
      "4322-05-22\n",
      "1999-05-01\n",
      "4111-07-14\n"
     ]
    }
   ],
   "source": [
    "for dt in y_pred[:,1:]:\n",
    "    print(''.join([OUTPUT_CHARS[index -1] for index in dt]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c55cfcc-5ce3-4b29-b8fd-46d3c05fdbc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
