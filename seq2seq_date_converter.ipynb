{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d731555a-e763-4042-9749-efbf7d443849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 16:34:26.426262: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-27 16:34:26.459320: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-27 16:34:26.459349: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-27 16:34:26.460311: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-27 16:34:26.465220: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-27 16:34:26.465989: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-27 16:34:27.059764: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7910b815-39cc-4e10-98e2-190250487abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10\n",
    "\n",
    "MONTHS_DICT = {\n",
    "    1: \"January\",\n",
    "    2: \"February\",\n",
    "    3: \"March\",\n",
    "    4: \"April\",\n",
    "    5: \"May\",\n",
    "    6: \"June\",\n",
    "    7: \"July\",\n",
    "    8: \"August\",\n",
    "    9: \"September\",\n",
    "    10: \"October\",\n",
    "    11: \"November\",\n",
    "    12: \"December\"\n",
    "              }\n",
    "\n",
    "ordinal_min = date(999, 1, 1).toordinal()\n",
    "ordinal_max = date(9999, 12, 31).toordinal()\n",
    "ordinal_random = np.random.randint(ordinal_min, ordinal_max)\n",
    "\n",
    "dt = date.fromordinal(ordinal_random)\n",
    "tm_year, tm_month, tm_day = dt.timetuple().tm_year, dt.timetuple().tm_mon, dt.timetuple().tm_mday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9aa6a62e-f5b5-403f-b46f-2501767a247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(n_samples):\n",
    "    X, y = [], []\n",
    "    ordinal_min = date(1000, 1, 1).toordinal()\n",
    "    ordinal_max = date(9999, 12, 31).toordinal()\n",
    "    \n",
    "    ordinal_random = np.random.randint(ordinal_max - ordinal_min, size=n_samples) + ordinal_min\n",
    "\n",
    "    for ordinal in ordinal_random:\n",
    "        dt = date.fromordinal(ordinal)\n",
    "        tm_year, tm_month, tm_day = dt.timetuple().tm_year, dt.timetuple().tm_mon, dt.timetuple().tm_mday\n",
    "        month = MONTHS_DICT[tm_month]\n",
    "        y.append(dt.isoformat())\n",
    "        X.append(f\"{month} {tm_day}, {tm_year}\")\n",
    "        \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62d63a4a-362e-4968-8556-3c41e84873f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CHARS = sorted(set(\"\".join(MONTHS_DICT.values()) + \"1234567890, \"))\n",
    "OUTPUT_CHARS = \"0123456789-\"\n",
    "def vectorize_input(data):\n",
    "    return [INPUT_CHARS.index(char) for char in data]\n",
    "\n",
    "def vectorize_output(data):\n",
    "    return [OUTPUT_CHARS.index(char) for char in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36728810-2c03-452c-8b42-229e344cfec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(n_samples, batch_size=32):\n",
    "    x, y = generate_data(n_samples)\n",
    "    \n",
    "    X = [vectorize_input(dt) for dt in x]\n",
    "    Y = [vectorize_output(dt) for dt in y]\n",
    "    X, Y = tf.ragged.constant(X, ragged_rank=1), tf.ragged.constant(Y,ragged_rank=1)\n",
    "\n",
    "    X, Y = (X + 1).to_tensor(), (Y + 1).to_tensor()\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X,Y))\n",
    "    dataset = dataset.shuffle(n_samples)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    \n",
    "    return dataset, X.shape, Y.shape\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "99f0f46d-8f8e-4310-82ef-bc5e726ee852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 16:34:33.512150: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:06:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-27 16:34:33.532898: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "train_dataset, MAX_INPUT_SHAPE, MAX_OUTPUT_SHAPE = create_dataset(n_samples=15000)\n",
    "test_dataset, _, _ = create_dataset(n_samples=3000)\n",
    "val_dataset, _, _ = create_dataset(n_samples=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48345486-8501-47b0-8393-7c551591b395",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 32\n",
    "\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1, output_dim=embedding_size, input_shape=[None]),\n",
    "    keras.layers.LSTM(128)\n",
    "])\n",
    "\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.LSTM(128, return_sequences=True),\n",
    "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")   \n",
    "])\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    encoder,\n",
    "    keras.layers.RepeatVector(MAX_OUTPUT_SHAPE[1]),\n",
    "    decoder\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2608126a-3e52-4536-844f-6dc04165a388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "469/469 [==============================] - 15s 27ms/step - loss: 1.5366 - accuracy: 0.4494 - val_loss: 1.1298 - val_accuracy: 0.5915\n",
      "Epoch 2/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.9378 - accuracy: 0.6654 - val_loss: 0.7507 - val_accuracy: 0.7206\n",
      "Epoch 3/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.6249 - accuracy: 0.7568 - val_loss: 0.4834 - val_accuracy: 0.8035\n",
      "Epoch 4/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.5637 - accuracy: 0.7940 - val_loss: 1.3513 - val_accuracy: 0.4961\n",
      "Epoch 5/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.4215 - accuracy: 0.8574 - val_loss: 0.2269 - val_accuracy: 0.9323\n",
      "Epoch 6/20\n",
      "469/469 [==============================] - 12s 27ms/step - loss: 0.2103 - accuracy: 0.9459 - val_loss: 1.3380 - val_accuracy: 0.5113\n",
      "Epoch 7/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.2058 - accuracy: 0.9497 - val_loss: 0.0722 - val_accuracy: 0.9898\n",
      "Epoch 8/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0477 - accuracy: 0.9946 - val_loss: 0.0333 - val_accuracy: 0.9969\n",
      "Epoch 9/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0235 - accuracy: 0.9984 - val_loss: 0.0182 - val_accuracy: 0.9990\n",
      "Epoch 10/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0132 - accuracy: 0.9995 - val_loss: 0.0113 - val_accuracy: 0.9997\n",
      "Epoch 11/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0081 - accuracy: 0.9999 - val_loss: 0.0074 - val_accuracy: 0.9998\n",
      "Epoch 12/20\n",
      "469/469 [==============================] - 13s 28ms/step - loss: 0.0052 - accuracy: 0.9999 - val_loss: 0.0049 - val_accuracy: 0.9999\n",
      "Epoch 13/20\n",
      "469/469 [==============================] - 12s 27ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9998\n",
      "Epoch 14/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0779 - accuracy: 0.9830 - val_loss: 0.0210 - val_accuracy: 0.9984\n",
      "Epoch 15/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0087 - accuracy: 0.9998 - val_loss: 0.0054 - val_accuracy: 0.9999\n",
      "Epoch 16/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 0.9998\n",
      "Epoch 17/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 0.9999\n",
      "Epoch 18/20\n",
      "469/469 [==============================] - 13s 27ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 0.9999\n",
      "Epoch 19/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 0.9999\n",
      "Epoch 20/20\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 9.1510e-04 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 0.9999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f00326eef10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Nadam()\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
    "model.fit(train_dataset, epochs=20, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "94522f9a-0d51-4222-ad23-cffe8bf98c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(date_strs):\n",
    "    ids = [vectorize_input(str) for str in date_strs]\n",
    "    X = tf.ragged.constant(ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2712963-95df-4351-8d40-5a27fd25ebf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_input([\"September 17, 2009\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86f218be-a06e-4e3d-b057-c3f8859160f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 487ms/step\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c054eac-0caf-432e-abea-cc94442fa867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009-09-17\n",
      "1789-07-14\n"
     ]
    }
   ],
   "source": [
    "for id in ids:\n",
    "    print(''.join([OUTPUT_CHARS[index -1] for index in id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb51093e-16a4-4cda-bebb-9f048790955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_input([\"May 02, 2020\", \"July 14, 1789\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9258661-de16-4f13-b196-e72a65e2b467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 467ms/step\n",
      "2020-04-20\n",
      "1789-09-14\n"
     ]
    }
   ],
   "source": [
    "ids = np.argmax(model.predict(X_new), axis=-1)\n",
    "for id in ids:\n",
    "    print(''.join([OUTPUT_CHARS[index -1] for index in id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83862de6-215f-4084-ad84-dfa1fe104c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = prepare_input([\"May 02, 2020\", \"September 17, 2009\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "071f8e34-df28-4235-9b44-302c47a8d79c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(18,), dtype=int32, numpy=\n",
       "array([17, 21, 38,  1,  3,  5,  2,  1,  5,  3,  5,  3,  0,  0,  0,  0,  0,\n",
       "        0], dtype=int32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_new[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d14f003e-f94d-46ef-b371-3d1f778ef3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs(date_strs, chars=INPUT_CHARS):\n",
    "    X_ids = [vectorize_input(dt) for dt in date_strs]\n",
    "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
    "    return (X + 1).to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e26f2d0-181a-455f-8b21-eee8a5688d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_date_strs_padded(date_strs):\n",
    "    X = prepare_date_strs(date_strs)\n",
    "    print(X)\n",
    "    if X.shape[1] < MAX_INPUT_SHAPE[1]:\n",
    "        X = tf.pad(X, [[0, 0], [0, MAX_INPUT_SHAPE[1] - X.shape[1]]])\n",
    "        print(X)\n",
    "    return X\n",
    "\n",
    "def convert_date_strs(date_strs):\n",
    "    X = prepare_date_strs_padded(date_strs)\n",
    "    ids = np.argmax(model.predict(X), axis=-1)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48741b2e-5f6a-4c76-a039-81914283ca95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[17 21 38  1  4  4  2  1  5  3  5  3  0  0  0  0  0  0]\n",
      " [20 24 32 35 24 29 22 24 33  1  4 10  2  1  5  3  3 12]], shape=(2, 18), dtype=int32)\n",
      "1/1 [==============================] - 0s 20ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = convert_date_strs([\"May 11, 2020\", \"September 17, 2009\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29328af2-556b-452e-b486-689a9007d45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-11\n",
      "2009-09-17\n"
     ]
    }
   ],
   "source": [
    "for id in pred:\n",
    "    print(''.join([OUTPUT_CHARS[index -1] for index in id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "524cf14a-2cce-44d4-b4ec-227dcbfed1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
