{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bf91a17-1bff-4c70-b2ee-f4d848dea3fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 13:22:10.391977: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-24 13:22:11.811485: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/nick/miniconda3/envs/tf_env/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/nick/miniconda3/envs/tf_env/lib/\n",
      "2024-11-24 13:22:11.811671: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/home/nick/miniconda3/envs/tf_env/lib/python3.9/site-packages/nvidia/cudnn/lib:/home/nick/miniconda3/envs/tf_env/lib/\n",
      "2024-11-24 13:22:11.811680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import gymnasium\n",
    "\n",
    "import ale_py\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13bbcfc1-55af-47c8-94e3-27438c6058b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gymnasium.make(\"LunarLander-v3\", render_mode=\"rgb_array\")\n",
    "# obs space = [lander_x , lander_y, vel_x, vel_y, angle, angular_vel, l_contact, r_contact]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28ff490b-a440-4d7f-90b9-706f75ba3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(shape=env.observation_space.shape)\n",
    "h_1 = keras.layers.Dense(64, activation=\"relu\")(inputs)\n",
    "h_2 = keras.layers.Dense(64, activation=\"relu\")(h_1)\n",
    "outputs = keras.layers.Dense(4)(h_2)\n",
    "q_net = keras.Model(inputs,outputs)\n",
    "\n",
    "target_net = keras.models.clone_model(q_net)\n",
    "target_net.set_weights(q_net.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "828974bc-02e0-410b-8cbb-45898c2ae49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(epsilon, state):\n",
    "    if np.random.rand() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        q_val = q_net.predict(state[np.newaxis])\n",
    "        return np.argmax(q_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b64e5332-aa47-44db-b8c3-e1d4001a6ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_buffer = deque(maxlen=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e460a82-5491-4ecf-845d-72bbf85cd072",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_buffer(env, n_steps, replay_buffer):\n",
    "    state, _ = env.reset()\n",
    "    for _ in range(n_steps):\n",
    "        action = env.action_space.sample()\n",
    "        next_state, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        if done:\n",
    "            state, _ = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271275e4-bcb2-49fe-b70e-8b1556d2f424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(replay_buffer):\n",
    "    rnd_indices = np.random.randint(0, len(replay_buffer), 32)\n",
    "    samples = [replay_buffer[index] for index in rnd_indices]\n",
    "    states, actions, rewards, next_states, dones = [np.array([sample[index] for sample in samples]) for index in range(5)]\n",
    "\n",
    "    target_value = q_net.predict(next_states)\n",
    "    target_mask = tf.one_hot(np.argmax(target_value, axis=1), 4)\n",
    "\n",
    "    max_target_value = (target_net.predict(next_states) * target_mask).sum(axis=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7063364e-edcb-4b98-85ab-f3248ce4eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_buffer(env, 20000, replay_buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ab0d9a-41df-4210-9afd-3e6452d0829e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for iteration in range(n_iterations):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = epsilon_greedy_policy(epsilon)\n",
    "        next_state, reward, terminated, truncated, info = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        replay_buffer.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "    \n",
    "    train_step()\n",
    "    if iteration % 2000 == 0:\n",
    "        target_net.set_weights(q_net.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c764ac7d-8135-4061-afa6-cf914d280d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 0., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de89ca36-77d2-4ffb-b47e-05b2c6683b3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
