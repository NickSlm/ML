{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9292584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.losses import mean_squared_error, huber_loss, MeanSquaredError\n",
    "from keras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c71c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef6bc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e129d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = tf.constant([[[1,2,3],[1,2,3],[1,2,3]]])\n",
    "shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d2dcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t + 5\n",
    "t = tf.add(t, 5)  # tf.math.add(t,5)\n",
    "# t.__add__(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff80a34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[14]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3]])\n",
    "# a_n = a @ tf.transpose(a)\n",
    "a_n = tf.matmul(a, tf.transpose(a))\n",
    "a_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "854b43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e56801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 5. 8.]\n",
      "tf.Tensor([2 5 8], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(t, axis=1))\n",
    "print(tf.reduce_mean(t, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17cdca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([4., 5., 6.])\n",
    "a = np.array([4., 5., 6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df847427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16., 25., 36.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8499ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([16., 25., 36.])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be4838",
   "metadata": {},
   "source": [
    "Tensorflow does not perform automatic type conversion to not hurt perfomance.\n",
    "If type conversion is needed you can use tf.cast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2606a180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(4., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0ca48",
   "metadata": {},
   "source": [
    "Because the tf.Tensor values so far are immutable we cannot change them which is problematic when we are working with weights that need to be adjusted by backpropagation.\n",
    "We can use tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e435d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.],[4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573a429d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e26b63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(v * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13d6bad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[42.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 0].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "129f365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[42.,  4.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a628ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(45, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "arr = tf.constant([1,2,3,4,5,6,7,8,9])\n",
    "print(tf.reduce_sum(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ebc37",
   "metadata": {},
   "source": [
    "# Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98ed31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebdf8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_california_housing()\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "X_val_scaled = std_scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a4639a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    mse = tf.square(error) / 2\n",
    "    mae = tf.abs(error) - 0.5\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    return tf.where(is_small_error, mse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37936b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6c0bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=huber_fn, optimizer=\"Nadam\")\n",
    "# model.fit(X_train, y_train, [...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea6d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        huber_mse = 0.5 * tf.square(error)\n",
    "        huber_mae = self.threshold * (tf.abs(error) - 0.5 * self.threshold)\n",
    "        is_smaller_error = tf.abs(error) < self.threshold\n",
    "        return tf.where(is_smaller_error, huber_mse, huber_mae)\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        This method used to store the parameters used in the training\n",
    "        \"\"\"\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f687bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                            input_shape=[8,]))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82a2a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68ab203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 2ms/step - loss: 0.9726 - accuracy: 0.0023 - val_loss: 0.3720 - val_accuracy: 0.0044\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2547 - accuracy: 0.0025 - val_loss: 0.2922 - val_accuracy: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2c14d7e80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b30a25d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2391 - accuracy: 0.0026 - val_loss: 0.2220 - val_accuracy: 0.0044\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2298 - accuracy: 0.0025 - val_loss: 0.2393 - val_accuracy: 0.0044\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\", \n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06ea06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cf2ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afba0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev = stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(weights * 0.1))\n",
    "\n",
    "def my_positive_weights(weights):\n",
    "    return tf.nn.relu(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b3be48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus, \n",
    "                           kernel_initializer=my_glorot_initializer, \n",
    "                           kernel_regularizer=my_l1_regularizer, \n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c3467ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3bdc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(weights * self.factor))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dac625f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                      input_shape=[8,]),\n",
    "    keras.layers.Dense(1, activation=my_softplus, \n",
    "                       kernel_initializer=my_glorot_initializer,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69bb6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b687992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.6904 - mae: 0.9289 - val_loss: inf - val_mae: inf\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5731 - mae: 0.5215 - val_loss: 3.0681 - val_mae: 0.5284\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2c395c730>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "267d17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aea76cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209c3a0",
   "metadata": {},
   "source": [
    "# Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2201cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0de17caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAccuracy(keras.metrics.Metric):\n",
    "    def __init__(self,  delta = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.delta = delta\n",
    "        self.huber_fn = create_huber(delta)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.total.assign(0.)\n",
    "        self.count.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9120e40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 554us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227ff9d",
   "metadata": {},
   "source": [
    "# Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1df9de",
   "metadata": {},
   "source": [
    "To create custom layers without any weight such as Flatten, Relu we can wrap it in Lambda layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63af726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2875cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "547849f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77cf2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[8,]),\n",
    "        keras.layers.Dense(1),\n",
    "        exponential_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a963313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8890 - val_loss: 0.4055\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 950us/step - loss: 0.4163 - val_loss: 0.3600\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 948us/step - loss: 0.4136 - val_loss: 0.3826\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.3933 - val_loss: 0.3700\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 941us/step - loss: 0.4032 - val_loss: 0.3454\n",
      "162/162 [==============================] - 0s 717us/step - loss: 0.3623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36233896017074585"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "         validation_data=(X_val_scaled, y_val))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad0d8a",
   "metadata": {},
   "source": [
    "To create a custom layer with weights we have to build a new subclass of keras.layers.Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "937e869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayerDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", \n",
    "            shape=[input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\"\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\",\n",
    "            shape=[self.units], \n",
    "            initializer=\"zeros\"\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tf.TensorShape(input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Method used to store the parameters\n",
    "        \"\"\"\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "079d5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70dcc6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    CustomLayerDense(30, activation=\"relu\", input_shape=[8,]),\n",
    "    CustomLayerDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf9e887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7098 - val_loss: 0.6942\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.5748 - val_loss: 0.5553\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4620 - val_loss: 0.6325\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4246 - val_loss: 0.4246\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4014 - val_loss: 0.3799\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3878 - val_loss: 0.4517\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3827 - val_loss: 0.5054\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3726 - val_loss: 0.3612\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3666 - val_loss: 0.4612\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.3614 - val_loss: 0.7848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f2c4c184f0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=10, \n",
    "         validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a3f9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        x1, x2 = X\n",
    "        print(\"x1.shape: \", x1.shape ,\" x2.shape: \", x2.shape) # Debugging of custom layer\n",
    "        return x1 + x2, x1 * x2\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape1, input_shape2 = input_shape\n",
    "        return [input_shape1, input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c2812b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.shape:  (None, 2)  x2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f547183",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68dc3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"relu\", \n",
    "                                          kernel_initializer=\"he_normal\") for _ in range(n_layers)]\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        print(Z.shape, inputs.shape)\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3aa74085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_1 = keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "        self.block_1 = ResidualBlock(2, 30)\n",
    "        self.block_2 = ResidualBlock(2, 30)\n",
    "        \n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden_1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block_1(Z)\n",
    "        Z = self.block_2(Z)\n",
    "        return self.out(Z)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "656f42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "870085e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "363/363 [==============================] - 2s 1ms/step - loss: 4.8528\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0852\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0155\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.6463\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.4780\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "121/121 [==============================] - 0s 767us/step - loss: 12.0481\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "162/162 [==============================] - 0s 677us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_val_scaled, y_val)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "918c3e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  270       \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  multiple                 1860      \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  multiple                 1860      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bf0468",
   "metadata": {},
   "source": [
    "# Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fe5c3c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6ee30678",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", \n",
    "                       kernel_initializer=\"he_normal\", \n",
    "                       kernel_regularizer=keras.regularizers.l2(0.05)),\n",
    "    keras.layers.Dense(1, kernel_regularizer=keras.regularizers.l2(0.05))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dadb21d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    indices = np.random.randint(len(X), size=batch_size)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "122adaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "acc_metric = keras.metrics.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c2c4c118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "11424/11610 [============================>.] - ETA: 0s - acc: 1.0368 - loss: 1.8615\n",
      "Epoch 2/5\n",
      "11456/11610 [============================>.] - ETA: 0s - acc: 0.9019 - loss: 1.3708\n",
      "Epoch 3/5\n",
      "11392/11610 [============================>.] - ETA: 0s - acc: 0.8760 - loss: 1.3257\n",
      "Epoch 4/5\n",
      "11392/11610 [============================>.] - ETA: 0s - acc: 0.9004 - loss: 1.3508\n",
      "Epoch 5/5\n",
      "11552/11610 [============================>.] - ETA: 0s - acc: 0.9086 - loss: 1.3443"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{n_epochs}\")\n",
    "    progbar = keras.utils.Progbar(len(y_train))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        acc_metric.update_state(y_batch, y_pred)\n",
    "        acc = acc_metric.result()\n",
    "        progbar.add(batch_size, values=[(\"acc\", acc),(\"loss\", loss)])\n",
    "    \n",
    "    acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de41c8b",
   "metadata": {},
   "source": [
    "# Functions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a17447c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cube(num):\n",
    "    return num ** 3\n",
    "\n",
    "cube(tf.constant(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a8c6911c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.eager.polymorphic_function.polymorphic_function.Function at 0x1f2c8a6d760>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "tf_cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f9835ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_cube(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1f8c3854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.constant(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bbfefd75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant(np.arange(10))\n",
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae315962",
   "metadata": {},
   "source": [
    "# Exercise 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "921e6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayerNormalization(keras.layers.Layer):\n",
    "    def __init__(self, ep=1e-3, **kwargs):\n",
    "        self.ep = ep\n",
    "        super().__init__(**kwargs)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.alpha = self.add_weight(name=\"alpha\", \n",
    "                                     shape=input_shape[-1:],\n",
    "                                     initializer=\"ones\")\n",
    "        self.beta = self.add_weight(name=\"beta\", \n",
    "                                    shape=input_shape[-1:],\n",
    "                                    initializer=\"zeros\")\n",
    "    def call(self, inputs):\n",
    "        mean, variance = tf.nn.moments(inputs, axes=-1, keepdims=True)\n",
    "        return self.alpha * (inputs - mean) / (tf.sqrt(self.ep + variance)) + self.beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "757a29cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_train.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b0d3df23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.9357733e-08>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_layer_normalization = CustomLayerNormalization()\n",
    "layer_normalization = keras.layers.LayerNormalization()\n",
    "\n",
    "tf.reduce_mean(keras.losses.mean_absolute_error(\n",
    "    layer_normalization(X), custom_layer_normalization(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f4b4d6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "X_test = X_test.astype(np.float32) / 255.\n",
    "X_train_full = X_train_full.astype(np.float32) / 255.\n",
    "X_train, X_val = X_train_full[5000:], X_train_full[:5000]\n",
    "y_train, y_val = y_train_full[5000:], y_train_full[:5000]\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
    "val_dataset = val_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3f9cd1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "cf07eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28,28]),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a259d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_epochs = 5\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.sparse_categorical_crossentropy\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=1e-2)\n",
    "metrics = keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "580e12f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "1718/1718 [==============================] - 29s 17ms/step - acc: 0.8819 - loss: 0.3335\n",
      "Validation acc: 0.8566\n",
      "\n",
      "Epoch 2/5\n",
      "1718/1718 [==============================] - 30s 18ms/step - acc: 0.8770 - loss: 0.3265\n",
      "Validation acc: 0.8656\n",
      "\n",
      "Epoch 3/5\n",
      "1718/1718 [==============================] - 30s 17ms/step - acc: 0.8827 - loss: 0.3190\n",
      "Validation acc: 0.8702\n",
      "\n",
      "Epoch 4/5\n",
      "1718/1718 [==============================] - 28s 17ms/step - acc: 0.8821 - loss: 0.3254\n",
      "Validation acc: 0.8618\n",
      "\n",
      "Epoch 5/5\n",
      "1718/1718 [==============================] - 28s 17ms/step - acc: 0.8777 - loss: 0.3271\n",
      "Validation acc: 0.8708\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{n_epochs}\")\n",
    "    progbar = keras.utils.Progbar(n_steps)\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        metrics.update_state(y_batch, y_pred)\n",
    "        acc = metrics.result()\n",
    "        progbar.add(1,values=[(\"acc\", acc), (\"loss\", loss)])\n",
    "    metrics.reset_states()\n",
    "    \n",
    "    for X_batch_val, y_batch_val in val_dataset:\n",
    "        val_pred = model(X_batch_val, training=False)\n",
    "        val_acc_metric.update_state(y_batch_val, val_pred)\n",
    "    val_acc = val_acc_metric.result()\n",
    "    val_loss = keras.losses.sparse_categorical_crossentropy(y_batch_val, val_pred)\n",
    "    print(f\"\\rValidation acc: %.4f\" % (float(val_acc),))\n",
    "\n",
    "    val_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7071db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665344c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
