{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9292584",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.losses import mean_squared_error, huber_loss, MeanSquaredError\n",
    "from keras.metrics import Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0c71c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ef6bc32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = tf.constant(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e129d6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 3, 3])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape = tf.constant([[[1,2,3],[1,2,3],[1,2,3]]])\n",
    "shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91d2dcee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = t + 5\n",
    "t = tf.add(t, 5)  # tf.math.add(t,5)\n",
    "# t.__add__(10)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff80a34a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[14]])>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([[1,2,3]])\n",
    "# a_n = a @ tf.transpose(a)\n",
    "a_n = tf.matmul(a, tf.transpose(a))\n",
    "a_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "854b43d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e56801d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 5. 8.]\n",
      "tf.Tensor([2 5 8], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(t, axis=1))\n",
    "print(tf.reduce_mean(t, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e17cdca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([4., 5., 6.])\n",
    "a = np.array([4., 5., 6.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df847427",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16., 25., 36.], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.square(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8499ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float64, numpy=array([16., 25., 36.])>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.square(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13be4838",
   "metadata": {},
   "source": [
    "Tensorflow does not perform automatic type conversion to not hurt perfomance.\n",
    "If type conversion is needed you can use tf.cast()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2606a180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = tf.constant(4., dtype=tf.float64)\n",
    "tf.constant(2.0) + tf.cast(t2, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca0ca48",
   "metadata": {},
   "source": [
    "Because the tf.Tensor values so far are immutable we cannot change them which is problematic when we are working with weights that need to be adjusted by backpropagation.\n",
    "We can use tf.Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e435d31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tf.Variable([[1., 2., 3.],[4., 5., 6.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "573a429d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e26b63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[ 2.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.assign(v * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13d6bad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[42.,  4.,  6.],\n",
       "       [ 8., 10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[0, 0].assign(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "129f365a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[42.,  4.,  0.],\n",
       "       [ 8., 10.,  1.]], dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v[:, 2].assign([0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0a628ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(45, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "arr = tf.constant([1,2,3,4,5,6,7,8,9])\n",
    "print(tf.reduce_sum(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4ebc37",
   "metadata": {},
   "source": [
    "# Custom Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98ed31ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ebdf8807",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_california_housing()\n",
    "X, y = dataset.data, dataset.target\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "X_train_scaled = std_scaler.fit_transform(X_train)\n",
    "X_test_scaled = std_scaler.transform(X_test)\n",
    "X_val_scaled = std_scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1a4639a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    mse = tf.square(error) / 2\n",
    "    mae = tf.abs(error) - 0.5\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    return tf.where(is_small_error, mse, mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "37936b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d6c0bd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=huber_fn, optimizer=\"Nadam\")\n",
    "# model.fit(X_train, y_train, [...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ea6d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        huber_mse = 0.5 * tf.square(error)\n",
    "        huber_mae = self.threshold * (tf.abs(error) - 0.5 * self.threshold)\n",
    "        is_smaller_error = tf.abs(error) < self.threshold\n",
    "        return tf.where(is_smaller_error, huber_mse, huber_mae)\n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        This method used to store the parameters used in the training\n",
    "        \"\"\"\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41f687bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                            input_shape=[8,]))\n",
    "model.add(keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "82a2a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "68ab203a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8293 - accuracy: 0.0023 - val_loss: 0.3023 - val_accuracy: 0.0044\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2413 - accuracy: 0.0026 - val_loss: 0.2201 - val_accuracy: 0.0044\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179f8866e80>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b30a25d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.2317 - accuracy: 0.0027 - val_loss: 0.2115 - val_accuracy: 0.0044\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 0.2246 - accuracy: 0.0026 - val_loss: 0.2739 - val_accuracy: 0.0044\n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\", \n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, \n",
    "          validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b06ea06d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.loss.threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cf2ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "afba0a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_softplus(z):\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "def my_glorot_initializer(shape, dtype=tf.float32):\n",
    "    stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "    return tf.random.normal(shape, stddev = stddev, dtype=dtype)\n",
    "\n",
    "def my_l1_regularizer(weights):\n",
    "    return tf.reduce_sum(tf.abs(weights * 0.1))\n",
    "\n",
    "def my_positive_weights(weights):\n",
    "    return tf.nn.relu(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b3be48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = keras.layers.Dense(1, activation=my_softplus, \n",
    "                           kernel_initializer=my_glorot_initializer, \n",
    "                           kernel_regularizer=my_l1_regularizer, \n",
    "                           kernel_constraint=my_positive_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c3467ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c3bdc4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(weights * self.factor))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dac625f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                      input_shape=[8,]),\n",
    "    keras.layers.Dense(1, activation=my_softplus, \n",
    "                       kernel_initializer=my_glorot_initializer,\n",
    "                       kernel_regularizer=MyL1Regularizer(0.01),\n",
    "                       kernel_constraint=my_positive_weights)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69bb6014",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b687992c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.7693 - mae: 0.9440 - val_loss: 1.0843 - val_mae: 0.5559\n",
      "Epoch 2/2\n",
      "363/363 [==============================] - 0s 965us/step - loss: 0.6072 - mae: 0.5299 - val_loss: 2.1735 - val_mae: 0.5258\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fbcadb80>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=2, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "267d17de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "aea76cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "       \"MyL1Regularizer\": MyL1Regularizer,\n",
    "       \"my_positive_weights\": my_positive_weights,\n",
    "       \"my_glorot_initializer\": my_glorot_initializer,\n",
    "       \"my_softplus\": my_softplus,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3209c3a0",
   "metadata": {},
   "source": [
    "# Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2201cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0de17caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAccuracy(keras.metrics.Metric):\n",
    "    def __init__(self,  delta = 1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.delta = delta\n",
    "        self.huber_fn = create_huber(delta)\n",
    "        self.total = self.add_weight(\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(\"count\", initializer=\"zeros\")\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "        \n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    \n",
    "    def reset_states(self):\n",
    "        self.total.assign(0.)\n",
    "        self.count.assign(0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9120e40f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363/363 [==============================] - 0s 552us/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8227ff9d",
   "metadata": {},
   "source": [
    "# Custom Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1df9de",
   "metadata": {},
   "source": [
    "To create custom layers without any weight such as Flatten, Relu we can wrap it in Lambda layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "63af726f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2875cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "547849f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0.36787945, 1.        , 2.7182817 ], dtype=float32)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponential_layer([-1., 0., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77cf2339",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "        keras.layers.Dense(30, activation=\"relu\", input_shape=[8,]),\n",
    "        keras.layers.Dense(1),\n",
    "        exponential_layer\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8a963313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 0.8693 - val_loss: 0.4831\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 861us/step - loss: 0.4425 - val_loss: 0.3747\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 862us/step - loss: 0.4077 - val_loss: 0.3627\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 854us/step - loss: 0.4490 - val_loss: 0.3863\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 841us/step - loss: 0.3996 - val_loss: 0.3679\n",
      "162/162 [==============================] - 0s 599us/step - loss: 0.3862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3861834406852722"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "         validation_data=(X_val_scaled, y_val))\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ad0d8a",
   "metadata": {},
   "source": [
    "To create a custom layer with weights we have to build a new subclass of keras.layers.Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "937e869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLayerDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "        \n",
    "    def build(self, input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", \n",
    "            shape=[input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\"\n",
    "        )\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\",\n",
    "            shape=[self.units], \n",
    "            initializer=\"zeros\"\n",
    "        )\n",
    "        super().build(input_shape)\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "    \n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tf.TensorShape(input_shape.as_list()[:-1] + [self.units])\n",
    "    \n",
    "    def get_config(self):\n",
    "        \"\"\"\n",
    "        Method used to store the parameters\n",
    "        \"\"\"\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "079d5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "70dcc6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    CustomLayerDense(30, activation=\"relu\", input_shape=[8,]),\n",
    "    CustomLayerDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf9e887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "363/363 [==============================] - 1s 1ms/step - loss: 1.8415 - val_loss: 3.0125\n",
      "Epoch 2/10\n",
      "363/363 [==============================] - 0s 936us/step - loss: 0.6381 - val_loss: 0.9399\n",
      "Epoch 3/10\n",
      "363/363 [==============================] - 0s 934us/step - loss: 0.4823 - val_loss: 0.4518\n",
      "Epoch 4/10\n",
      "363/363 [==============================] - 0s 952us/step - loss: 0.4299 - val_loss: 0.4415\n",
      "Epoch 5/10\n",
      "363/363 [==============================] - 0s 949us/step - loss: 0.4090 - val_loss: 0.3838\n",
      "Epoch 6/10\n",
      "363/363 [==============================] - 0s 938us/step - loss: 0.3950 - val_loss: 0.4553\n",
      "Epoch 7/10\n",
      "363/363 [==============================] - 0s 927us/step - loss: 0.3867 - val_loss: 0.3713\n",
      "Epoch 8/10\n",
      "363/363 [==============================] - 0s 925us/step - loss: 0.3781 - val_loss: 0.5114\n",
      "Epoch 9/10\n",
      "363/363 [==============================] - 0s 928us/step - loss: 0.3719 - val_loss: 0.4246\n",
      "Epoch 10/10\n",
      "363/363 [==============================] - 0s 923us/step - loss: 0.3676 - val_loss: 0.9516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x179fbfae310>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "model.fit(X_train_scaled, y_train, epochs=10, \n",
    "         validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a3f9925",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        x1, x2 = X\n",
    "        print(\"x1.shape: \", x1.shape ,\" x2.shape: \", x2.shape) # Debugging of custom layer\n",
    "        return x1 + x2, x1 * x2\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        input_shape1, input_shape2 = input_shape\n",
    "        return [input_shape1, input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5c2812b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x1.shape:  (None, 2)  x2.shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f547183",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68dc3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"relu\", \n",
    "                                          kernel_initializer=\"he_normal\") for _ in range(n_layers)]\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        print(Z.shape, inputs.shape)\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3aa74085",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden_1 = keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "        self.block_1 = ResidualBlock(2, 30)\n",
    "        self.block_2 = ResidualBlock(2, 30)\n",
    "        \n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden_1(inputs)\n",
    "        for _ in range(1 + 3):\n",
    "            Z = self.block_1(Z)\n",
    "        Z = self.block_2(Z)\n",
    "        return self.out(Z)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "656f42a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "870085e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "363/363 [==============================] - 2s 1ms/step - loss: 72.3591\n",
      "Epoch 2/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 3.1400\n",
      "Epoch 3/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 2.7163\n",
      "Epoch 4/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.2249\n",
      "Epoch 5/5\n",
      "363/363 [==============================] - 0s 1ms/step - loss: 1.0895\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "121/121 [==============================] - 0s 704us/step - loss: 18.8721\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "(None, 30) (None, 30)\n",
      "162/162 [==============================] - 0s 590us/step\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=5)\n",
    "score = model.evaluate(X_val_scaled, y_val)\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "918c3e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"residual_regressor\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               multiple                  270       \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  multiple                 1860      \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  multiple                 1860      \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " dense_5 (Dense)             multiple                  31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,021\n",
      "Trainable params: 4,021\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f29d47",
   "metadata": {},
   "source": [
    "# Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc233ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1f4a3b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", \n",
    "                       kernel_initializer=\"he_normal\", \n",
    "                       kernel_regularizer=keras.regularizers.l2(0.05)),\n",
    "    keras.layers.Dense(1, kernel_regularizer=keras.regularizers.l2(0.05))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e6b313dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    indices = np.random.randint(len(X), size=batch_size)\n",
    "    return X[indices], y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "51f71a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "optimizer = keras.optimizers.SGD(learning_rate=1e-3)\n",
    "acc_metric = keras.metrics.MeanAbsoluteError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b18c2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/5\n",
      "11488/11610 [============================>.] - ETA: 0s - acc: 0.8844 - loss: 1.3368\n",
      "Epoch 2/5\n",
      "11520/11610 [============================>.] - ETA: 0s - acc: 0.8807 - loss: 1.3201\n",
      "Epoch 3/5\n",
      "11552/11610 [============================>.] - ETA: 0s - acc: 0.8991 - loss: 1.3540\n",
      "Epoch 4/5\n",
      "11488/11610 [============================>.] - ETA: 0s - acc: 0.9060 - loss: 1.3533\n",
      "Epoch 5/5\n",
      "11424/11610 [============================>.] - ETA: 0s - acc: 0.8964 - loss: 1.3312"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"\\nEpoch {epoch}/{n_epochs}\")\n",
    "    progbar = keras.utils.Progbar(len(y_train))\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True)\n",
    "            loss = loss_fn(y_batch, y_pred)\n",
    "        \n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        acc_metric.update_state(y_batch, y_pred)\n",
    "        acc = acc_metric.result()\n",
    "        progbar.add(batch_size, values=[(\"acc\", acc),(\"loss\", loss)])\n",
    "    \n",
    "    acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02585ee8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
